# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2014-2020, ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE (Theory and Simulation of Materials (THEOS) and National Centre for Computational Design and Discovery of Novel Materials (NCCR MARVEL)), Switzerland and ROBERT BOSCH LLC, USA. All rights reserved
# This file is distributed under the same license as the AiiDA package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: AiiDA 1.3\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2020-07-01 16:11+0000\n"
"PO-Revision-Date: 2020-07-01 16:11+0000\n"
"Language-Team: Chinese (China) (https://www.transifex.com/aiidateam/teams/98967/zh_CN/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: zh_CN\n"
"Plural-Forms: nplurals=1; plural=0;\n"

#: ../docs/source/topics/calculations/concepts.rst:5
#: ../docs/source/topics/processes/concepts.rst:5
#: ../docs/source/topics/provenance/concepts.rst:5
#: ../docs/source/topics/workflows/concepts.rst:5
msgid "Concepts"
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:7
#: ../docs/source/topics/calculations/usage.rst:9
msgid ""
"A calculation is a process (see the :ref:`process "
"section<topics:processes:concepts>` for details) that *creates* new data. "
"Currently, there are two ways of implementing a calculation process:"
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:10
#: ../docs/source/topics/processes/functions.rst:10
msgid ""
":ref:`calculation function<topics:calculations:concepts:calcfunctions>`"
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:11
msgid ":ref:`calculation job<topics:calculations:concepts:calcjobs>`"
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:13
msgid ""
"The first one is the simplest of the two and is basically a python function "
"that is magically transformed into a process. This is ideal for calculations"
" that are not very computationally intensive and can be easily implemented "
"in a python function. For more taxing calculations, typically performed by "
"external codes that are optionally run on remote computing clusters, the "
"calculation job is the better alternative."
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:17
msgid ""
"In the following sections, both concepts will be explained but without going"
" too much into detail on how to implement or run them. For a more detailed "
"expos√©, please refer to the respective advanced sections on "
":ref:`calculation functions<topics:calculations:usage:calcfunctions>` and "
":ref:`calculation jobs<topics:calculations:usage:calcjobs>`."
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:24
#: ../docs/source/topics/calculations/usage.rst:20
msgid "Calculation functions"
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:26
msgid "Consider the following computational task at hand:"
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:29
msgid ""
"Given three integers, add the first two and then multiply the sum by the "
"third."
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:31
msgid ""
"In plain python code, the solution would look something like the following:"
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:36
msgid ""
"This simple code snippet will achieve the goal of getting the desired "
"result, however, the provenance is lost. There is no connection between the "
"output of the functions and their inputs. The remedy to this problem is the "
":py:func:`~aiida.engine.processes.functions.calcfunction`. The "
"``calcfunction`` in AiiDA is a `function decorator "
"<https://docs.python.org/3/glossary.html#term-decorator>`_ that transforms a"
" regular python function in a calculation process, which automatically "
"stores the provenance of its output in the :ref:`provenance "
"graph<topics:provenance>` when executed. Updating the previous snippet with "
"``calcfunction`` decorators yields:"
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:45
msgid ""
"The only thing we had to do to decorate the two functions was to add the "
"line ``@calcfunction`` just before the function definition. Adding the "
"decorator tells AiiDA that the provenance for this function should be stored"
" in the provenance graph when it is executed. This means linking up the "
"inputs and the outputs for a calculation node, which represents the function"
" that was executed. The final change that has to be performed to make this "
"possible, is to make the inputs and the outputs storable. In the previous "
"snippet, the inputs are plain python integer types, which cannot be "
"automatically stored in the provenance graph as nodes. To solve this, one "
"only has to wrap them in the :py:class:`~aiida.orm.nodes.data.int.Int` node "
"sub class, which makes them storable in the database:"
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:55
msgid ""
"The only difference with the previous snippet is that all inputs have been "
"wrapped in the :py:class:`~aiida.orm.nodes.data.int.Int` class. The result "
"that is returned by the function, is now also an "
":py:class:`~aiida.orm.nodes.data.int.Int` node that can be stored in the "
"provenance graph, and contains the result of the computation."
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:60
msgid ""
"Since ``x`` and ``y`` inside the ``add`` and ``multiply`` functions are "
"already :py:class:`~aiida.orm.nodes.data.int.Int` instances the sum will "
"also be one. This is true because all arithmetic operators also work on the "
"base AiiDA classes (``Int``, ``Float``, etc.) as they would on the "
"equivalent python types. It is important to realize though that only "
":py:class:`~aiida.orm.nodes.node.Node` instances, or sub classes thereof can"
" be stored. For more information on how to return results from process "
"functions, refer to the :ref:`advanced "
"section<topics:calculations:usage:calcfunctions>`."
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:65
msgid ""
"With these trivial changes, the full provenance of the result produced by "
"running the function is maintained and looks like the following:"
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:70
msgid "The provenance generated by the calcfunction example"
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:72
msgid ""
"The example above already shows how a calcfunction can be run: simply by "
"calling it. The value that is returned is the result returned by the "
"definition of the function. However, sometimes one would also like to have a"
" reference to the calculation node that represents the execution of the "
"function in the provenance graph. The following example shows two additional"
" launch functions that will return a tuple, which in addition to the "
"results, also return the ``pk`` or the node associated with the process"
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:80
msgid ""
"This was a very short and limited description of calculation functions. For "
"a more detailed description of launching them, please refer to the section "
"on :ref:`launching processes<topics:processes:usage:launching>`. If you want"
" more details on implementing calculation functions and best practices, "
"refer to the section on :ref:`working with calculation "
"functions<topics:calculations:usage:calcfunctions>`."
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:88
#: ../docs/source/topics/calculations/usage.rst:64
msgid "Calculation jobs"
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:90
msgid ""
"In the previous section on :ref:`calculation "
"functions<topics:calculations:concepts:calcfunctions>`, we showed how a "
"simple python function can be transformed into a process, such that when it "
"is launched, its execution is recorded automatically in the provenance "
"graph. However, not all computations are well suited to be implemented as a "
"python function, but rather are implemented as a separate code, external to "
"AiiDA. To interface an external code with the engine of AiiDA, the "
":py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` process class "
"was introduced. A detailed explanation of how to implement it, the interface"
" and best practices, can be found in a :ref:`later "
"section<topics:calculations:usage:calcjobs>`. Here, instead, we will focus "
"on the big picture and explain in broad lines how a calculation job models "
"the execution of an external code and what tasks it performs when launched."
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:96
msgid ""
"To illustrate how a calculation job operates, we need an external code. "
"Let's imagine an external code that consists of a bash script that reads an "
"input file containing two integers, sums them and prints the result in the "
"standard output using ``echo``, for example:"
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:107
msgid ""
"When run, this script reads the contents of a file called ``aiida.in`` and "
"expects that it contains two integers. It will parse these into the "
"variables ``x`` and ``y`` and then print their sum. When you want to run "
"this 'code' through AiiDA, you need to tell *how* AiiDA should run it. The "
":py:class:`~aiida.calculations.arithmetic.add.ArithmeticAddCalculation` is a"
" calculation job implementation that forms an interface to accomplish "
"exactly that for the example bash script. A ``CalcJob`` implementation for a"
" specific code, often referred to as a calculation plugin, essentially "
"instructs the engine how it should be run. This includes how the necessary "
"input files should be created based on the inputs that it receives, how the "
"code executable should be called and what files should be retrieved when the"
" calculation is complete. Note the files should be 'retrieved' because "
"calculation jobs can be run not just on the localhost, but on any "
":ref:`computer that is configured in AiiDA<how-to:codes:computers>`, "
"including remote machines accessible over for example SSH."
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:115
msgid ""
"Since a ``CalcJob`` is a process just like the :ref:`calculation "
"functions<topics:calculations:concepts:calcfunctions>` described before, "
"they can be run in an identical way."
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:120
msgid ""
"the provenance generated by running the calculation job will look something "
"like this:"
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:125
msgid "The provenance generated by the calculation job example"
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:127
msgid ""
"The execution of the calculation job is represented in the provenance graph "
"by a process node, i.e. the pink square labeled `C\\ :sub:`1`` in "
":numref:`fig_calculation_jobs_provenance_arithmetic_add`. The integer data "
"nodes ``x`` and ``y`` that were passed as inputs are linked to the "
"calculation job as such, as well as the third input ``code``. This input is "
"required for *all* calculation jobs as it represents the external code that "
"is actually executed. These code nodes are instances of the "
":py:class:`~aiida.orm.nodes.data.code.Code` class, which is a sub-class of "
":py:class:`~aiida.orm.nodes.data.data.Data`. This means that code instances "
"are a sort of data node. Its function is to record the path to the "
"executable and some other code related attributes defined during the code "
"setup."
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:134
msgid ""
"The calculation job produced two outputs, an integer node, containing the "
"sum of ``x`` and ``y`` and a "
":py:class:`~aiida.orm.nodes.data.folder.FolderData` node, containing the "
"output files that were retrieved. Note that all outputs of calculation jobs "
"(except for the ``retrieved`` node) are technically not created by the "
"calculation job itself, but rather by an implementation of the "
":py:class:`~aiida.parsers.parser.Parser` class. In principle, this step is "
"optional, and so a calculation job is therefore not required to produce any "
"outputs, except for the ``retrieved`` folder data node, which will always be"
" there. How the parser fits into the concept of calculation jobs will be "
"addressed in :ref:`this "
"section<topics:calculations:concepts:calcjobs_parsers>`."
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:142
msgid "Transport tasks"
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:144
msgid ""
"To arrive at the provenance graph shown above in "
":numref:`fig_calculation_jobs_provenance_arithmetic_add`, the engine "
"performed quite some tasks. When a calculation job is launched, the engine "
"will take it roughly through the following steps:"
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:147
msgid ""
"**Upload**: the calculation job implementation is used to transform the "
"input nodes into the required input files, which are uploaded to a 'working'"
" directory on the target machine"
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:148
msgid ""
"**Submit**: to execute the calculation, a job is submitted to the scheduler "
"of the computer on which the input `code` is configured."
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:149
msgid ""
"**Update**: the engine will query the scheduler to check for the status of "
"the calculation job"
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:150
msgid ""
"**Retrieve**: once the job has finished, the engine will retrieve the output"
" files, specified by the calculation plugin and store them in a node "
"attached as an output node to the calculation"
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:152
msgid ""
"All of these tasks require the engine to interact with the computer, or "
"machine, that will actually run the external code. Since the "
":py:class:`~aiida.orm.nodes.data.code.Code` that is used as an input for the"
" calculation job, which is configured for a specific "
":py:class:`~aiida.orm.computers.Computer`, the engine knows exactly how to "
"execute all these tasks. The ``CalcJob`` implementation itself then is "
"completely independent of the machine the code will be run on. To run the "
"calculation job on a different machine, all you have to do is change the "
"``code`` input to one that is configured for that machine. If the machine is"
" *not* the localhost, the engine will need a way to connect to the remote "
"machine in order to perform each of the four tasks listed above. The "
"mechanism that allows the engine to connect to the remote machine is called "
"a *transport* and therefore the tasks it performs using this transport are "
"called *transport tasks*."
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:163
msgid "Exponential backoff mechanism"
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:165
msgid ""
"In the case of calculation jobs being executed on a remote machine, the "
"engine will have to connect to the machine for each of the transport tasks. "
"In connecting to the remote, a whole host of potential problems may occur "
"that would cause the calculation job to fail. For example, the remote "
"machine may be down and as a result unreachable, or the engine itself may "
"lose its internet connection. However, these problems are often temporary. "
"To prevent the calculation job from excepting and it being lost forever, an "
"*exponential backoff mechanism* has been implemented. Whenever the engine "
"performs a transport task but encounters an exception, instead of letting "
"the calculation job fail, it will reschedule the same task to be executed "
"again at a later time. The task will be automatically rescheduled until it "
"finishes successfully, where the interval between tries increases "
"exponentially. If after 5 consecutive tries, the task still fails, instead "
"of rescheduling it, the engine will simply pause the calculation job. The "
"output of ``verdi process list`` will give more information on why the task "
"failed:"
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:184
msgid ""
"When there are calculation jobs that have been paused because the transport "
"tasks have failed multiple times, the user has the time to investigate the "
"problem. If the problem is determined to be temporary and it has been "
"resolved, one can use ``verdi process play`` to resume the paused processes."
" The engine will then automatically reschedule the task that failed last and"
" the calculation job will continue where it left off."
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:188
msgid ""
"This exponential backoff mechanism makes the engine very robust with respect"
" to calculation jobs, reducing the loss of computational resources due to "
"temporary problems to an absolute minimum."
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:192
msgid ""
"The parameters, such as the delays between retries and the maximum number of"
" retries, are currently not configurable, but they might be in the future."
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:197
msgid "Parsers"
msgstr ""

#: ../docs/source/topics/calculations/concepts.rst:198
msgid ""
"The previous section explained how the ``CalcJob`` class functions as an "
"interface between AiiDA's engine and an external piece of code. The "
"calculation job plugin will instruct the engine how the :ref:`transport "
"tasks<topics:calculations:concepts:calcjobs_transport_tasks>` should be "
"accomplished. However, as mentioned before, those tasks stop after the "
"output files have been retrieved, which the engine will attach as a "
":py:class:`~aiida.orm.nodes.data.folder.FolderData` node with the label "
"``'retrieved'`` to the calculation job node. As far as the calculation job "
"goes that is all that is absolutely required. However, often one wants to "
"parse those output files into some specific outputs that should be "
"represented as individual nodes in the provenance graph. This can be "
"accomplished by implementing the :py:class:`~aiida.parsers.parser.Parser` "
"class and specifying it in the inputs of the calculation job. In that case, "
"the engine will call the parser after the output files created by the job "
"have been successfully retrieved. In the parser implementation, the "
"retrieved files can then be parsed and converted into output nodes. For "
"technical details on how to implement a parser for a calculation job and how"
" to specify it in the inputs, please refer to the :ref:`detailed parser "
"section<topics:calculations:usage:calcjobs:parsers>`,"
msgstr ""

#: ../docs/source/topics/calculations/index.rst:5
msgid "Calculations"
msgstr ""

#: ../docs/source/topics/calculations/index.rst:7
msgid ""
"This topic section provides detailed information on the concept of "
"calculations in AiiDA and an extensive guide on how to work with them. An "
"introductory guide to working with calculations can be found in :ref:`\"How "
"to run external codes\"<how-to:codes>`."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:5
#: ../docs/source/topics/processes/usage.rst:5
#: ../docs/source/topics/workflows/usage.rst:5
msgid "Usage"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:7
msgid ""
"This chapter assumes knowledge of the :ref:`basic "
"concept<topics:calculations:concepts>` and difference between calculation "
"functions and calculation jobs is known and when one should use on or the "
"other."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:12
msgid ":ref:`calculation function<topics:calculations:usage:calcfunctions>`"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:13
msgid ":ref:`calculation job<topics:calculations:usage:calcjobs>`"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:15
msgid ""
"This section will provide detailed information and best practices on how to "
"implement these two calculation types."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:22
msgid ""
"The section on the :ref:`concept of calculation "
"functions<topics:calculations:concepts:calcfunctions>` already addressed "
"their aim: automatic recording of their execution with their inputs and "
"outputs in the provenance graph. The :ref:`section on process "
"functions<topics:processes:functions>` subsequently detailed the rules that "
"apply when implementing them, all of which to calculation functions, which "
"are a sub type, just like work functions. However, there are some "
"differences given that calculation functions are 'calculation'-like "
"processes and work function behave like 'workflow'-like processes. What this"
" entails in terms of intended usage and limitations for calculation "
"functions is the scope of this section."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:28
msgid "Creating data"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:29
msgid ""
"It has been said many times before: calculation functions, like all "
"'calculation'-like processes, `create` data, but what does `create` mean "
"exactly? In this context, the term 'create' is not intended to refer to the "
"simple creation of a new data node in the graph, in an interactive shell or "
"a script for example. But rather it indicates the creation of a new piece of"
" data from some other data through a computation implemented by a process. "
"This is then exactly what the calculation function does. It takes one or "
"more data nodes as inputs and returns one or more data nodes as outputs, "
"whose content is based on those inputs. As explained in the :ref:`technical "
"section<topics:processes:functions>`, outputs are created simply by "
"returning the nodes from the function. The engine will inspect the return "
"value from the function and attach the output nodes to the calculation node "
"that represents the calculation function. To verify that the output nodes "
"are in fact 'created', the engine will check that the nodes are not stored. "
"Therefore, it is very important that you **do not store the nodes you create"
" yourself**, or the engine will raise an exception, as shown in the "
"following example:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:42
msgid ""
"Because the returned node is already stored, the engine will raise the "
"following exception:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:50
msgid ""
"The reason for this strictness is that a node that was stored after being "
"created in the function body, is indistinguishable from a node that was "
"already stored and had simply been loaded in the function body and returned,"
" e.g.:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:55
msgid ""
"The loaded node would also have gotten a `create` link from the calculation "
"function, even though it was not really created by it at all. It is exactly "
"to prevent this ambiguity that calculation functions require all returned "
"output nodes to be *unstored*."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:58
msgid ""
"Note that work functions have exactly the opposite required and all the "
"outputs that it returns **have to be stored**, because as a 'workflow'-like "
"process, it *cannot* create new data. For more details refer to the "
":ref:`work function section<topics:workflows:usage:workfunctions>`."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:66
msgid ""
"To explain how a calculation job can be implemented, we will continue with "
"the example presented in the section on the :ref:`concept of the calculation"
" job<topics:calculations:concepts:calcjobs>`. There we described a code that"
" adds two integers, implemented as a simple bash script, and how the "
":py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` class can be "
"used to run this code through AiiDA. Since it is a sub class of the "
":py:class:`~aiida.engine.processes.process.Process` class, it shares all its"
" properties. It will be very valuable to have read the section on working "
"with :ref:`generic processes<topics:processes:usage>` before continuing, "
"because all the concepts explained there will apply also to calculation "
"jobs."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:75
#: ../docs/source/topics/workflows/usage.rst:150
msgid "Define"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:76
msgid ""
"To implement a calculation job, one simply sub classes the "
":py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` process class "
"and implements the "
":py:meth:`~aiida.engine.processes.calcjobs.calcjob.CalcJob.define` method. "
"You can pick any name that is a valid python class name. The most important "
"method of the ``CalcJob`` class, is the ``define`` class method. Here you "
"define, what inputs it takes and what outputs it will generate."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:84
msgid ""
"As the snippet above demonstrates, the class method takes two arguments:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:86
msgid ""
"``cls`` this is the reference of the class itself and is mandatory for any "
"class method"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:87
msgid "``spec`` which is the 'specification'"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:90
msgid ""
"Do not forget to add the line ``super().define(spec)`` as the first line of "
"the ``define`` method, where you replace the class name with the name of "
"your calculation job. This will call the ``define`` method of the parent "
"class, which is necessary for the calculation job to work properly"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:93
msgid ""
"As the name suggests, the ``spec`` can be used to specify the properties of "
"the calculation job. For example, it can be used to define inputs that the "
"calculation job takes. In our example, we need to be able to pass two "
"integers as input, so we define those in the spec by calling "
"``spec.input()``. The first argument is the name of the input. This name "
"should be used later to specify the inputs when launching the calculation "
"job and it will also be used as the label for link to connect the data node "
"and the calculation node in the provenance graph. Additionally, as we have "
"done here, you can specify which types are valid for that particular input. "
"Since we expect integers, we specify that the valid type is the database "
"storable :py:class:`~aiida.orm.nodes.data.int.Int` class."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:103
msgid ""
"Since we sub class from ``CalcJob`` and call its ``define`` method, it will "
"inherit the ports that it declares as well. If you look at the "
"implementation, you will find that the base class ``CalcJob`` already "
"defines an input ``code`` that takes a ``Code`` instance. This will "
"reference the code that the user wants to run when he launches the "
"``CalcJob``. For this reason, you **do not** again have to declare this "
"input."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:108
msgid ""
"Next we should define what outputs we expect the calculation to produce:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:113
msgid ""
"Just as for the inputs, one can specify what node type each output should "
"have. By default a defined output will be 'required', which means that if "
"the calculation job terminates and the output has not been attached, the "
"process will be marked as failed. To indicate that an output is optional, "
"one can use ``required=False`` in the ``spec.output`` call. Note that the "
"process spec, and its :py:meth:`~plumpy.ProcessSpec.input` and "
":py:meth:`~plumpy.ProcessSpec.output` methods provide a lot more "
"functionality. Fore more details, please refer to the section on "
":ref:`process specifications<topics:processes:usage:spec>`."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:123
msgid "Prepare"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:124
msgid ""
"We have now defined through the process specification, what inputs the "
"calculation job expects and what outputs it will create. The final remaining"
" task is to instruct the engine how the calculation job should actually be "
"run. To understand what the engine would have to do to accomplish this, "
"let's consider what one typically does when manually preparing to run a "
"computing job through a scheduler:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:128
msgid ""
"Prepare a working directory in some scratch space on the machine where the "
"job will run"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:129
msgid "Create the raw input files required by the executable"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:130
msgid ""
"Create a launch script containing scheduler directives, loading of "
"environment variables and finally calling the executable with certain "
"command line parameters."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:132
msgid ""
"So all we need to do now is instruct the engine how to accomplish these "
"things for a specific calculation job. Since these instructions will be "
"calculation dependent, we will implement this with the "
":py:meth:`~aiida.engine.processes.calcjobs.calcjob.CalcJob.prepare_for_submission`"
" method. The implementation of the ``ArithmeticAddCalculation`` that we are "
"considering in the example looks like the following:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:139
msgid ""
"Before we go into the code line-by-line, let's describe the big picture of "
"what is happening here. The goal of this method is to help the engine "
"accomplish the three steps required for preparing the submission a "
"calculation job, as described above. The raw input files that are required "
"can be written to a sandbox folder that is passed in as the ``folder`` "
"argument."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:145
msgid ""
"The ``folder`` argument points to a temporary sandbox folder on the local "
"file system that can be used to write the input files to. After the "
"``prepare_for_submission`` method returns, the engine will take those "
"contents and copy them to the working directory where the calculation will "
"be run. On top of that, these files will also be written to the file "
"repository of the node that represents the calculation as an additional "
"measure of provenance. Even though the information written there should be a"
" derivation of the contents of the nodes that were passed as input nodes, "
"since it is a derived form we store this explicitly nonetheless. Sometimes, "
"this behavior is undesirable, for example for efficiency or data privacy "
"reasons, so it can be controlled with various lists such as "
":ref:`local_copy_list "
"<topics:calculations:usage:calcjobs:file_lists_local_copy>` and "
":ref:`provenance_exclude_list "
"<topics:calculations:usage:calcjobs:file_lists_provenance_exclude>`."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:151
msgid ""
"All the other required information, such as the directives of which files to"
" copy and what command line options to use are defined through the "
":py:class:`~aiida.common.datastructures.CalcInfo` datastructure, which "
"should be returned from the method as the only value. In principle, this is "
"what one **should do** in the ``prepare_for_submission`` method:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:154
msgid ""
"Writing raw inputs files required for the calculation to run to the "
"``folder`` sandbox folder."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:155
msgid ""
"Use a ``CalcInfo`` to instruct the engine which files to copy to the working"
" directory"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:156
msgid ""
"Use a ``CalcInfo`` to tell which codes should run, using which command line "
"parameters, such as standard input and output redirection."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:160
msgid ""
"The ``prepare_for_submission`` does not have to write the submission script "
"itself. The engine will know how to do this, because the codes that are to "
"be used have been configured on a specific computer, which defines what "
"scheduler is to be used. This gives the engine all the necessary information"
" on how to write the launch script such as what scheduler directives to "
"write."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:164
msgid ""
"Now that we know what the ``prepare_for_submission`` is expected to do, "
"let's see how the implementation of the ``ArithmeticAddCalculation`` "
"accomplishes it line-by-line. The input file required for this example "
"calculation will consist of the two integers that are passed as inputs. The "
"``self.inputs`` attribute returns an attribute dictionary with the parsed "
"and validated inputs, according to the process specification defined in the "
"``define`` method. This means that you do not have to validate the inputs "
"yourself. That is to say, if an input is marked as required and of a certain"
" type, by the time we get to the ``prepare_for_submission`` it is guaranteed"
" that the dictionary returned by ``self.inputs`` will contain that input and"
" of the correct type."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:170
msgid ""
"From the two inputs ``x`` and ``y`` that will have been passed when the "
"calculation job was launched, we should now generate the input file, that is"
" simply a text file with these two numbers on a single line, separated by a "
"space. We accomplish this by opening a filehandle to the input file in the "
"sandbox folder and write the values of the two ``Int`` nodes to the file."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:175
msgid ""
"The format of this input file just so happens to be the format that the "
":ref:`bash script<topics:calculations:concepts:calcjobs>` expects that we "
"are using in this example. The exact number of input files and their content"
" will of course depend on the code for which the calculation job is being "
"written."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:178
msgid ""
"With the input file written, we now have to create an instance of "
":py:class:`~aiida.common.datastructures.CalcInfo` that should be returned "
"from the method. This data structure will instruct the engine exactly what "
"needs to be done to execute the code, such as what files should be copied to"
" the remote computer where the code will be executed. In this simple "
"example, we define four simple attributes:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:182
msgid ""
"``codes_info``: a list of :py:class:`~aiida.common.datastructures.CodeInfo` "
"datastructures, that tell which codes to run consecutively during the job"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:183
msgid ""
"``local_copy_list``: a list of tuples that instruct what files to copy to "
"the working directory from the local machine"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:184
msgid ""
"``remote_copy_list``: a list of tuples that instruct what files to copy to "
"the working directory from the machine on which the job will run"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:185
msgid ""
"``retrieve_list``: a list of tuples instructing which files should be "
"retrieved from the working directory and stored in the local repository "
"after the job has finished"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:187
msgid ""
"In this example we only need to run a single code, so the ``codes_info`` "
"list has a single ``CodeInfo`` datastructure. This datastructure needs to "
"define which code it needs to run, which is one of the inputs passed to the "
"``CalcJob``, and does so by means of its UUID. Through the ``stdout_name`` "
"attribute, we tell the engine where the output of the executable should be "
"redirected to. In this example this is set to the value of the  "
"``output_filename`` option. What options are available in calculation jobs, "
"what they do and how they can be set will be explained in the :ref:`section "
"on options<topics:calculations:usage:calcjobs:options>`. Finally, the "
"``cmdline_params`` attribute takes a list with command line parameters that "
"will be placed *after* the executable in the launch script. Here we use it "
"to explicitly instruct the executable to read its input from the filename "
"stored in the option ``input_filename``."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:197
msgid ""
"Since we instruct the executable should read the input from "
"``self.options.input_filename``, this is also the filename we used when "
"writing that very input file in the sandbox folder."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:199
msgid ""
"Finally, we have to define the various \"file lists\" that tell what files "
"to copy from where to where and what files to retrieve. Here we will briefly"
" describe their intended goals. The implementation details will be described"
" in full in the :ref:`file lists "
"section<topics:calculations:usage:calcjobs:file_lists>`."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:203
msgid ""
"The local copy list is useful to instruct the engine to copy over files that"
" you might already have stored in your database, such as instances of "
":py:class:`~aiida.orm.nodes.data.singlefile.SinglefileData` nodes, that you "
"can define and pass as inputs of the ``CalcJob``. You could have of course "
"many copied their content to the ``folder`` sandbox folder, which will also "
"have caused them to be written to the working directory. The disadvantage of"
" that method, however, is that all the contents written to the sandbox "
"folder will also be stored in the repository of the ``CalcJobNode`` that "
"will represent the execution of the ``CalcJob`` in the provenance graph. "
"This will cause duplication of the data contained within these data nodes. "
"By not writing them explicitly to the sandbox folder, you avoid this "
"duplication, without losing provenance, because the data node itself will of"
" course be recorded in the provenance graph."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:209
msgid ""
"The remote copy list is useful to avoid unnecessary file transfers between "
"the machine where the engine runs and where the calculation jobs are "
"executed. For example, imagine you have already completed a calculation job "
"on a remote cluster and now want to launch a second one, that requires some "
"of the output files of the first run as its inputs. The remote copy list "
"allows you to specify exactly what output files to copy to the remote "
"working directory, without them having to be retrieved to the engine's "
"machine in between."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:213
msgid ""
"The retrieve list, finally, allows you to instruct the engine what files "
"should be retrieved from the working directory after the job has terminated."
" These files will be downloaded to the local machine, stored in a "
":py:class:`~aiida.orm.nodes.data.folder.FolderData` data node and attached "
"as an output to the ``CalcJobNode`` with the link label ``retrieved``."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:218
msgid ""
"We didn't explicitly define the ``retrieved`` folder data node as an output "
"in the example ``ArithmeticAddCalculation`` implementation shown above. This"
" is because this is already defined by the ``CalcJob`` base class. Just as "
"the ``code`` input, the ``retrieved`` output is common for all calculation "
"job implementations."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:226
msgid "File lists"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:231
msgid "Local copy list"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:232
msgid ""
"The local copy list takes tuples of length three, each of which represents a"
" file to be copied, defined through the following items:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:234
msgid ""
"`node uuid`: the node whose repository contains the file, typically a "
"``SinglefileData`` or ``FolderData`` node"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:235
msgid ""
"`source relative path`: the relative path of the file within the node "
"repository"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:236
#: ../docs/source/topics/calculations/usage.rst:303
msgid ""
"`target relative path`: the relative path within the working directory to "
"which to copy the file"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:238
msgid ""
"As an example, consider a ``CalcJob`` implementation that receives a "
"``SinglefileData`` node as input with the name ``pseudopotential``, to copy "
"its contents one can specify:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:244
msgid ""
"The ``SinglefileData`` node only contains a single file by definition, the "
"relative path of which is returned by the ``filename`` attribute. If "
"instead, you need to transfer a specific file from a ``FolderData``, you can"
" specify the explicit key of the file, like so:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:251
msgid ""
"Note that the filenames in the relative source and target path need not be "
"the same. This depends fully on how the files are stored in the node's "
"repository and what files need to be written to the working directory."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:254
msgid ""
"One might think what the purpose of the list is, when one could just as "
"easily use normal the normal API to write the file to the ``folder`` sandbox"
" folder. It is true, that in this way the file will be copied to the working"
" directory, however, then it will *also* be copied into the repository of "
"the calculation node. Since in this case it is merely a direct one-to-one "
"copy of the file that is already part of one of the input nodes (in an "
"unaltered form), this duplication is unnecessary and adds useless weight to "
"the file repository. Using the ``local_copy_list`` prevents this unnecessary"
" duplication of file content. It can also be used if the content of a "
"particular input node is privacy sensitive and cannot be duplicated in the "
"repository."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:263
msgid "Provenance exclude list"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:264
msgid ""
"The :ref:`local_copy_list "
"<topics:calculations:usage:calcjobs:file_lists_local_copy>`  allows one to "
"instruct the engine to write files from the input files to the working "
"directory, without them *also* being copied to the file repository of the "
"calculation node. As discussed in the corresponding section, this is useful "
"in order to avoid duplication or in case where the data of the nodes is "
"proprietary or privacy sensitive and cannot be duplicated arbitrarily "
"everywhere in the file repository. However, the limitation of the "
"``local_copy_list`` is that the it can only target single files in its "
"entirety and cannot be used for arbitrary files that are written to the "
"``folder`` sandbox folder. To provide full control over what files from the "
"``folder`` are stored permanently in the calculation node file repository, "
"the ``provenance_exclude_list`` is introduced. This "
":py:class:`~aiida.common.datastructures.CalcInfo` attribute is a list of "
"filepaths, relative to the base path of the ``folder`` sandbox folder, which"
" *are not stored* in the file repository."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:270
msgid ""
"Consider the following file structure as written by an implementation of "
"``prepare_for_submission`` to the ``folder`` sandbox:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:280
msgid ""
"Clearly, we do not want the ``personal.dat`` and ``secret.key`` files to end"
" up permanently in the file repository. This can be achieved by defining:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:287
msgid ""
"With this specification, the final contents of the repository of the "
"calculation node will contain:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:298
msgid "Remote copy list"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:299
msgid ""
"The remote copy list takes tuples of length three, each of which represents "
"a file to be copied on the remote machine where the calculation will run, "
"defined through the following items:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:301
msgid ""
"`computer uuid`: this is the UUID of the ``Computer`` on which the source "
"file resides. For now the remote copy list can only copy files on the same "
"machine where the job will run."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:302
msgid ""
"`source absolute path`: the absolute path of the source file on the remote "
"machine"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:309
msgid ""
"Note that the source path can point to a directory, in which case its "
"contents will be recursively copied in its entirety."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:314
msgid "Retrieve list"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:315
msgid ""
"The retrieve list supports various formats to define what files should be "
"retrieved. The simplest is retrieving a single file, whose filename you know"
" before hand and you simply want to copy with the same name in the retrieved"
" folder. Imagine you want to retrieve the files ``output1.out`` and "
"``output_folder/output2.out`` you would simply add them as strings to the "
"retrieve list:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:323
msgid ""
"The retrieved files will be copied over keeping the exact names and "
"hierarchy. If you require more control over the hierarchy and nesting, you "
"can use tuples of length three instead, with the following items:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:326
msgid ""
"`source relative path`: the relative path, with respect to the working "
"directory on the remote, of the file or directory to retrieve"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:327
msgid ""
"`target relative path`: the relative path where to copy the files locally in"
" the retrieved folder. The string `'.'` indicates the top level in the "
"retrieved folder."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:328
msgid ""
"`depth`: the number of levels of nesting in the folder hierarchy to maintain"
" when copying, starting from the deepest file"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:330
msgid ""
"For example, imagine the calculation will have written a file in the remote "
"working directory with the folder hierarchy "
"``some/remote/path/files/output.dat``. If you want to copy the file, with "
"the final resulting path ``path/files/output.dat``, you would specify:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:337
msgid ""
"The depth of two, ensures that only two levels of nesting are copied. If the"
" output files have dynamic names that one cannot know beforehand, the "
"``'*'`` glob pattern can be used. For example, if the code will generate a "
"number of XML files in the folder ``relative/path/output`` with filenames "
"that follow the pattern ``file_*[0-9].xml``, you can instruct to retrieve "
"all of them as follows:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:345
msgid ""
"The second item when using globbing *has* to be ``'.'`` and the depth works "
"just as before. In this example, all files matching the globbing pattern "
"will be copied in the directory ``output`` in the retrieved folder data "
"node."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:350
msgid "Retrieve temporary list"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:351
msgid ""
"Recall that, as explained in the :ref:`'prepare' "
"section<topics:calculations:usage:calcjobs:prepare>`, all the files that are"
" retrieved by the engine following the 'retrieve list', are stored in the "
"``retrieved`` folder data node. This means that any file you retrieve for a "
"completed calculation job will be stored in your repository. If you are "
"retrieving big files, this can cause your repository to grow significantly. "
"Often, however, you might only need a part of the information contained in "
"these retrieved files. To solve this common issue, there is the concept of "
"the 'retrieve temporary list'. The specification of the retrieve temporary "
"list is identical to that of the normal :ref:`retrieve "
"list<topics:calculations:usage:calcjobs:file_lists_retrieve>`. The only "
"difference is that, unlike the files of the retrieve list which will be "
"permanently stored in the retrieved "
":py:class:`~aiida.orm.nodes.data.folder.FolderData` node, the files of the "
"retrieve temporary list will be stored in a temporary sandbox folder. This "
"folder is then passed to the "
":ref:`parser<topics:calculations:usage:calcjobs:parsers>`, if one was "
"specified for the calculation job. The parser implementation can then parse "
"these files and store the relevant information as output nodes. After the "
"parser terminates, the engine will take care to automatically clean up the "
"sandbox folder with the temporarily retrieved files. The contract of the "
"'retrieve temporary list' is essentially that the files will be available "
"during parsing and will be destroyed immediately afterwards."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:367
msgid "Options"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:368
msgid ""
"In addition to the common metadata inputs, such as ``label`` and "
"``description``, that all processes have, the "
":py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` has an "
"additonal input called ``options``. These options allow to subtly change the"
" behavior of the calculation job, for example which parser should be used "
"once it is finished and special scheduler directives. The full list of "
"available options are documented below as part of the ``CalcJob`` interface:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:380
msgid "Launch"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:382
msgid ""
"Launching a calculation job is no different from launching any other process"
" class, so please refer to the section on :ref:`launching "
"processes<topics:processes:usage:launch>`. The only caveat that we should "
"place is that calculation jobs typically tend to take quite a bit of time. "
"The trivial example we used above of course will run very fast, but a "
"typical calculation job that will be submitted to a scheduler will most "
"likely take longer than just a few seconds. For that reason it is highly "
"advisable to **submit** calculation jobs instead of running them. By "
"submitting them to the daemon, you free up your interpreter straight away "
"and the process will be checkpointed between the various :ref:`transport "
"tasks<topics:calculations:concepts:calcjobs_transport_tasks>` that will have"
" to be performed. The exception is of course when you want to run a "
"calculation job locally for testing or demonstration purposes."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:393
msgid "Dry run"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:394
msgid ""
"The calculation job has one additional feature over all other processes when"
" it comes to launching them. Since an incorrectly configured calculation job"
" can potentially waste computational resources, one might want to inspect "
"the input files that will be written by the plugin, before actually "
"submitting the job. A so-called dry-run is possible by simply specifying it "
"in the metadata of the inputs. If you are using the process builder, it is "
"as simple as:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:403
msgid ""
"When you now launch the process builder, the engine will perform the entire "
"process of a normal calculation job run, except that it will not actually "
"upload and submit the job to the remote computer. However, the "
"``prepare_for_submission`` method will be called. The inputs that it writes "
"to the input folder will be stored in temporary folder called "
"``submit_test`` that will be created in the current working directory. Each "
"time you perform a dry-run, a new sub folder will be created in the "
"``submit_test`` folder, which you allows you to perform multiple dry-runs "
"without overwriting the previous results."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:408
msgid "Moreover, the following applies:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:410
msgid ""
"when calling :py:func:`~aiida.engine.launch.run` for a calculation with the "
"``dry_run`` flag set, you will get back its results, being always an empty "
"dictionary ``{}``;"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:413
msgid ""
"if you call :py:func:`~aiida.engine.launch.run_get_node`, you will get back "
"as a node an unstored ``CalcJobNode``. In this case, the unstored "
"``CalcJobNode`` (let's call it ``node``) will have an additional property "
"``node.dry_run_info``. This is a dictionary that contains additional "
"information on the dry-run output. In particular, it will have the following"
" keys:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:419
msgid ""
"``folder``: the absolute path to the folder within the ``submit_test`` "
"folder where the files have been created, e.g.: "
"``/home/user/submit_test/20190726-00019``"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:422
msgid ""
"``script_filename``: the filename of the submission script that AiiDA "
"generated in the folder, e.g.: ``_aiidasubmit.sh``"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:425
msgid ""
"if you send a dry-run to the :py:func:`~aiida.engine.launch.submit` "
"function, this will be just forwarded to run and you will get back the "
"unstored node (with the same properties as above)."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:432
msgid ""
"By default the storing of provenance is enabled and this goes also for a dry"
" run. If you do not want any nodes to be created during a dry run, simply "
"set the metadata input ``store_provenance`` to ``False``."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:439
msgid "Parsing"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:440
msgid ""
"The previous sections explained in detail how the execution of an external "
"executable is wrapped by the ``CalcJob`` class to make it runnable by "
"AiiDA's engine. From the first steps of preparing the input files on the "
"remote machine, to retrieving the relevant files and storing them in a "
":py:class:`~aiida.orm.nodes.data.folder.FolderData` node, that is attached "
"as the ``retrieved`` output. This is the last *required* step for a "
"``CalcJob`` to terminate, but often we would *like* to parse the raw output "
"and attach them as queryable output nodes to the calculation job node. To "
"automatically trigger the parsing of a calculation job after its output has "
"been retrieved, is to specify the :ref:`parser name "
"option<topics:calculations:usage:calcjobs:options>`. If the engine find this"
" option specified, it will load the corresponding parser class, which should"
" be a sub class of :py:class:`~aiida.parsers.parser.Parser` and calls its "
":py:meth:`~aiida.parsers.parser.Parser.parse` method."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:446
msgid ""
"To explain the interface of the ``Parser`` class and the ``parse`` method, "
"let's take the "
":py:class:`~aiida.parsers.plugins.arithmetic.add.ArithmeticAddParser` as an "
"example. This parser is designed to parse the output produced by the simple "
"bash script that is wrapped by the ``ArithmeticAddCalculation`` discussed in"
" the previous sections."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:453
msgid ""
"To create a new parser implementation, simply create a new class that sub "
"classes the :py:class:`~aiida.parsers.parser.Parser` class. As usual, any "
"valid python class name will work, but the convention is to always use the "
"``Parser`` suffix and to use the same name as the calculation job for which "
"the parser is designed. For example, here we are implementing a parser for "
"the ``ArithmeticAddCalculation``, so therefore we name it "
"``ArithmeticAddParser``, just replacing the ``Calculation`` suffix for "
"``Parser``. The only method that needs to be implemented is the "
":py:meth:`~aiida.parsers.parser.Parser.parse` method. Its signature should "
"include ``**kwargs``, the reason for which will become clear later. The goal"
" of the ``parse`` method is very simple:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:460
msgid ""
"Open and load the content of the output files generated by the calculation "
"job and have been retrieved by the engine"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:461
msgid ""
"Create data nodes out of this raw data that are attached as output nodes"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:462
msgid "Log human-readable warning messages in the case of worrying output"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:463
msgid ""
"Optionally return an :ref:`exit code<topics:processes:concepts:exit_codes>` "
"to indicate that the results of the calculation was not successful"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:465
msgid ""
"The advantage of adding the raw output data in different form as output "
"nodes, is that in that form the content becomes queryable. This allows one "
"to query for calculations that produced specific outputs with a certain "
"value, which becomes a very powerful approach for post-processing and "
"analyses of big databases."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:468
msgid ""
"The ``retrieved`` attribute of the parser will return the ``FolderData`` "
"node that should have been attached by the engine containing all the "
"retrieved files, as specified using the :ref:`retrieve "
"list<topics:calculations:usage:calcjobs:file_lists_retrieve>` in the "
":ref:`preparation step of the calculation "
"job<topics:calculations:usage:calcjobs:prepare>`. If this node has not been "
"attached for whatever reason, this call will throw an "
":py:class:`~aiida.common.exceptions.NotExistent` exception. This is why we "
"wrap the ``self.retrieved`` call in a try-catch block:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:478
msgid ""
"If the exception is thrown, it means the retrieved files are not available "
"and something must have has gone terribly awry with the calculation. In this"
" case, there is nothing to do for the parser and so we return an exit code. "
"Specific exit codes can be referenced by their label, such as "
"``ERROR_NO_RETRIEVED_FOLDER`` in this example, through the "
"``self.exit_codes`` property. This call will retrieve the corresponding exit"
" code defined on the ``CalcJob`` that we are currently parsing. Returning "
"this exit code from the parser will stop the parsing immediately and will "
"instruct the engine to set its exit status and exit message on the node of "
"this calculation job. This should scenario should however never occur, but "
"it is just here as a safety. If the exception would not be caught, the "
"engine will catch the exception instead and set the process state of the "
"corresponding calculation to ``Excepted``. Note that this will happen for "
"any exception that occurs during parsing."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:487
msgid ""
"Assuming that everything went according to plan during the retrieval, we now"
" have access to those retrieved files and can start to parse them. In this "
"example, there should be a single output file that was written by "
"redirecting the standard output of the bash script that added the two "
"integers. The parser opens this file, reads its content and tries to parse "
"the sum from it:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:497
msgid ""
"Note that again we wrap this parsing action in a try-except block. If the "
"file cannot be found or cannot be read, we return the appropriate exit code."
" The ``parse_stdout`` method is just a small utility function to separate "
"the actual parsing of the data from the main parser code. In this case, the "
"parsing is so simple that we might have as well kept it in the main method, "
"but this is just to illustrate that you are completely free to organize the "
"code within the ``parse`` method for clarity. If we manage to parse the sum,"
" produced by the calculation, we wrap it in the appropriate "
":py:class:`~aiida.orm.nodes.data.int.Int` data node class, and register it "
"as an output through the ``out`` method:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:509
msgid ""
"Note that if we encountered no problems, we do not have to return anything. "
"The engine will interpret this as the calculation having finished "
"successfully. You might now pose the question: \"what part of the raw data "
"should I parse and in what types of data nodes should I store it?\". This "
"not an easy question to answer in the general, because it will heavily "
"depend on the type of raw output that is produced by the calculation and "
"what parts you would like to be queryable. However, we can give you some "
"guidelines:"
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:515
msgid ""
"Store data that you might want to query for, in the lightweight data nodes, "
"such as :py:class:`~aiida.orm.nodes.data.dict.Dict`, "
":py:class:`~aiida.orm.nodes.data.list.List` and "
":py:class:`~aiida.orm.nodes.data.structure.StructureData`. The contents of "
"these nodes are stored as attributes in the database, which makes sure that "
"they can be queried for."
msgstr ""

#: ../docs/source/topics/calculations/usage.rst:517
msgid ""
"Bigger data sets, such as large (multi-dimnensional) arrays, are better "
"stored in an :py:class:`~aiida.orm.nodes.data.array.array.ArrayData` or one "
"of its sub classes. If you were to store all this data in the database, it "
"would become unnecessarily bloated, because the chances you would have to "
"query for this data are unlikely. Instead these array type data nodes store "
"the bulk of their content in the repository. This way you still keep the "
"data and therewith the provenance of your calculations, while keeping your "
"database lean and fast!"
msgstr ""

#: ../docs/source/topics/cli.rst:5
msgid "Command line interface"
msgstr ""

#: ../docs/source/topics/cli.rst:7
msgid ""
"The command line interface utility for AiiDA is called ``verdi``. This "
"section explains the basic concepts that apply to all ``verdi`` commands."
msgstr ""

#: ../docs/source/topics/cli.rst:14
msgid "Parameters"
msgstr ""

#: ../docs/source/topics/cli.rst:15
msgid "Parameters to ``verdi`` commands come in two flavors:"
msgstr ""

#: ../docs/source/topics/cli.rst:17
msgid ""
"Arguments: positional parameters, e.g. ``123`` in ``verdi process kill 123``"
msgstr ""

#: ../docs/source/topics/cli.rst:18
msgid ""
"Options: announced by a flag (e.g. ``-f`` or ``--flag``), potentially "
"followed by a value. E.g. ``verdi process list --limit 10`` or ``verdi "
"process -h``."
msgstr ""

#: ../docs/source/topics/cli.rst:23
msgid "Multi-value options"
msgstr ""

#: ../docs/source/topics/cli.rst:25
msgid ""
"Some ``verdi`` commands provide *options* that can take multiple values. "
"This allows to avoid repetition and e.g. write::"
msgstr ""

#: ../docs/source/topics/cli.rst:30
msgid "instead of the more lengthy::"
msgstr ""

#: ../docs/source/topics/cli.rst:34
msgid ""
"Note the use of the so-called 'endopts' marker ``--`` that is necessary to "
"mark the end of the ``-N`` option and distinguish it from the "
"``archive.aiida`` argument."
msgstr ""

#: ../docs/source/topics/cli.rst:40
msgid "Help strings"
msgstr ""

#: ../docs/source/topics/cli.rst:41
msgid ""
"Append the ``--help`` option to any verdi (sub-)command to get help on how "
"to use it. For example, ``verdi process kill --help`` shows::"
msgstr ""

#: ../docs/source/topics/cli.rst:55
msgid "All help strings consist of three parts:"
msgstr ""

#: ../docs/source/topics/cli.rst:57
msgid "A ``Usage:`` line describing how to invoke the command"
msgstr ""

#: ../docs/source/topics/cli.rst:58
msgid "A description of the command's functionality"
msgstr ""

#: ../docs/source/topics/cli.rst:59
msgid "A list of the available options"
msgstr ""

#: ../docs/source/topics/cli.rst:61
msgid ""
"The ``Usage:`` line encodes information on the command's parameters, e.g.:"
msgstr ""

#: ../docs/source/topics/cli.rst:63
msgid "``[OPTIONS]``: this command takes one (or more) options"
msgstr ""

#: ../docs/source/topics/cli.rst:64
msgid ""
"``PROCESSES``: this command *requires* a process as a positional argument"
msgstr ""

#: ../docs/source/topics/cli.rst:65
msgid ""
"``[PROCESSES]``: this command takes a process as an *optional* positional "
"argument"
msgstr ""

#: ../docs/source/topics/cli.rst:66
msgid ""
"``[PROCESSES]...``: this command takes one or more processes as *optional* "
"positional arguments"
msgstr ""

#: ../docs/source/topics/cli.rst:68
msgid ""
"Multi-value options are followed by ``...`` in the help string and the "
"``Usage:`` line of the corresponding command will contain the 'endopts' "
"marker. For example::"
msgstr ""

#: ../docs/source/topics/cli.rst:91
msgid "Profile"
msgstr ""

#: ../docs/source/topics/cli.rst:92
msgid ""
"AiiDA supports multiple profiles per installation, one of which is marked as"
" the default and used unless another profile is requested. Show the current "
"default profile using::"
msgstr ""

#: ../docs/source/topics/cli.rst:97
msgid ""
"In order to use a different profile, pass the ``-p/--profile`` option to any"
" ``verdi`` command, for example::"
msgstr ""

#: ../docs/source/topics/cli.rst:101
msgid ""
"Note that the specified profile will be used for this and *only* this "
"command. Use ``verdi profile setdefault`` in order to permanently change the"
" default profile."
msgstr ""

#: ../docs/source/topics/cli.rst:108
msgid "Identifiers"
msgstr ""

#: ../docs/source/topics/cli.rst:110
msgid ""
"When working with AiiDA entities, you need a way to *refer* to them on the "
"command line. Any entity in AiiDA can be addressed via three identifiers:"
msgstr ""

#: ../docs/source/topics/cli.rst:113
msgid ""
"\"Primary Key\" (PK): An integer, e.g. ``723``, identifying your entity "
"within your database (automatically assigned)"
msgstr ""

#: ../docs/source/topics/cli.rst:114
msgid ""
"`Universally Unique Identifier "
"<https://en.wikipedia.org/wiki/Universally_unique_identifier#Version_4_(random)>`_"
" (UUID): A string, e.g. ``ce81c420-7751-48f6-af8e-eb7c6a30cec3`` identifying"
" your entity globally (automatically assigned)"
msgstr ""

#: ../docs/source/topics/cli.rst:115
msgid ""
"Label: A human-readable string, e.g. ``test_calculation`` (manually "
"assigned)"
msgstr ""

#: ../docs/source/topics/cli.rst:119
msgid ""
"PKs are easy to type and work as long as you stay within your database. "
"**When sharing data with others, however, always use UUIDs.**"
msgstr ""

#: ../docs/source/topics/cli.rst:122
msgid ""
"Any ``verdi`` command that expects an identifier as a paramter will accept "
"PKs, UUIDs and labels."
msgstr ""

#: ../docs/source/topics/cli.rst:124
msgid ""
"In almost all cases, this will work out of the box. Since command line "
"parameters are passed as strings, AiiDA needs to deduce the type of "
"identifier from its content, which can fail in edge cases (see "
":ref:`topics:cli:identifier_resolution` for details). You can take the "
"following precautions in order to avoid such edge cases:"
msgstr ""

#: ../docs/source/topics/cli.rst:128
msgid "PK: no precautions needed"
msgstr ""

#: ../docs/source/topics/cli.rst:129
msgid ""
"UUID: no precautions needed for full UUIDs. Partial UUIDs should include at "
"least one non-numeric character or dash"
msgstr ""

#: ../docs/source/topics/cli.rst:130
msgid ""
"Label: add an exclamation mark ``!`` at the end of the identifier in order "
"to force interpretation as a label"
msgstr ""

#: ../docs/source/topics/cli.rst:136
msgid "Implementation of identifier resolution"
msgstr ""

#: ../docs/source/topics/cli.rst:138
msgid "The logic for deducing the identifier type is as follows:"
msgstr ""

#: ../docs/source/topics/cli.rst:140
msgid "Try interpreting the identifier as a PK (integer)"
msgstr ""

#: ../docs/source/topics/cli.rst:141
msgid ""
"If this fails, try interpreting the identifier as a UUID (full or partial)"
msgstr ""

#: ../docs/source/topics/cli.rst:142
msgid "If this fails, interpret the identifier as a label"
msgstr ""

#: ../docs/source/topics/cli.rst:144
msgid ""
"The following example illustrates edge cases that can arise in this logic:"
msgstr ""

#: ../docs/source/topics/cli.rst:147
msgid "PK"
msgstr ""

#: ../docs/source/topics/cli.rst:147
msgid "UUID"
msgstr ""

#: ../docs/source/topics/cli.rst:147
msgid "LABEL"
msgstr ""

#: ../docs/source/topics/cli.rst:149 ../docs/source/topics/cli.rst:150
msgid "10"
msgstr ""

#: ../docs/source/topics/cli.rst:149
msgid "12dfb104-7b2b-4bca-adc0-1e4fd4ffcc88"
msgstr ""

#: ../docs/source/topics/cli.rst:149
msgid "group"
msgstr ""

#: ../docs/source/topics/cli.rst:150
msgid "11"
msgstr ""

#: ../docs/source/topics/cli.rst:150
msgid "deadbeef-62ba-444f-976d-31d925dac557"
msgstr ""

#: ../docs/source/topics/cli.rst:151
msgid "12"
msgstr ""

#: ../docs/source/topics/cli.rst:151
msgid "3df34a1e-5215-4e1a-b626-7f75b9586ef5"
msgstr ""

#: ../docs/source/topics/cli.rst:151
msgid "deadbeef"
msgstr ""

#: ../docs/source/topics/cli.rst:154
msgid ""
"trying to identify the first entity by its partial UUID ``12`` would match "
"the third entity by its PK instead"
msgstr ""

#: ../docs/source/topics/cli.rst:155
msgid ""
"trying to identify the second entity by its label ``10`` would match the "
"first entity by its PK instead"
msgstr ""

#: ../docs/source/topics/cli.rst:156
msgid ""
"trying to identify the third entity by its label ``deadbeef`` would match "
"the second entity on its partial UUID ``deadbeef`` instead"
msgstr ""

#: ../docs/source/topics/cli.rst:158
msgid ""
"The ambiguity between a partial UUID and a PK can always be resolved by "
"including a longer substring of the UUID, eventually rendering the "
"identifier no longer a valid PK."
msgstr ""

#: ../docs/source/topics/cli.rst:160
msgid ""
"The case of a label being also a valid PK or (partial) UUID requires a "
"different solution. For this case, ``verdi`` reserves a special character, "
"the exclamation mark ``!``, that can be appended to the identifier. Before "
"any type guessing is done, AiiDA checks for the presence of this marker and,"
" if found, will interpret the identifier as a label. I.e. to solve ambiguity"
" examples mentioned above, one would pass ``10!`` and ``deadbeef!``."
msgstr ""

#: ../docs/source/topics/database.rst:5
msgid "Database"
msgstr ""

#: ../docs/source/topics/database.rst:7 ../docs/source/topics/index.rst:16
msgid "Todo"
msgstr ""

#: ../docs/source/topics/database.rst:15
msgid "Advanced querying"
msgstr ""

#: ../docs/source/topics/database.rst:17
msgid ""
"The basics on using the :class:`~aiida.orm.querybuilder.QueryBuilder` to "
"find the data you are interested in is explained in the :ref:`finding and "
"querying how-to<how-to:data:find>`. This section explains some more advanced"
" methods for querying your database and the :ref:`queryhelp "
"dictionary<topics:database:advancedquery>`."
msgstr ""

#: ../docs/source/topics/database.rst:23
msgid "Working with edges"
msgstr ""

#: ../docs/source/topics/database.rst:25
msgid ""
"Filters and projections can be applied to both the vertices of the query "
"path and the edges that connect them. Applying a filter or projection to an "
"edge works the same way as for vertices, but the relevant keyword is now "
"preceded by ``edge_``. Using the ``ArithmeticAddCalculation`` calculation "
"job as an example, let's say we want to query for the first input of the "
"addition, i.e. the ``Int`` nodes which have been provided as the input with "
"label ``x``:"
msgstr ""

#: ../docs/source/topics/database.rst:36
msgid ""
"By using the ``edge_filters`` keyword argument, we can query for only the "
"inputs that have the label ``x``. Note that any operator that can be used to"
" filter vertices can also be applied to edges. Say we want to find all input"
" ``Int`` nodes that are **not** connected to the ``CalcJobNode``'s via an "
"edge with label ``x``:"
msgstr ""

#: ../docs/source/topics/database.rst:46
msgid ""
"Here, the equality operator ``==`` is negated by prepending an exclamation "
"mark ``!``. See the :ref:`reference table "
"below<topics:database:advancedquery:tables:operators>` for a table with all "
"operators. Similar to filters, we can *project* information of the edge "
"using the ``edge_project`` keyword argument:"
msgstr ""

#: ../docs/source/topics/database.rst:56
msgid ""
"In the example above, we are querying for the edge labels of the incoming "
"``Int`` nodes of all ``CalcJobNode``'s."
msgstr ""

#: ../docs/source/topics/database.rst:61
msgid "Ordering and limiting results"
msgstr ""

#: ../docs/source/topics/database.rst:63
msgid ""
"You can order the results of your query by the properties of the entity. Say"
" you want to return the list of ``Int`` outputs from all ``CalcJobNode``'s, "
"sorted by the time they were created in *descending* order, i.e. the most "
"recent first:"
msgstr ""

#: ../docs/source/topics/database.rst:73
msgid ""
"This can also be used to order your results based on values in a (nested) "
"dictionary, such as the ``attributes`` column. However, as the "
":class:`~aiida.orm.querybuilder.QueryBuilder` cannot infer the type of the "
"value in this case, you have to *cast* the type:"
msgstr ""

#: ../docs/source/topics/database.rst:83
msgid ""
"The query above will return all ``Int`` nodes that are output of all "
"``CalcJobNode``'s, in *ascending* order of their value, i.e. from small to "
"big. Note that in this case you have to specify the order operation with a "
"dictionary, where the ``order`` key details how you want to order the query "
"results and the ``cast`` key informs the ``QueryBuilder`` of the attribute "
"type. A list of the available cast types and their aliases can be found in "
"the table below:"
msgstr ""

#: ../docs/source/topics/database.rst:90
msgid "**Python type**"
msgstr ""

#: ../docs/source/topics/database.rst:90
msgid "**Alias**"
msgstr ""

#: ../docs/source/topics/database.rst:90
msgid "**SQLAlchemy type**"
msgstr ""

#: ../docs/source/topics/database.rst:92
msgid "int"
msgstr ""

#: ../docs/source/topics/database.rst:92
msgid "i"
msgstr ""

#: ../docs/source/topics/database.rst:92
msgid "Integer"
msgstr ""

#: ../docs/source/topics/database.rst:94
msgid "float"
msgstr ""

#: ../docs/source/topics/database.rst:94
msgid "f"
msgstr ""

#: ../docs/source/topics/database.rst:94
msgid "Float"
msgstr ""

#: ../docs/source/topics/database.rst:96
msgid "bool"
msgstr ""

#: ../docs/source/topics/database.rst:96
msgid "b"
msgstr ""

#: ../docs/source/topics/database.rst:96
msgid "Boolean"
msgstr ""

#: ../docs/source/topics/database.rst:98
msgid "str"
msgstr ""

#: ../docs/source/topics/database.rst:98
msgid "t"
msgstr ""

#: ../docs/source/topics/database.rst:98
msgid "String"
msgstr ""

#: ../docs/source/topics/database.rst:100
#: ../docs/source/topics/database.rst:168
msgid "dict"
msgstr ""

#: ../docs/source/topics/database.rst:100
msgid "j"
msgstr ""

#: ../docs/source/topics/database.rst:100
msgid "JSONB"
msgstr ""

#: ../docs/source/topics/database.rst:102
msgid "datetime.datetime"
msgstr ""

#: ../docs/source/topics/database.rst:102
msgid "d"
msgstr ""

#: ../docs/source/topics/database.rst:102
msgid "DateTime"
msgstr ""

#: ../docs/source/topics/database.rst:105
msgid ""
"You can also order using multiple properties by providing a list of "
"dictionaries that each specify one sorting operation:"
msgstr ""

#: ../docs/source/topics/database.rst:114
msgid ""
"Here the ``Int`` nodes will first be sorted by their value in ascending "
"order. Nodes for which the value is equal are subsequently sorted by their "
"modification time in descending order."
msgstr ""

#: ../docs/source/topics/database.rst:117
msgid ""
"Finally, you can also limit the number of query results returned with the "
"``limit()`` method. Suppose you only want the first three results from our "
"query:"
msgstr ""

#: ../docs/source/topics/database.rst:126
msgid ""
"This can be easily combined with the ``order_by`` method in order to get the"
" last three ``CalcJobNode``'s that were created in the database:"
msgstr ""

#: ../docs/source/topics/database.rst:138
msgid "Reference tables"
msgstr ""

#: ../docs/source/topics/database.rst:142
msgid "List of all operators:"
msgstr ""

#: ../docs/source/topics/database.rst:145
msgid "**Operator**"
msgstr ""

#: ../docs/source/topics/database.rst:145
msgid "**Datatype**"
msgstr ""

#: ../docs/source/topics/database.rst:145
msgid "**Example**"
msgstr ""

#: ../docs/source/topics/database.rst:145
msgid "Explanation"
msgstr ""

#: ../docs/source/topics/database.rst:147
msgid "``==``"
msgstr ""

#: ../docs/source/topics/database.rst:147
#: ../docs/source/topics/database.rst:149
msgid "all"
msgstr ""

#: ../docs/source/topics/database.rst:147
msgid "``'id': {'==': 123}``"
msgstr ""

#: ../docs/source/topics/database.rst:147
msgid "Filter for equality"
msgstr ""

#: ../docs/source/topics/database.rst:149
msgid "``in``"
msgstr ""

#: ../docs/source/topics/database.rst:149
msgid "``'name': {'in': ['foo', 'bar']}``"
msgstr ""

#: ../docs/source/topics/database.rst:149
msgid "Filter for values that are in the given list."
msgstr ""

#: ../docs/source/topics/database.rst:151
msgid "``>,<,<=,>=``"
msgstr ""

#: ../docs/source/topics/database.rst:151
msgid "float, integer, date"
msgstr ""

#: ../docs/source/topics/database.rst:151
msgid "``'ctime': {'<': datetime(2016, 03, 03)}``"
msgstr ""

#: ../docs/source/topics/database.rst:151
msgid "Filter for values that are greater or smaller than a certain value"
msgstr ""

#: ../docs/source/topics/database.rst:155
msgid "``like``"
msgstr ""

#: ../docs/source/topics/database.rst:155
#: ../docs/source/topics/database.rst:160
msgid "string"
msgstr ""

#: ../docs/source/topics/database.rst:155
msgid "``'name': {'like': 'label%'}``"
msgstr ""

#: ../docs/source/topics/database.rst:155
msgid ""
"Filter for matching substrings where ``%`` and ``_`` are wildcards. To match"
" a literal ``%`` or ``_`` escape it by prefixing it with ``\\\\``."
msgstr ""

#: ../docs/source/topics/database.rst:160
msgid "``ilike``"
msgstr ""

#: ../docs/source/topics/database.rst:160
msgid "``'name': {'ilike': 'lAbEl%'}``"
msgstr ""

#: ../docs/source/topics/database.rst:160
msgid "Case insensitive version of ``like``."
msgstr ""

#: ../docs/source/topics/database.rst:162
msgid "``or``"
msgstr ""

#: ../docs/source/topics/database.rst:162
#: ../docs/source/topics/database.rst:165
msgid "list of expressions"
msgstr ""

#: ../docs/source/topics/database.rst:162
msgid "``'id': {'or': [{'<': 12}, {'==': 199}]}``"
msgstr ""

#: ../docs/source/topics/database.rst:162
msgid "A list of expressions where at least one should be matched."
msgstr ""

#: ../docs/source/topics/database.rst:165
msgid "``and``"
msgstr ""

#: ../docs/source/topics/database.rst:165
msgid "``'id': {'and': [{'<': 12}, {'>': 1}]}``"
msgstr ""

#: ../docs/source/topics/database.rst:165
msgid "A list of expressions where all should be matched."
msgstr ""

#: ../docs/source/topics/database.rst:168
msgid "``has_key``"
msgstr ""

#: ../docs/source/topics/database.rst:168
msgid "``'attributes': {'has_key': 'some_key'}``"
msgstr ""

#: ../docs/source/topics/database.rst:168
msgid "Filter for dictionaries that contain a certain key."
msgstr ""

#: ../docs/source/topics/database.rst:170
msgid "``of_type``"
msgstr ""

#: ../docs/source/topics/database.rst:170
msgid "any"
msgstr ""

#: ../docs/source/topics/database.rst:170
msgid "``'attributes.some_key': {'of_type': 'bool'}``"
msgstr ""

#: ../docs/source/topics/database.rst:170
msgid "Filter for values of a certain type."
msgstr ""

#: ../docs/source/topics/database.rst:172
msgid "``of_length``"
msgstr ""

#: ../docs/source/topics/database.rst:172
#: ../docs/source/topics/database.rst:174
#: ../docs/source/topics/database.rst:176
#: ../docs/source/topics/database.rst:178
msgid "lists"
msgstr ""

#: ../docs/source/topics/database.rst:172
msgid "``'attributes.some_list': {'of_length': 4}``"
msgstr ""

#: ../docs/source/topics/database.rst:172
msgid "Filter for lists of a certain length."
msgstr ""

#: ../docs/source/topics/database.rst:174
msgid "``shorter``"
msgstr ""

#: ../docs/source/topics/database.rst:174
msgid "``'attributes.some_list': {'shorter': 4}``"
msgstr ""

#: ../docs/source/topics/database.rst:174
msgid "Filter for lists that are shorter than a certain length."
msgstr ""

#: ../docs/source/topics/database.rst:176
msgid "``longer``"
msgstr ""

#: ../docs/source/topics/database.rst:176
msgid "``'attributes.some_list': {'longer': 4}``"
msgstr ""

#: ../docs/source/topics/database.rst:176
msgid "Filter for lists that are longer than a certain length."
msgstr ""

#: ../docs/source/topics/database.rst:178
msgid "``contains``"
msgstr ""

#: ../docs/source/topics/database.rst:178
msgid "``'attributes.some_key': {'contains': ['a', 'b']}``"
msgstr ""

#: ../docs/source/topics/database.rst:178
msgid "Filter for lists that should contain certain values."
msgstr ""

#: ../docs/source/topics/database.rst:183
msgid "List of all relationships:"
msgstr ""

#: ../docs/source/topics/database.rst:186
msgid "**Entity from**"
msgstr ""

#: ../docs/source/topics/database.rst:186
msgid "**Entity to**"
msgstr ""

#: ../docs/source/topics/database.rst:186
msgid "**Relationship**"
msgstr ""

#: ../docs/source/topics/database.rst:186
msgid "**Explanation**"
msgstr ""

#: ../docs/source/topics/database.rst:188
#: ../docs/source/topics/database.rst:188
#: ../docs/source/topics/database.rst:190
#: ../docs/source/topics/database.rst:190
#: ../docs/source/topics/database.rst:192
#: ../docs/source/topics/database.rst:192
#: ../docs/source/topics/database.rst:194
#: ../docs/source/topics/database.rst:194
#: ../docs/source/topics/database.rst:196
#: ../docs/source/topics/database.rst:198
#: ../docs/source/topics/database.rst:200
#: ../docs/source/topics/database.rst:202
#: ../docs/source/topics/database.rst:204
#: ../docs/source/topics/database.rst:206
#: ../docs/source/topics/database.rst:212
#: ../docs/source/topics/database.rst:217
msgid "Node"
msgstr ""

#: ../docs/source/topics/database.rst:188
msgid "*with_outgoing*"
msgstr ""

#: ../docs/source/topics/database.rst:188
msgid "One node as input of another node"
msgstr ""

#: ../docs/source/topics/database.rst:190
msgid "*with_incoming*"
msgstr ""

#: ../docs/source/topics/database.rst:190
msgid "One node as output of another node"
msgstr ""

#: ../docs/source/topics/database.rst:192
msgid "*with_descendants*"
msgstr ""

#: ../docs/source/topics/database.rst:192
msgid "One node as the ancestor of another node (Path)"
msgstr ""

#: ../docs/source/topics/database.rst:194
msgid "*with_ancestors*"
msgstr ""

#: ../docs/source/topics/database.rst:194
msgid "One node as descendant of another node (Path)"
msgstr ""

#: ../docs/source/topics/database.rst:196
#: ../docs/source/topics/database.rst:198
#: ../docs/source/topics/database.rst:208
#: ../docs/source/topics/database.rst:210
msgid "Group"
msgstr ""

#: ../docs/source/topics/database.rst:196
#: ../docs/source/topics/database.rst:200
#: ../docs/source/topics/database.rst:204
#: ../docs/source/topics/database.rst:212
msgid "*with_node*"
msgstr ""

#: ../docs/source/topics/database.rst:196
msgid "The group of a node"
msgstr ""

#: ../docs/source/topics/database.rst:198
#: ../docs/source/topics/database.rst:210
msgid "*with_group*"
msgstr ""

#: ../docs/source/topics/database.rst:198
msgid "The node is a member of a group"
msgstr ""

#: ../docs/source/topics/database.rst:200
#: ../docs/source/topics/database.rst:202
msgid "Computer"
msgstr ""

#: ../docs/source/topics/database.rst:200
msgid "The computer of a node"
msgstr ""

#: ../docs/source/topics/database.rst:202
msgid "*with_computer*"
msgstr ""

#: ../docs/source/topics/database.rst:202
msgid "The node of a computer"
msgstr ""

#: ../docs/source/topics/database.rst:204
#: ../docs/source/topics/database.rst:206
#: ../docs/source/topics/database.rst:208
#: ../docs/source/topics/database.rst:210
#: ../docs/source/topics/database.rst:219
#: ../docs/source/topics/database.rst:221
msgid "User"
msgstr ""

#: ../docs/source/topics/database.rst:204
msgid "The creator of a node is a user"
msgstr ""

#: ../docs/source/topics/database.rst:206
#: ../docs/source/topics/database.rst:208
#: ../docs/source/topics/database.rst:219
msgid "*with_user*"
msgstr ""

#: ../docs/source/topics/database.rst:206
#: ../docs/source/topics/database.rst:208
#: ../docs/source/topics/database.rst:210
msgid "The node was created by a user"
msgstr ""

#: ../docs/source/topics/database.rst:212
msgid "Log"
msgstr ""

#: ../docs/source/topics/database.rst:212
msgid "The log of a node"
msgstr ""

#: ../docs/source/topics/database.rst:214
msgid "Log Node"
msgstr ""

#: ../docs/source/topics/database.rst:214
msgid "Node Comment"
msgstr ""

#: ../docs/source/topics/database.rst:214
msgid "*with_log* *with_node*"
msgstr ""

#: ../docs/source/topics/database.rst:214
msgid "The node has a log The comment of a node"
msgstr ""

#: ../docs/source/topics/database.rst:217
#: ../docs/source/topics/database.rst:219
#: ../docs/source/topics/database.rst:221
msgid "Comment"
msgstr ""

#: ../docs/source/topics/database.rst:217
#: ../docs/source/topics/database.rst:221
msgid "*with_comment*"
msgstr ""

#: ../docs/source/topics/database.rst:217
msgid "The node has a comment"
msgstr ""

#: ../docs/source/topics/database.rst:219
msgid "The comment was created by a user"
msgstr ""

#: ../docs/source/topics/database.rst:221
msgid "The creator of a comment is a user"
msgstr ""

#: ../docs/source/topics/database.rst:227
msgid "The queryhelp"
msgstr ""

#: ../docs/source/topics/database.rst:229
msgid ""
"The ``queryhelp`` dictionary is a property of the "
":class:`~aiida.orm.querybuilder.QueryBuilder` class. Once you have built "
"your query using the appender method explained in the :ref:`finding and "
"querying for data how-to<how-to:data:find>` and the advanced sections above,"
" you can easily store your query by saving the ``QueryBuilder.queryhelp`` "
"dictionary as a JSON file for later use:"
msgstr ""

#: ../docs/source/topics/database.rst:243
msgid ""
"To use the queryhelp to instantiate the "
":class:`~aiida.orm.querybuilder.QueryBuilder`, you can use `Python's "
"automatic keyword expansion "
"<https://docs.python.org/3/tutorial/controlflow.html#unpacking-argument-"
"lists>`_:"
msgstr ""

#: ../docs/source/topics/database.rst:252
msgid ""
"Alternatively, you can also use the ``queryhelp`` to set up your query by "
"specifying the path, filters and projections and constructing the "
"``queryhelp`` dictionary by hand. To do this, you have to specify:"
msgstr ""

#: ../docs/source/topics/database.rst:255
msgid ""
"the ``path``: Here, the user specifies the path along which to join tables "
"as a list of dictionaries, where each list item identifies a vertex in your "
"path. You define the vertex class with the ``cls`` key::"
msgstr ""

#: ../docs/source/topics/database.rst:265
msgid ""
"Each entity in the query has to have a unique tag. If the tag is not "
"provided, it is set to the name of the class. However, this will not work if"
" you choose the same class twice in the query. In this case you have to "
"provide the tag using the ``tag`` key::"
msgstr ""

#: ../docs/source/topics/database.rst:283
msgid ""
"You also have to detail some information on the vertex edges, in order to "
"connect them correctly. There are several redundant ways this can be done:"
msgstr ""

#: ../docs/source/topics/database.rst:286
msgid ""
"You can specify that this node is an input or output of another node "
"preceding the current one in the list. That other node can be specified by "
"an integer or the class or type. The following examples are all valid "
"joining instructions, assuming there is a structure defined at index 2 of "
"the path with tag \"struc1\"::"
msgstr ""

#: ../docs/source/topics/database.rst:298
msgid "queryhelp_item['direction'] = integer"
msgstr ""

#: ../docs/source/topics/database.rst:300
msgid ""
"If any of the above specs (\"with_outgoing\", \"with_incoming\") were not "
"specified, the key \"direction\" is looked for. Directions are defined as "
"distances in the tree. 1 is defined as one step down the tree along a link. "
"This means that 1 joins the node specified in this dictionary to the node "
"specified on list-item before **as an output**. Direction defaults to 1, "
"which is why, if nothing is specified, this node is joined to the previous "
"one as an output by default. A negative number reverse the direction of the "
"link. The absolute value of the direction defines the table to join to with "
"respect to your own position in the list. An absolute value of 1 joins one "
"table above, a value of 2 to the table defined 2 indices above. The two "
"following queryhelps yield the same query::"
msgstr ""

#: ../docs/source/topics/database.rst:355
msgid "what to ``project``: Determing which columns the query will return::"
msgstr ""

#: ../docs/source/topics/database.rst:364
msgid ""
"If you are using JSONB columns, you can also project a value stored inside "
"the json::"
msgstr ""

#: ../docs/source/topics/database.rst:376
msgid ""
"Returns the state and the id of all instances of ``PwCalculation`` where a "
"structures is linked as output of a relax-calculation. The strings that you "
"pass have to be name of the columns. If you pass an asterisk ('*'), the "
"query will return the instance of the AiidaClass."
msgstr ""

#: ../docs/source/topics/database.rst:380
msgid ""
"the ``filters``: Filters enable you to further specify the query. This is an"
" example for a query for structures that were added after a certain time "
"(say last 4 days) and have an id larger than 50::"
msgstr ""

#: ../docs/source/topics/database.rst:400
msgid ""
"If you want to include filters and projections on links between nodes, you "
"will have to add these to filters and projections in the queryhelp. Let's "
"take an example from before and add a few filters on the link::"
msgstr ""

#: ../docs/source/topics/database.rst:423
msgid ""
"Notice that the tag for the link, by default, is the tag of the two "
"connecting nodes delimited by two dashes '--' and the order DOES matter."
msgstr ""

#: ../docs/source/topics/database.rst:425
msgid ""
"Alternatively, you can choose the tag for the edge in the path when defining"
" the entity to join using ``edge_tag``::"
msgstr ""

#: ../docs/source/topics/database.rst:451
msgid "Limits and offset can be set directly like this::"
msgstr ""

#: ../docs/source/topics/database.rst:459
msgid ""
"That queryhelp would tell the QueryBuilder to return 10 rows after the first"
" 20 have been skipped."
msgstr ""

#: ../docs/source/topics/index.rst:3
msgid "Topics"
msgstr ""

#: ../docs/source/topics/index.rst:18
msgid "daemon  // after provenance repository // after database"
msgstr ""

#: ../docs/source/topics/plugins.rst:5
msgid "Plugins"
msgstr ""

#: ../docs/source/topics/plugins.rst:10
msgid "What a plugin can do"
msgstr ""

#: ../docs/source/topics/plugins.rst:12
msgid ""
"Add a new class to AiiDA's :ref:`entry point groups "
"<topics:plugins:entrypointgroups>`, including:: calculations, parsers, "
"workflows, data types, verdi commands, schedulers, transports and "
"importers/exporters from external databases. This typically involves "
"subclassing the respective base class AiiDA provides for that purpose."
msgstr ""

#: ../docs/source/topics/plugins.rst:14
msgid "Install new commandline and/or GUI executables"
msgstr ""

#: ../docs/source/topics/plugins.rst:15
msgid ""
"Depend on, and build on top of any number of other plugins (as long as their"
" requirements do not clash)"
msgstr ""

#: ../docs/source/topics/plugins.rst:21
msgid "What a plugin should not do"
msgstr ""

#: ../docs/source/topics/plugins.rst:23
msgid "An AiiDA plugin should not:"
msgstr ""

#: ../docs/source/topics/plugins.rst:25
msgid "Change the database schema AiiDA uses"
msgstr ""

#: ../docs/source/topics/plugins.rst:26
msgid ""
"Use protected functions, methods or classes of AiiDA (those starting with an"
" underscore ``_``)"
msgstr ""

#: ../docs/source/topics/plugins.rst:27
msgid ""
"Monkey patch anything within the ``aiida`` namespace (or the namespace "
"itself)"
msgstr ""

#: ../docs/source/topics/plugins.rst:29
msgid ""
"Failure to comply will likely prevent your plugin from being listed on the "
"official `AiiDA plugin registry <registry>`_."
msgstr ""

#: ../docs/source/topics/plugins.rst:31
msgid ""
"If you find yourself in a situation where you feel like you need to do any "
"of the above, please open an issue on the `AiiDA repository <core>`_ and we "
"can try to advise on how to proceed."
msgstr ""

#: ../docs/source/topics/plugins.rst:41
msgid "What is an entry point?"
msgstr ""

#: ../docs/source/topics/plugins.rst:44
msgid ""
"The ``setuptools`` package (used by ``pip``) has a feature called `entry "
"points`_, which allows to associate a string (the entry point *identifier*) "
"with any python object defined inside a python package. Entry points are "
"defined in the ``setup.py`` file, for example::"
msgstr ""

#: ../docs/source/topics/plugins.rst:56
msgid ""
"Here, we add a new entry point ``mycode.mydata`` to the entry point *group* "
"``aiida.data``. The entry point identifier points to the ``MyData`` class "
"inside the file ``mydata.py``, which is part of the ``aiida_mycode`` "
"package."
msgstr ""

#: ../docs/source/topics/plugins.rst:59
msgid ""
"When installing a python package that defines entry points, the entry point "
"specifications are written to a file inside the distribution's ``.egg-info``"
" folder. ``setuptools`` provides a package ``pkg_resources`` for querying "
"these entry point specifications by distribution, by entry point group "
"and/or by name of the entry point and load the data structure to which it "
"points."
msgstr ""

#: ../docs/source/topics/plugins.rst:63
msgid "Why entry points?"
msgstr ""

#: ../docs/source/topics/plugins.rst:65
msgid ""
"AiiDA defines a set of entry point groups (see "
":ref:`topics:plugins:entrypointgroups` below). By inspecting the entry "
"points added to these groups by AiiDA plugins, AiiDA can offer uniform "
"interfaces to interact with them. For example:"
msgstr ""

#: ../docs/source/topics/plugins.rst:69
msgid ""
"``verdi plugin list aiida.workflows`` provides an overview of all workflows "
"installed by AiiDA plugins. Users can inspect the inputs/outputs of each "
"workflow using the same command without having to study the documentation of"
" the plugin."
msgstr ""

#: ../docs/source/topics/plugins.rst:71
msgid ""
"The ``DataFactory``, ``CalculationFactory`` and ``WorkflowFactory`` methods "
"allow instantiating new classes through a simple short string (e.g. "
"``quantumespresso.pw``). Users don't need to remember exactly where in the "
"plugin package the class resides, and plugins can be refactored without "
"users having to re-learn the plugin's API."
msgstr ""

#: ../docs/source/topics/plugins.rst:78
msgid "AiiDA entry point groups"
msgstr ""

#: ../docs/source/topics/plugins.rst:80
msgid ""
"Below, we list the entry point groups defined and searched by AiiDA. You can"
" get the same list as the output of ``verdi plugin list``."
msgstr ""

#: ../docs/source/topics/plugins.rst:84
msgid "``aiida.calculations``"
msgstr ""

#: ../docs/source/topics/plugins.rst:86
msgid ""
"Entry points in this group are expected to be subclasses of "
":py:class:`aiida.orm.JobCalculation "
"<aiida.orm.nodes.process.calculation.calcjob.CalcJobNode>`. This replaces "
"the previous method of placing a python module with the class in question "
"inside the ``aiida/orm/calculation/job`` subpackage."
msgstr ""

#: ../docs/source/topics/plugins.rst:88
msgid "Example entry point specification::"
msgstr ""

#: ../docs/source/topics/plugins.rst:96
msgid "``aiida_mycode/calcs/mycode.py``::"
msgstr ""

#: ../docs/source/topics/plugins.rst:102
msgid "Will lead to usage::"
msgstr ""

#: ../docs/source/topics/plugins.rst:108
msgid "``aiida.parsers``"
msgstr ""

#: ../docs/source/topics/plugins.rst:110
msgid ""
"AiiDA expects a subclass of ``Parser``. Replaces the previous approach "
"consisting in placing a parser module under ``aiida/parsers/plugins``."
msgstr ""

#: ../docs/source/topics/plugins.rst:112
msgid "Example spec::"
msgstr ""

#: ../docs/source/topics/plugins.rst:120
msgid "``aida_mycode/parsers/myparser.py``::"
msgstr ""

#: ../docs/source/topics/plugins.rst:126 ../docs/source/topics/plugins.rst:150
#: ../docs/source/topics/plugins.rst:174 ../docs/source/topics/plugins.rst:289
msgid "Usage::"
msgstr ""

#: ../docs/source/topics/plugins.rst:132
msgid "``aiida.data``"
msgstr ""

#: ../docs/source/topics/plugins.rst:134
msgid ""
"Group for :py:class:`~aiida.orm.nodes.data.data.Data` subclasses. Previously"
" located in a subpackage of ``aiida/orm/data``."
msgstr ""

#: ../docs/source/topics/plugins.rst:136 ../docs/source/topics/plugins.rst:160
#: ../docs/source/topics/plugins.rst:191 ../docs/source/topics/plugins.rst:253
#: ../docs/source/topics/plugins.rst:275
msgid "Spec::"
msgstr ""

#: ../docs/source/topics/plugins.rst:144
msgid "``aiida_mycode/data/mydat.py``::"
msgstr ""

#: ../docs/source/topics/plugins.rst:156
msgid "``aiida.workflows``"
msgstr ""

#: ../docs/source/topics/plugins.rst:158
msgid "Package AiiDA workflows as follows:"
msgstr ""

#: ../docs/source/topics/plugins.rst:168
msgid "``aiida_mycode/workflows/mywf.py``::"
msgstr ""

#: ../docs/source/topics/plugins.rst:179
msgid ""
"For old-style workflows the entry point mechanism of the plugin system is "
"not supported. Therefore one cannot load these workflows with the "
"``WorkflowFactory``. The only way to run these, is to store their source "
"code in the ``aiida/workflows/user`` directory and use normal python imports"
" to load the classes."
msgstr ""

#: ../docs/source/topics/plugins.rst:185
msgid "``aiida.cmdline``"
msgstr ""

#: ../docs/source/topics/plugins.rst:187
msgid ""
"``verdi`` uses the `click_` framework, which makes it possible to add new "
"subcommands to existing verdi commands, such as ``verdi data mydata``. AiiDA"
" expects each entry point to be either a ``click.Command`` or "
"``click.CommandGroup``."
msgstr ""

#: ../docs/source/topics/plugins.rst:199
msgid "``aiida_mycode/commands/mydata.py``::"
msgstr ""

#: ../docs/source/topics/plugins.rst:213
msgid "Usage:"
msgstr ""

#: ../docs/source/topics/plugins.rst:220
msgid "``aiida.tools.dbexporters``"
msgstr ""

#: ../docs/source/topics/plugins.rst:222
msgid ""
"If your plugin package adds support for exporting to an external database, "
"use this entry point to have aiida find the module where you define the "
"necessary functions."
msgstr ""

#: ../docs/source/topics/plugins.rst:234
msgid "``aiida.tools.dbimporters``"
msgstr ""

#: ../docs/source/topics/plugins.rst:236
msgid ""
"If your plugin package adds support for importing from an external database,"
" use this entry point to have aiida find the module where you define the "
"necessary functions."
msgstr ""

#: ../docs/source/topics/plugins.rst:249
msgid "``aiida.schedulers``"
msgstr ""

#: ../docs/source/topics/plugins.rst:251
msgid ""
"We recommend naming the plugin package after the scheduler (e.g. ``aiida-"
"myscheduler``), so that the entry point name can simply equal the name of "
"the scheduler:"
msgstr ""

#: ../docs/source/topics/plugins.rst:261
msgid "``aiida_myscheduler/myscheduler.py``::"
msgstr ""

#: ../docs/source/topics/plugins.rst:267
msgid ""
"Usage: The scheduler is used in the familiar way by entering 'myscheduler' "
"as the scheduler option when setting up a computer."
msgstr ""

#: ../docs/source/topics/plugins.rst:270
msgid "``aiida.transports``"
msgstr ""

#: ../docs/source/topics/plugins.rst:272
msgid ""
"``aiida-core`` ships with two modes of transporting files and folders to "
"remote computers: ``ssh`` and ``local`` (stub for when the remote computer "
"is actually the same). We recommend naming the plugin package after the mode"
" of transport (e.g. ``aiida-mytransport``), so that the entry point name can"
" simply equal the name of the transport:"
msgstr ""

#: ../docs/source/topics/plugins.rst:283
msgid "``aiida_mytransport/mytransport.py``::"
msgstr ""

#: ../docs/source/topics/plugins.rst:294
msgid ""
"When setting up a new computer, specify ``mytransport`` as the transport "
"mode."
msgstr ""

#: ../docs/source/topics/plugins.rst:301
msgid "Plugin test fixtures"
msgstr ""

#: ../docs/source/topics/plugins.rst:303
msgid ""
"One concern when running tests for AiiDA plugins is to separate the test "
"environment from your production environment. Typically tests should be run "
"against an empty AiiDA database."
msgstr ""

#: ../docs/source/topics/plugins.rst:306
msgid "AiiDA ships with tools that take care of this for you. They will:"
msgstr ""

#: ../docs/source/topics/plugins.rst:308
msgid "start a temporary postgres server"
msgstr ""

#: ../docs/source/topics/plugins.rst:309
msgid "create a new database"
msgstr ""

#: ../docs/source/topics/plugins.rst:310
msgid "create a temporary ``.aiida`` folder"
msgstr ""

#: ../docs/source/topics/plugins.rst:311
msgid "create a test profile"
msgstr ""

#: ../docs/source/topics/plugins.rst:312
msgid "(optional) reset the AiiDA database before every individual test"
msgstr ""

#: ../docs/source/topics/plugins.rst:314
msgid ""
"thus letting you focus on testing the functionality of your plugin without "
"having to worry about this separation."
msgstr ""

#: ../docs/source/topics/plugins.rst:317
msgid ""
"The overhead for setting up the temporary environment is of the order of a "
"few seconds and occurs only once per test session. You can control the "
"database backend for the temporary profile by setting the "
"``AIIDA_TEST_BACKEND`` environment variable, e.g. ``export "
"AIIDA_TEST_BACKEND=sqlalchemy``."
msgstr ""

#: ../docs/source/topics/plugins.rst:321
msgid ""
"If you prefer to run tests on an existing profile, say ``test_profile``, "
"simply set the following environment variable before running your tests::"
msgstr ""

#: ../docs/source/topics/plugins.rst:327
msgid ""
"In order to prevent accidental data loss, AiiDA only allows to run tests on "
"profiles whose name starts with ``test_``."
msgstr ""

#: ../docs/source/topics/plugins.rst:329
msgid ""
"AiiDA ships with a number of fixtures in "
":py:mod:`aiida.manage.tests.pytest_fixtures` for you to use."
msgstr ""

#: ../docs/source/topics/plugins.rst:331
msgid "In particular:"
msgstr ""

#: ../docs/source/topics/plugins.rst:333
msgid ""
"The :py:func:`~aiida.manage.tests.pytest_fixtures.aiida_profile` fixture "
"initializes the :py:class:`~aiida.manage.tests.TestManager` and yields it to"
" the test function. Its parameters ``scope='session', autouse=True`` cause "
"this fixture to automatically run once per test session, even if you don't "
"explicitly require it."
msgstr ""

#: ../docs/source/topics/plugins.rst:335
msgid ""
"The :py:func:`~aiida.manage.tests.pytest_fixtures.clear_database` fixture "
"depends on the :py:func:`~aiida.manage.tests.pytest_fixtures.aiida_profile` "
"fixture and tells the received :py:class:`~aiida.manage.tests.TestManager` "
"instance to reset the database. This fixture lets each test start in a fresh"
" AiiDA environment."
msgstr ""

#: ../docs/source/topics/plugins.rst:337
msgid ""
"The :py:func:`~aiida.manage.tests.pytest_fixtures.temp_dir` fixture returns "
"a temporary directory for file operations and deletes it after the test is "
"finished."
msgstr ""

#: ../docs/source/topics/plugins.rst:338
msgid ""
"... you may want to add your own fixtures tailored for your plugins to set "
"up specific ``Data`` nodes & more."
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:7
msgid ""
"Anything that runs in AiiDA is an instance of the "
":py:class:`~aiida.engine.processes.process.Process` class. The ``Process`` "
"class contains all the information and logic to tell, whoever is handling "
"it, how to run it to completion. Typically the one responsible for running "
"the processes is an instance of a :py:class:`~aiida.engine.runners.Runner`. "
"This can be a local runner or one of the daemon runners in case of the "
"daemon running the process."
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:12
msgid ""
"In addition to those run instructions, any ``Process`` that has been "
"executed needs some sort of record in the database to store what happened "
"during its execution. For example it needs to record what its exact inputs "
"were, the log messages that were reported and what the final outputs were. "
"For this purpose, every process will utilize an instance of a sub class of "
"the :py:class:`~aiida.orm.nodes.process.ProcessNode` class. This "
"``ProcessNode`` class is a sub class of :py:class:`~aiida.orm.nodes.Node` "
"and serves as the record of the process' execution in the database and by "
"extension the provenance graph."
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:17
msgid ""
"It is very important to understand this division of labor. A ``Process`` "
"describes how something should be run, and the ``ProcessNode`` serves as a "
"mere record in the database of what actually happened during execution. A "
"good thing to remember is that while it is running, we are dealing with the "
"``Process`` and when it is finished we interact with the ``ProcessNode``."
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:24
msgid "Process types"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:26
msgid "Processes in AiiDA come in two flavors:"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:28
msgid "Calculation-like"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:29
msgid "Workflow-like"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:31
msgid ""
"The calculation-like processes have the capability to *create* data, whereas"
" the workflow-like processes orchestrate other processes and have the "
"ability to *return* data produced by calculations. Again, this is a "
"distinction that plays a big role in AiiDA and is crucial to understand. For"
" this reason, these different types of processes also get a different sub "
"class of the ``ProcessNode`` class. The hierarchy of these node classes and "
"the link types that are allowed between them and ``Data`` nodes, is "
"explained in detail in the :ref:`provenance "
"implementation<topics:provenance:implementation>` documentation."
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:36
msgid ""
"Currently, there are four types of processes in ``aiida-core`` and the "
"following table shows with which node class it is represented in the "
"provenance graph and what the process is used for."
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:39
msgid "Process class"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:39
msgid "Node class"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:39
msgid "Used for"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:41
msgid ":py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob`"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:41
msgid ":py:class:`~aiida.orm.nodes.process.calculation.calcjob.CalcJobNode`"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:41
msgid "Calculations performed by external codes"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:42
msgid ":py:class:`~aiida.engine.processes.workchains.workchain.WorkChain`"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:42
msgid ":py:class:`~aiida.orm.nodes.process.workflow.workchain.WorkChainNode`"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:42
msgid "Workflows that run multiple calculations"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:43
#: ../docs/source/topics/processes/concepts.rst:44
msgid ":py:class:`~aiida.engine.processes.functions.FunctionProcess`"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:43
msgid ""
":py:class:`~aiida.orm.nodes.process.calculation.calcfunction.CalcFunctionNode`"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:43
msgid "Python functions decorated with the ``@calcfunction`` decorator"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:44
msgid ""
":py:class:`~aiida.orm.nodes.process.workflow.workfunction.WorkFunctionNode`"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:44
msgid "Python functions decorated with the ``@workfunction`` decorator"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:47
msgid ""
"For basic information on the concept of a ``CalcJob`` or ``calcfunction``, "
"refer to the :ref:`calculations concept<topics:calculations:concepts>` The "
"``WorkChain`` and ``workfunction`` are described in the :ref:`workflows "
"concept<topics:workflows:concepts>`. After having read and understood the "
"basic concept of calculation and workflow processes, detailed information on"
" how to implement and use them can be found in the dedicated developing "
"sections for :ref:`calculations<topics:calculations:usage>` and "
":ref:`workflows<topics:workflows:usage>`, respectively."
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:51
msgid ""
"A ``FunctionProcess`` is never explicitly implemented but will be generated "
"dynamically by the engine when a python function decorated with a "
":py:func:`~aiida.engine.processes.functions.calcfunction` or "
":py:func:`~aiida.engine.processes.functions.workfunction` is run."
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:57
msgid "Process state"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:58
msgid ""
"Each instance of a ``Process`` class that is being executed has a process "
"state. This property tells you about the current status of the process. It "
"is stored in the instance of the ``Process`` itself and the workflow engine,"
" the ``plumpy`` library, operates only on that value. However, the "
"``Process`` instance 'dies' as soon as it is terminated, therefore the "
"process state is also written to the calculation node that the process uses "
"as its database record, under the ``process_state`` attribute. The process "
"can be in one of six states:"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:65
msgid "*Active*"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:65
msgid "*Terminated*"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:67
msgid "Created"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:67
msgid "Killed"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:68
msgid "Running"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:68
msgid "Excepted"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:69
msgid "Waiting"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:69
msgid "Finished"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:72
msgid ""
"The three states in the left column are 'active' states, whereas the right "
"column displays the three 'terminal' states. Once a process reaches a "
"terminal state, it will never leave it; its execution is permanently "
"terminated. When a process is first created, it is put in the ``Created`` "
"state. As soon as it is picked up by a runner and it is active, it will be "
"in the ``Running`` state. If the process is waiting for another process, "
"that it called, to be finished, it will be in the ``Waiting`` state. If a "
"process is in the ``Killed`` state, it means the user issued a command to "
"kill it, or its parent process was killed. The ``Excepted`` state indicates "
"that during execution an exception occurred that was not caught and the "
"process was unexpectedly terminated. The final option is the ``Finished`` "
"state, which means that the process was successfully executed, and the "
"execution was nominal. Note that this does not automatically mean that the "
"result of the process can also be considered to be successful, it was just "
"executed without any problems."
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:82
msgid ""
"To distinguish between a successful and a failed execution, there is the "
":ref:`exit status<topics:processes:concepts:exit_codes>`. This is another "
"attribute that is stored in the node of the process and is an integer that "
"can be set by the process. A ``0`` (zero) means that the result of the "
"process was successful, and a non-zero value indicates a failure. All the "
"process nodes used by the various processes are sub-classes of "
":py:class:`~aiida.orm.nodes.process.ProcessNode`, which defines handy "
"properties to query the process state and exit status."
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:88
msgid "Property"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:88
msgid "Meaning"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:90
msgid "``process_state``"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:90
msgid "Returns the current process state"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:91
msgid "``exit_status``"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:91
msgid "Returns the exit status, or None if not set"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:92
msgid "``exit_message``"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:92
msgid "Returns the exit message, or None if not set"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:93
msgid "``is_terminated``"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:93
msgid ""
"Returns ``True`` if the process was either ``Killed``, ``Excepted``, or "
"``Finished``"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:94
msgid "``is_killed``"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:94
msgid "Returns ``True`` if the process is ``Killed``"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:95
msgid "``is_excepted``"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:95
msgid "Returns ``True`` if the process is ``Excepted``"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:96
msgid "``is_finished``"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:96
msgid "Returns ``True`` if the process is ``Finished``"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:97
msgid "``is_finished_ok``"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:97
msgid ""
"Returns ``True`` if the process is ``Finished`` and the ``exit_status`` is "
"equal to zero"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:98
msgid "``is_failed``"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:98
msgid ""
"Returns ``True`` if the process is ``Finished`` and the ``exit_status`` is "
"non-zero"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:101
msgid ""
"When you load a calculation node from the database, you can use these "
"property methods to inquire about its state and exit status."
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:107
msgid "Process exit codes"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:108
msgid ""
"The previous section about the process state showed that a process that is "
"``Finished`` does not say anything about whether the result is 'successful' "
"or 'failed'. The ``Finished`` state means nothing more than that the engine "
"succeeded in running the process to the end of execution, without it "
"encountering exceptions or being killed. To distinguish between a "
"'successful' and 'failed' process, an 'exit status' can be defined. The "
"`exit status is a common concept in programming "
"<https://en.wikipedia.org/wiki/Exit_status>`_ and is a small integer, where "
"zero means that the result of the process was successful, and a non-zero "
"value indicates a failure. By default a process that terminates nominally "
"will get a ``0`` (zero) exit status. To mark a process as failed, one can "
"return an instance of the "
":py:class:`~aiida.engine.processes.exit_code.ExitCode` named tuple, which "
"allows to set an integer ``exit_status`` and a string message as "
"``exit_message``. When the engine receives such an ``ExitCode`` as the "
"return value from a process, it will set the exit status and message on the "
"corresponding attributes of the process node representing the process in the"
" provenance graph. How exit codes can be defined and returned depends on the"
" process type and will be documented in detail in the respective "
":ref:`calculation<topics:calculations:usage>` and "
":ref:`workflow<topics:workflows:usage>` development sections."
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:121
msgid "Process lifetime"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:123
msgid ""
"The lifetime of a process is defined as the time from the moment it is "
"launched until it reaches a :ref:`terminal "
"state<topics:processes:concepts:state>`."
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:128
msgid "Process and node distinction"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:129
msgid ""
"As explained in the :ref:`introduction of this "
"section<topics:processes:concepts>`, there is a clear and important "
"distinction between the 'process' and the 'node' that represents its "
"execution in the provenance graph. When a process is launched, an instance "
"of the ``Process`` class is created in memory which will be propagated to "
"completion by the responsible runner. This 'process' instance only exists in"
" the memory of the python interpreter that it is running in, for example "
"that of a daemon runner, and so we cannot directly inspect its state. That "
"is why the process will write any of its state changes to the corresponding "
"node representing it in the provenance graph. In this way, the node acts as "
"a 'proxy' or a mirror image that reflects the state of the process in "
"memory. This means that the output of many of the ``verdi`` commands, such "
"as ``verdi process list``, do not actually show the state of the process "
"instances, but rather the state of the node to which they have last written "
"their state."
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:137
msgid "Process tasks"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:138
msgid ""
"The previous section explained how launching a process means creating an "
"instance of the ``Process`` class in memory. When the process is being 'run'"
" (see the section on :ref:`launching "
"processes<topics:processes:usage:launch>` for more details) that is to say "
"in a local interpreter, the particular process instance will die as soon as "
"the interpreter dies. This is what often makes 'submitting' the preferred "
"method of launching a process. When a process is 'submitted', an instance of"
" the ``Process`` is created, along with the node that represents it in the "
"database, and its state is then persisted (stored) in the database. This is "
"called a 'process checkpoint', more information on which :ref:`will follow "
"later<topics:processes:concepts:checkpoints>`. Subsequently, the process "
"instance is shut down and a 'continuation task' is sent to the process queue"
" of RabbitMQ. This task is simply a small message that just contains an "
"identifier for the process."
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:146
msgid ""
"All the daemon runners, when they are launched, subscribe to the process "
"queue and RabbitMQ will distribute the continuation tasks to them as they "
"come in, making sure that each task is only sent to one runner at a time. "
"The receiving daemon runner can restore the process instance in memory from "
"the checkpoint that was stored in the database and continue the execution. "
"As soon as the process reaches a terminal state, the daemon runner will "
"acknowledge to RabbitMQ that the task has been completed. Until the runner "
"has confirmed that a task is completed, RabbitMQ will consider the task as "
"incomplete. If a daemon runner is shut down or dies before it got the chance"
" to finish running a process, the task will automatically be requeued by "
"RabbitMQ and sent to another daemon runner. Together with the fact that all "
"the tasks in the process queue are persisted to disk by RabbitMQ, guarantees"
" that once a continuation task has been sent to RabbitMQ, it will at some "
"point be finished, while allowing the machine to be shut down."
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:153
msgid ""
"Each daemon runner has a maximum number of tasks that it can run "
"concurrently, which means that if there are more active tasks than available"
" slots, some of the tasks will remain queued. Processes, whose task is in "
"the queue and not with any runner, though technically 'active' as they are "
"not terminated, are not actually being run at the moment. While a process is"
" not actually being run, i.e. it is not in memory with a runner, one cannot "
"interact with it. Similarly, as soon as the task disappears, either because "
"the process was intentionally terminated (or unintentionally), the process "
"will never continue running again."
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:162
msgid "Process checkpoints"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:163
msgid ""
"A process checkpoint is a complete representation of a ``Process`` instance "
"in memory that can be stored in the database. Since it is a complete "
"representation, the ``Process`` instance can also be fully reconstructed "
"from such a checkpoint. At any state transition of a process, a checkpoint "
"will be created, by serializing the process instance and storing it as an "
"attribute on the corresponding process node. This mechanism is the final cog"
" in the machine, together with the persisted process queue of RabbitMQ as "
"explained in the previous section, that allows processes to continue after "
"the machine they were running on, has been shut down and restarted."
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:172
msgid "Process sealing"
msgstr ""

#: ../docs/source/topics/processes/concepts.rst:173
msgid ""
"One of the cardinal rules of AiiDA is that once a node is *stored*, it is "
"immutable, which means that its attributes can no longer be changed. This "
"rule is a problem for processes, however, since in order to be able to start"
" running it, its corresponding process node first has to be stored. However,"
" at that point its attributes, such as the process state or other mutable "
"attributes, can no longer be changed by the engine throughout the lifetime "
"of the corresponding process. To overcome this limitation, the concept of "
"*updatable* attributes is introduced. These are special attributes that are "
"allowed to be changed *even* when the process node is already stored *and* "
"the corresponding process is still active. To mark the point where a process"
" is terminated and even the updatable attributes on the process node are to "
"be considered immutable, the node is *sealed*. A sealed process node behaves"
" exactly like a normal stored node, as in *all* of its attributes are "
"immutable. In addition, once a process node is sealed, no more incoming or "
"outgoing links can be attached to it. Unsealed process nodes can also not be"
" exported, because they belong to processes that are still active. Note that"
" the sealing concept does not apply to data nodes and they are exportable as"
" soon as they are stored. To determine whether a process node is sealed, one"
" can use the property :py:attr:`~aiida.orm.utils.mixins.Sealable.is_sealed`."
msgstr ""

#: ../docs/source/topics/processes/functions.rst:5
msgid "Process functions"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:7
msgid ""
"A process function is a process (see the "
":ref:`concepts<topics:processes:concepts>` for a definition and explanation)"
" that is implemented as a decorated python function. Currently, there are "
"two types of process functions:"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:11
msgid ":ref:`work function<topics:workflows:concepts:workfunctions>`"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:13
msgid ""
"The former can *create* new data, whereas the latter can orchestrate other "
"processes and *return* their results. This section will provide detailed "
"information and best practices on how to implement these two process types. "
"Since the calculation function and work function are both process functions "
"and have the same implementation, all the rules explained below apply to "
"both process types."
msgstr ""

#: ../docs/source/topics/processes/functions.rst:17
msgid ""
"The simple example in the :ref:`introductory section on calculation "
"functions<topics:calculations:concepts:calcfunctions>` showed how a simple "
"python function can be turned into a calculation function simply by adorning"
" it with the :py:func:`~aiida.engine.processes.functions.calcfunction` "
"decorator. When the function is run, AiiDA will dynamically generate a "
":py:class:`~aiida.engine.processes.functions.FunctionProcess` and build its "
":ref:`process specification<topics:processes:usage:spec>` based on the "
"function signature. Here we will explain how this is accomplished and what "
"features of the python function signature standard are supported."
msgstr ""

#: ../docs/source/topics/processes/functions.rst:22
msgid "Function signatures"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:23
msgid ""
"To explain what features of python function definitions and calls are "
"supported we first need to be clear about some terminology. When dealing "
"with functions, there are two distinct parts:"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:26
msgid ""
"`function definitions "
"<https://docs.python.org/3/reference/compound_stmts.html#function-"
"definitions>`_"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:27
msgid ""
"`function calls "
"<https://docs.python.org/3/reference/expressions.html#calls>`_"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:29
msgid ""
"Consider the following code snippet that defines a simple python function:"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:34
msgid ""
"The function takes three 'parameters', named ``x``, ``y`` and ``z``. In "
"addition, the function ``plain_function`` is said to have default values, "
"because one or more parameters (``z`` in this case) have the form `parameter"
" = expression`. When *calling* a function, the terminology changes slightly "
"and values for parameters can be passed as either 'positional' or 'keyword'."
" In the example below, the function is called with 'positional' arguments:"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:42
msgid ""
"They are called positional, because the arguments are not explicitly named "
"and so will be matched to the corresponding parameter solely based on their "
"position in the function call. In this example, ``x``, ``y`` and ``z`` will "
"have the values ``1``, ``2`` and ``3``, respectively. Since we specified "
"three values, the default for the third parameter ``z`` was not actually "
"used. However, we are allowed to only specify two arguments, in which case "
"the default *will* be used as can be seen below:"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:50
msgid ""
"By not specifying the third argument, the default will be used, so in this "
"case ``z`` will equal ``1``. Additionally, one can employ 'named' arguments "
"to specifically target a parameter based on its name, instead of having to "
"rely on its position:"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:56
msgid ""
"Notice how the order in which we pass the arguments is irrelevant because we"
" specify the name of each argument explicitly when assigning the value. Now "
"that we know the difference between positional and named arguments, it is "
"important to realize a python requirement that **positional arguments have "
"to come before named arguments**. What this means is that *both* the "
"function definition and function call below are illegal, because there are "
"named arguments before positional ones:"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:63
msgid ""
"Finally, python knows the concept of ``*args`` and ``**kwargs``, also "
"referred to as variable arguments and keyword arguments, which allow one to "
"define a function which accepts an undetermined number of positional and "
"keyword arguments."
msgstr ""

#: ../docs/source/topics/processes/functions.rst:68
msgid ""
"The variable arguments ``*args`` will receive the positionally passed "
"arguments as a tuple and the keyword arguments ``**kwargs`` will receive the"
" named arguments as a dictionary. With the formal definitions out of the "
"way, let's now see which of these concepts are supported by process "
"functions."
msgstr ""

#: ../docs/source/topics/processes/functions.rst:72
msgid "Default arguments"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:73
msgid ""
"Default arguments are supported by calculation functions just as normal "
"python functions as long as it is a :py:class:`~aiida.orm.nodes.node.Node` "
"instance, just like the inputs or ``None``. However, just as with python "
"functions, one should only use immutable objects as function defaults "
"because mutable objects can give unexpected results as they will be kept "
"between function calls. Therefore, in order to use a default value for "
"process functions, simply use ``None`` as the default value and check for "
"its presence in the function body settings the default value if it is "
"``None``. This pattern looks like the following:"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:81
msgid ""
"Both function calls in the example above will have the exact same result."
msgstr ""

#: ../docs/source/topics/processes/functions.rst:84
msgid "Variable and keyword arguments"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:85
msgid ""
"Variable arguments are *not* supported by process functions. The reasoning "
"behind this is that the process specification for the "
":py:class:`~aiida.engine.processes.functions.FunctionProcess` is built "
"dynamically based on the function signature and so the names of the inputs "
"are based on the parameter name from the function definition, or the named "
"argument when the function is called. Since for variable arguments, neither "
"at function definition nor at function call, explicit parameter names are "
"used, the engine can impossibly determine what names, and by extensions link"
" label, to use for the inputs."
msgstr ""

#: ../docs/source/topics/processes/functions.rst:89
msgid ""
"In contrast, keyword arguments for that reason *are* supported and it is the"
" keyword used when the function is called that determines the names of the "
"parameters and the labels of the input links. The following snippet is "
"therefore perfectly legal and will return the sum of all the nodes that are "
"passed:"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:95
msgid "The provenance generated by this example looks like the following:"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:100
msgid ""
"The link labels of the inputs are determined based on the naming of the "
"parameters when the function is called."
msgstr ""

#: ../docs/source/topics/processes/functions.rst:102
msgid ""
"Note that the inputs **have to be passed as keyword arguments** because they"
" are used for the link labels. If the inputs would simply have been passed "
"as positional arguments, the engine could have impossibly determined what "
"label to use for the links that connect the input nodes with the calculation"
" function node. For this reason, invoking a 'dynamic' function, i.e. one "
"that supports ``**kwargs`` in its signature, with more positional arguments "
"that explicitly named in the signature, will raise a ``TypeError``."
msgstr ""

#: ../docs/source/topics/processes/functions.rst:107
msgid "Return values"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:108
msgid ""
"In :numref:`fig_calculation_functions_kwargs` you can see that the engine "
"used the label ``result`` for the link connecting the calculation function "
"node with its output node. This is the default link label if only a single "
"result is returned from the calculation function. If you want to specify a "
"label yourself, you can return the result in the form of a dictionary, where"
" the key will be used as the link label. By using a dictionary you can also "
"record multiple nodes as output. Consider the following snippet:"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:117
msgid ""
"The provenance generated by running this calculation function will look "
"like:"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:122
msgid ""
"If a dictionary is returned, the keys will be used as the labels for the "
"links that connect the output nodes with the calculation node."
msgstr ""

#: ../docs/source/topics/processes/functions.rst:124
msgid ""
"As always, all the values returned by a calculation function have to be "
"storable, which means they have to be instances of the "
":py:class:`~aiida.orm.nodes.node.Node` class."
msgstr ""

#: ../docs/source/topics/processes/functions.rst:127
msgid ""
"It is very important that you **do not call** "
":py:meth:`~aiida.orm.nodes.node.Node.store` **yourself** on the nodes before"
" returning them from a ``calcfunction``. Because of the calculation/workflow"
" duality in AiiDA, a ``calcfunction``, which is a calculation-like process, "
"can only *create* and not *return* data nodes. This means that if a node is "
"returned from a ``calcfunction`` that *is already stored*, the engine will "
"throw an exception."
msgstr ""

#: ../docs/source/topics/processes/functions.rst:133
#: ../docs/source/topics/processes/usage.rst:220
#: ../docs/source/topics/workflows/usage.rst:108
#: ../docs/source/topics/workflows/usage.rst:273
msgid "Exit codes"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:134
msgid ""
"So far we have only seen examples of calculation functions where everything "
"works out just fine. However, the real world is different, and often we will"
" encounter situations where problems arise. A calculation function may "
"receive incorrect or incoherent inputs, or the code it executes may throw an"
" exception. Of course we could throw an input validation exception or not "
"even catch the exceptions that the code we call throws, but that will lead "
"the function process to be put in the ``Excepted`` terminal state. As "
"explained in the :ref:`process state<topics:processes:concepts:state>` "
"section, this state is indeed reserved for processes that incurred an "
"exception during execution. Consider the following calculation function "
"definition and call:"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:144
msgid ""
"Because the value for ``y`` that is being passed is zero, the engine will "
"encounter a ``ZeroDivisionError`` exception when the calculation function is"
" run. The output of ``verdi process list`` will confirm that the process has"
" excepted:"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:155
msgid ""
"Exceptions that occur during the execution of a process are recorded as a "
"log message on the corresponding process node. To show these log messages, "
"one can use ``verdi process report``. In the case of the example above, it "
"would look something like the following:"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:174
msgid ""
"However, in this particular example the exception is not so much an "
"unexpected error, but one we could have considered and have seen coming, so "
"it might be more applicable to simply mark the process as failed. To "
"accomplish this, there is the concept of an :ref:`exit "
"status<topics:processes:concepts:exit_codes>` that can be set on the "
"process, which is an integer that, when non-zero, marks a process in the "
"``Finished`` state as 'failed'. Since the exit status is set as an attribute"
" on the process node, it also makes it very easy to query for failed "
"processes. To set a non-zero exit status on a calculation function to "
"indicate it as failed, simply return an instance of the "
":py:class:`~aiida.engine.processes.exit_code.ExitCode` class. Time for a "
"demonstration:"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:183
msgid ""
"When we run the calculation function now, with the same inputs, instead of "
"excepting, the process will successfully terminate and its exit status will "
"be set to the value stored in the ``ExitCode``. The exit status is also "
"displayed by ``verdi process list``:"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:195
msgid ""
"Both approaches are valid and which one to use depends on your use case. The"
" question you should ask yourself is whether a potential problem merits "
"throwing the process on the pile of 'excepted' processes. Or maybe, as in "
"the example above, the problem is easily foreseeable and classifiable with a"
" well defined exit status, in which case it might make more sense to return "
"the exit code. At the end one should think which solution makes it easier "
"for a workflow calling the function to respond based on the result and what "
"makes it easier to query for these specific failure modes."
msgstr ""

#: ../docs/source/topics/processes/functions.rst:202
#: ../docs/source/topics/provenance/index.rst:5
msgid "Provenance"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:203
msgid ""
"In addition to the basic attributes that are stored for all processes such "
"as the process state and label, the process functions automatically store "
"additional information that relates to the source code of the function they "
"represent:"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:205
msgid "Function name"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:206
msgid "Function namespace"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:207
msgid "Function starting line number"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:208
msgid "Function source file"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:210
msgid ""
"The first three are retrieved by inspecting the python source code as soon "
"as the process function is executed and are stored as attributes on the "
"process node. They can be accessed through the corresponding properties on "
"the process node as follows:"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:216
msgid ""
"The source code of the file in which the function is defined is also stored,"
" but since it can be quite big, it is stored as a raw file in the repository"
" of the process node. It can be retrieved through the "
":py:meth:`~aiida.orm.utils.mixins.FunctionCalculationMixin.get_function_source_code`"
" method."
msgstr ""

#: ../docs/source/topics/processes/functions.rst:219
msgid ""
"The attributes give some querability to the process functions stored in the "
"provenance graph and by storing the source code of the function that was "
"executed, there will be some reference in the future to track how the "
"function created its output nodes. Note, however, that just storing the "
"source file of the function does not guarantee that one can reproduce the "
"exact result. For example, one can 'leak' data into the function by reading "
"a file or loading an existing node from the database that was not explicitly"
" passed as an input. Alternatively, external code can be imported and "
"called, the source code of which will not be recorded."
msgstr ""

#: ../docs/source/topics/processes/functions.rst:225
msgid "Reproducibility guidelines"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:226
msgid ""
"Due to the nature of the way process functions are implemented, it is "
"impossible to guarantee 100% reproducibility, but by following the following"
" guidelines, one can come as close as possible."
msgstr ""

#: ../docs/source/topics/processes/functions.rst:228
msgid "Do not leak data into functions"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:229
msgid "Limit importing of external code"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:230
msgid "Keep functions self-consistent and in separate files"
msgstr ""

#: ../docs/source/topics/processes/functions.rst:232
msgid ""
"Leaking data into functions is accomplished for example by reading a file on"
" the local file system in the function body and using its contents for the "
"creation of the outputs. Even if you store the source code, if you don't "
"possess the file that was read, it is impossible to reproduce the results. "
"Likewise, you should not load any existing data from the database through "
"the API, but rather they should be direct inputs of the process function."
msgstr ""

#: ../docs/source/topics/processes/functions.rst:236
msgid ""
"A similar problem occurs when importing other python code. Practically, it "
"is almost impossible to never import code into process functions, as this "
"would force massive code duplication. However, there is still a difference "
"between importing code from the ``aiida-core`` library or the repository in "
"which the process function is hosted, and the importing of a local python "
"file. Even though for both cases there can no be guarantee of "
"reproducibility, the former stands a better chance by far, as the version "
"number of the plugin package should be recorded. The rule of thumb then is "
"to keep the importing of code to a minimum, but if you have to, make sure to"
" make it part of a plugin package with a well-defined version number."
msgstr ""

#: ../docs/source/topics/processes/functions.rst:242
msgid ""
"Finally, as mentioned in the introduction, the source file of a process "
"function is stored as a file in the repository for *each execution*. "
"Currently there is no automatic deduplication for identical files by the "
"engine, so these files may occupy quite a bit of space. For this reason it "
"is advisable to keep each process function in its own separate file. This "
"not only improves readability, but it also minimizes the impact on the size "
"of the file repository."
msgstr ""

#: ../docs/source/topics/processes/index.rst:5
msgid "Processes"
msgstr ""

#: ../docs/source/topics/processes/index.rst:7
msgid ""
"This topic section provides extensive and detailed information on the "
"concept of processes in AiiDA and how to work with them. Since the concepts "
"explained here apply to processes in general, they also apply to its "
"subtypes: calculations and workflows. Information specific to each subtype "
"can be found in the topic sections on :ref:`calculations "
"<topics:calculations>` and :ref:`workflows <topics:workflows>`, "
"respectively."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:7
msgid ""
"This chapter assumes knowledge of the previous section on the :ref:`basic "
"concept of processes<topics:workflows:concepts>`."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:9
msgid ""
"This section will explain the aspects of working with processes that apply "
"to all processes. Details that only pertain to a specific sub type of "
"process, will be documented in their respective sections:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:12
msgid ":ref:`calculation functions<topics:calculations:usage:calcfunctions>`"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:13
msgid ":ref:`calculation jobs<topics:calculations:usage:calcjobs>`"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:14
msgid ":ref:`work functions<topics:workflows:usage:workfunctions>`"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:15
msgid ":ref:`work chains<topics:workflows:usage:workchains>`"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:21
msgid "Defining processes"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:26
msgid "Process specification"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:27
msgid ""
"How a process defines the inputs that it requires or can optionally take, "
"depends on the process type. The inputs of "
":py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` and "
":py:class:`~aiida.engine.processes.workchains.workchain.WorkChain` are given"
" by the :py:class:`~aiida.engine.processes.process_spec.ProcessSpec` class, "
"which is defined though  the "
":py:meth:`~aiida.engine.processes.process.Process.define` method. For "
"process functions, the "
":py:class:`~aiida.engine.processes.process_spec.ProcessSpec` is dynamically "
"generated by the engine from the signature of the decorated function. "
"Therefore, to determine what inputs a process takes, one simply has to look "
"at the process specification in the ``define`` method or the function "
"signature. For the "
":py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` and "
":py:class:`~aiida.engine.processes.workchains.workchain.WorkChain` there is "
"also the concept of the :ref:`process "
"builder<topics:processes:usage:builder>`, which will allow one to inspect "
"the inputs with tab-completion and help strings in the shell."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:33
msgid ""
"The three most important attributes of the "
":py:class:`~aiida.engine.processes.process_spec.ProcessSpec` are:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:35
msgid "``inputs``"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:36
msgid "``outputs``"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:37
msgid "``exit_codes``"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:39
msgid ""
"Through these attributes, one can define what inputs a process takes, what "
"outputs it will produce and what potential exit codes it can return in case "
"of errors. Just by looking at a process specification then, one will know "
"exactly *what* will happen, just not *how* it will happen. The ``inputs`` "
"and ``outputs`` attributes are *namespaces* that contain so called *ports*, "
"each one of which represents a specific input or output. The namespaces can "
"be arbitrarily nested with ports and so are called *port namespaces*. The "
"port and port namespace are implemented by the :py:class:`~plumpy.Port` and "
":py:class:`~aiida.engine.processes.ports.PortNamespace` class, respectively."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:49
msgid "Ports and Port namespaces"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:50
msgid ""
"To define an input for a process specification, we only need to add a port "
"to the ``inputs`` port namespace, as follows:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:57
msgid ""
"The ``input`` method, will create an instance of "
":py:class:`~aiida.engine.processes.ports.InputPort`, a sub class of the base"
" :py:class:`~plumpy.Port`, and will add it to the ``inputs`` port namespace "
"of the spec. Creating an output is just as easy, but one should use the "
":py:meth:`~plumpy.ProcessSpec.output` method instead:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:65
msgid ""
"This will cause an instance of "
":py:class:`~aiida.engine.processes.ports.OutputPort`, also a sub class of "
"the base :py:class:`~plumpy.Port`, to be created and to be added to the "
"``outputs`` specifcation attribute. Recall, that the ``inputs`` and "
"``output`` are instances of a "
":py:class:`~aiida.engine.processes.ports.PortNamespace`, which means that "
"they can contain any port. But the "
":py:class:`~aiida.engine.processes.ports.PortNamespace` itself is also a "
"port itself, so it can be added to another port namespace, allowing one to "
"create nested port namespaces. Creating a new namespace in for example the "
"inputs namespace is as simple as:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:75
msgid ""
"This will create a new ``PortNamespace`` named ``namespace`` in the "
"``inputs`` namespace of the spec. You can create arbitrarily nested "
"namespaces in one statement, by separating them with a ``.`` as shown here:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:83
msgid ""
"This command will result in the ``PortNamespace`` name ``namespace`` to be "
"nested inside another ``PortNamespace`` called ``nested``."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:87
msgid ""
"Because the period is reserved to denote different nested namespaces, it "
"cannot be used in the name of terminal input and output ports as that could "
"be misinterpreted later as a port nested in a namespace."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:89
msgid ""
"Graphically, this can be visualized as a nested dictionary and will look "
"like the following:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:99
msgid ""
"The ``outputs`` attribute of the ``ProcessSpec`` is also a ``PortNamespace``"
" just as the ``inputs``, with the only different that it will create "
"``OutputPort`` instead of ``InputPort`` instances. Therefore the same "
"concept of nesting through ``PortNamespaces`` applies to the outputs of a "
"``ProcessSpec``."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:106
msgid "Validation and defaults"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:107
msgid ""
"In the previous section, we saw that the ``ProcessSpec`` uses the "
"``PortNamespace``, ``InputPort`` and ``OutputPort`` to define the inputs and"
" outputs structure of the ``Process``. The underlying concept that allows "
"this nesting of ports is that the ``PortNamespace``, ``InputPort`` and "
"``OutputPort``, are all a subclass of :py:class:`~plumpy.ports.Port`. And as"
" different subclasses of the same class, they have more properties and "
"attributes in common, for example related to the concept of validation and "
"default values. All three have the following attributes (with the exception "
"of the ``OutputPort`` not having a ``default`` attribute):"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:112
msgid "``default``"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:113
msgid "``required``"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:114
msgid "``valid_type``"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:115
msgid "``validator``"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:117
msgid ""
"These attributes can all be set upon construction of the port or after the "
"fact, as long as the spec has not been sealed, which means that they can be "
"altered without limit as long as it is within the ``define`` method of the "
"corresponding ``Process``. An example input port that explicitly sets all "
"these attributes is the following:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:124
msgid ""
"Here we define an input named ``positive_number`` that should be of type "
"``Int`` or ``Float`` and should pass the test of the ``is_number_positive`` "
"validator. If no value is passed, the default will be used."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:129
msgid ""
"In python, it is good practice to avoid mutable defaults for function "
"arguments, `since they are instantiated at function definition and reused "
"for each invocation <https://docs.python.org/3/reference/compound_stmts.html"
"#function-definitions>`_. This can lead to unexpected results when the "
"default value is changed between function calls. In the context of AiiDA, "
"nodes (both stored and unstored) are considered *mutable* and should "
"therefore *not* be used as default values for process ports. However, it is "
"possible to use a lambda that returns a node instance as done in the example"
" above. This will return a new instance of the node with the given value, "
"each time the process is instantiated."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:135
msgid ""
"Note that the validator is nothing more than a free function which takes a "
"single argument, being the value that is to be validated. If nothing is "
"returned, the value is considered to be valid. To signal that the value is "
"invalid and to have a validation error raised, simply return a string with "
"the validation error message, for example:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:145
msgid ""
"The ``valid_type`` can define a single type, or a tuple of valid types."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:149
msgid ""
"Note that by default all ports are required, but specifying a default value "
"implies that the input is not required and as such specifying "
"``required=False`` is not necessary in that case. It was added to the "
"example above simply for clarity."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:152
msgid ""
"The validation of input or output values with respect to the specification "
"of the corresponding port, happens at the instantiation of the process and "
"when it is finalized, respectively. If the inputs are invalid, a "
"corresponding exception will be thrown and the process instantiation will "
"fail. When the outputs fail to be validated, likewise an exception will be "
"thrown and the process state will be set to ``Excepted``."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:160
msgid "Dynamic namespaces"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:161
msgid ""
"In the previous section we described the various attributes related to "
"validation and claimed that all the port variants share those attributes, "
"yet we only discussed the ``InputPort`` and ``OutputPort`` explicitly. The "
"statement, however, is still correct and the ``PortNamespace`` has the same "
"attributes. You might then wonder what the meaning is of a ``valid_type`` or"
" ``default`` for a ``PortNamespace`` if all it does is contain "
"``InputPorts``, ``OutputPorts`` or other ``PortNamespaces``. The answer to "
"this question lies in the ``PortNamespace`` attribute ``dynamic``."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:166
msgid ""
"Often when designing the specification of a ``Process``, we cannot know "
"exactly which inputs we want to be able to pass to the process. However, "
"with the concept of the ``InputPort`` and ``OutputPort`` one *does* need to "
"know exactly, how many values one expects at least, as they do have to be "
"defined. This is where the ``dynamic`` attribute of the ``PortNamespace`` "
"comes in. By default this is set to ``False``, but by setting it to "
"``True``, one indicates that that namespace can take a number of values that"
" is unknown at the time of definition of the specification. This now "
"explains the meaning of the ``valid_type``, ``validator`` and ``default`` "
"attributes in the context of the ``PortNamespace``. If you do mark a "
"namespace as dynamic, you may still want to limit the set of values that are"
" acceptable, which you can do by specifying the valid type and or validator."
" The values that will eventually be passed to the port namespace will then "
"be validated according to these rules exactly as a value for a regular input"
" port would be."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:178
msgid "Non storable inputs"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:179
msgid ""
"In principle, the only valid types for inputs and outputs should be "
"instances of a :py:class:`~aiida.orm.nodes.data.data.Data` node, or one of "
"its sub classes, as that is the only data type that can be recorded in the "
"provenance graph as an input or output of a process. However, there are "
"cases where you might want to pass an input to a process, whose provenance "
"you do not care about and therefore would want to pass a non-database "
"storable type anyway."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:184
msgid ""
"AiiDA allows you to break the provenance as to be not too restrictive, but "
"always tries to urge you and guide you in a direction to keep the "
"provenance. There are legitimate reasons to break it regardless, but make "
"sure you think about the implications and whether you are really willing to "
"lose the information."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:187
msgid ""
"For this situation, the ``InputPort`` has the attribute ``non_db``. By "
"default this is set to ``False``, but by setting it to ``True`` we can "
"indicate that the values that are passed to the port should not be stored as"
" a node in the provenance graph and linked to the process node. This allows "
"one to pass any normal value that one would also be able to pass to a normal"
" function."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:195
msgid "Automatic input serialization"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:197
msgid ""
"Quite often, inputs which are given as python data types need to be cast to "
"the corresponding AiiDA type before passing them to a process. Doing this "
"manually can be cumbersome, so you can define a function when defining the "
"process specification, which does the conversion automatically. This "
"function, passed as ``serializer`` parameter to ``spec.input``, is invoked "
"if the given input is *not* already an AiiDA type."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:201
msgid ""
"For inputs which are stored in the database (``non_db=False``), the "
"serialization function should return an AiiDA data type. For ``non_db`` "
"inputs, the function must be idempotent because it might be applied more "
"than once."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:204
msgid ""
"The following example work chain takes three inputs ``a``, ``b``, ``c``, and"
" simply returns the given inputs. The "
":func:`aiida.orm.nodes.data.base.to_aiida_type` function is used as "
"serialization function."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:209
msgid ""
"This work chain can now be called with native Python types, which will "
"automatically be converted to AiiDA types by the "
":func:`aiida.orm.nodes.data.base.to_aiida_type` function. Note that the "
"module which defines the corresponding AiiDA type must be loaded for it to "
"be recognized by :func:`aiida.orm.nodes.data.base.to_aiida_type`."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:214
msgid ""
"Of course, you can also use the serialization feature to perform a more "
"complex serialization of the inputs."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:221
msgid ""
"Any ``Process`` most likely will have one or multiple expected failure "
"modes. To clearly communicate to the caller what went wrong, the ``Process``"
" supports setting its ``exit_status``. This ``exit_status``, a positive "
"integer, is an attribute of the process node and by convention, when it is "
"zero means the process was successful, whereas any other value indicates "
"failure. This concept of an exit code, with a positive integer as the exit "
"status, `is a common concept in programming <https://shapeshed.com/unix-"
"exit-codes/>`_ and a standard way for programs to communicate the result of "
"their execution."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:226
msgid ""
"Potential exit codes for the ``Process`` can be defined through the "
"``ProcessSpec``, just like inputs and ouputs. Any exit code consists of a "
"positive non-zero integer, a string label to reference it and a more "
"detailed description of the problem that triggers the exit code. Consider "
"the following example:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:235
msgid ""
"This defines an exit code for the ``Process`` with exit status ``418`` and "
"exit message ``the work chain had an identity crisis``. The string "
"``ERROR_I_AM_A_TEAPOT`` is a label that the developer can use to reference "
"this particular exit code somewhere in the ``Process`` code itself."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:238
msgid ""
"Whenever a ``Process`` exits through a particular error code, the caller "
"will be able to introspect it through the ``exit_status`` and "
"``exit_message`` attributes of the node. Assume for example that we ran a "
"``Process`` that threw the exit code described above, the caller would be "
"able to do the following:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:249
msgid ""
"This is useful, because the caller can now programmatically, based on the "
"``exit_status``, decide how to proceed. This is an infinitely more robust "
"way of communicating specific errors to a non-human than parsing text-based "
"logs or reports. Additionally, the exit codes make it very easy to query for"
" failed processes with specific error codes."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:257
msgid "Exit code conventions"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:258
msgid ""
"In principle, the only restriction on the exit status of an exit code is "
"that it should be a positive integer or zero. However, to make effective use"
" of exit codes, there are some guidelines and conventions as to decide what "
"integers to use. Note that since the following rules are *guidelines* you "
"can choose to ignore them and currently the engine will not complain, but "
"this might change in the future. Regardless, we advise you to follow the "
"guidelines since it will improve the interoperability of your code with "
"other existing plugins. The following integer ranges are reserved or "
"suggested:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:264
msgid "0 -  99: Reserved for internal use by `aiida-core`"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:265
msgid ""
"100 - 199: Reserved for errors parsed from scheduler output of calculation "
"jobs (note: this is not yet implemented)"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:266
msgid "200 - 299: Suggested to be used for process input validation errors"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:267
msgid "300 - 399: Suggested for critical process errors"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:269
msgid "For any other exit codes, one can use the integers from 400 and up."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:275
msgid "Process metadata"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:277
msgid ""
"Each process, in addition to the normal inputs defined through its process "
"specification, can take optional 'metadata'. These metadata differ from "
"inputs in the sense that they are not nodes that will show up as inputs in "
"the provenance graph of the executed process. Rather, these are inputs that "
"slightly modify the behavior of the process or allow to set attributes on "
"the process node that represents its execution. The following metadata "
"inputs are available for *all* process classes:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:282
msgid "``label``: will set the label on the ``ProcessNode``"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:283
msgid "``description``: will set the description on the ``ProcessNode``"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:284
msgid ""
"``store_provenance``: boolean flag, by default ``True``, that when set to "
"``False``, will ensure that the execution of the process **is not** stored "
"in the provenance graph"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:286
msgid ""
"Sub classes of the :py:class:`~aiida.engine.processes.process.Process` class"
" can specify further metadata inputs, refer to their specific documentation "
"for details. To pass any of these metadata options to a process, simply pass"
" them in a dictionary under the key ``metadata`` in the inputs when "
"launching the process. How a process can be launched is explained the "
"following section."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:294
msgid "Launching processes"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:295
msgid ""
"Any process can be launched by 'running' or 'submitting' it. Running means "
"to run the process in the current python interpreter in a blocking way, "
"whereas submitting means to send it to a daemon worker over RabbitMQ. For "
"long running processes, such as calculation jobs or complex workflows, it is"
" best advised to submit to the daemon. This has the added benefit that it "
"will directly return control to your interpreter and allow the daemon to "
"save intermediate progress during checkpoints and reload the process from "
"those if it has to restart. Running processes can be useful for trivial "
"computational tasks, such as simple calcfunctions or workfunctions, or for "
"debugging and testing purposes."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:305
msgid "Process launch"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:307
msgid ""
"To launch a process, one can use the free functions that can be imported "
"from the :py:mod:`aiida.engine` module. There are four different functions:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:310
msgid ":py:func:`~aiida.engine.launch.run`"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:311
msgid ":py:func:`~aiida.engine.launch.run_get_node`"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:312
msgid ":py:func:`~aiida.engine.launch.run_get_pk`"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:313
msgid ":py:func:`~aiida.engine.launch.submit`"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:315
msgid ""
"As the name suggest, the first three will 'run' the process and the latter "
"will 'submit' it to the daemon. Running means that the process will be "
"executed in the same interpreter in which it is launched, blocking the "
"interpreter, until the process is terminated. Submitting to the daemon, in "
"contrast, means that the process will be sent to the daemon for execution, "
"and the interpreter is released straight away."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:319
msgid ""
"All functions have the exact same interface ``launch(process, **inputs)`` "
"where:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:321
msgid "``process`` is the process class or process function to launch"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:322
msgid "``inputs`` are the inputs as keyword arguments to pass to the process."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:324
msgid ""
"What inputs can be passed depends on the exact process class that is to be "
"launched. For example, when we want to run an instance of the "
":py:class:`~aiida.calculations.arithmetic.add.ArithmeticAddCalculation` "
"process, which takes two :py:class:`~aiida.orm.nodes.data.int.Int` nodes as "
"inputs under the name ``x`` and ``y`` [#f1]_, we would do the following:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:330
msgid ""
"The function will submit the calculation to the daemon and immediately "
"return control to the interpreter, returning the node that is used to "
"represent the process in the provenance graph."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:333
msgid ""
"Process functions, i.e. python functions decorated with the ``calcfunction``"
" or ``workfunction`` decorators, **cannot be submitted** but can only be "
"run."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:335
msgid "The ``run`` function is called identically:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:340
msgid ""
"except that it does not submit the process to the daemon, but executes it in"
" the current interpreter, blocking it until the process is terminated. The "
"return value of the ``run`` function is also **not** the node that "
"represents the executed process, but the results returned by the process, "
"which is a dictionary of the nodes that were produced as outputs. If you "
"would still like to have the process node or the pk of the process node you "
"can use one of the following variants:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:347
msgid ""
"Finally, the :py:func:`~aiida.engine.launch.run` launcher has two attributes"
" ``get_node`` and ``get_pk`` that are simple proxies to the "
":py:func:`~aiida.engine.launch.run_get_node` and "
":py:func:`~aiida.engine.launch.run_get_pk` methods. This is a handy "
"shortcut, as now you can choose to use any of the three variants with just a"
" single import:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:353
msgid ""
"If you want to launch a process class that takes a lot more inputs, often it"
" is useful to define them in a dictionary and use the python syntax ``**`` "
"that automatically expands it into keyword argument and value pairs. The "
"examples used above would look like the following:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:359
msgid ""
"Process functions, i.e. :ref:`calculation "
"functions<topics:calculations:concepts:calcfunctions>` and :ref:`work "
"functions<topics:workflows:concepts:workfunctions>`, can be launched like "
"any other process as explained above, with the only exception that they "
"**cannot be submitted**. In addition to this limitation, process functions "
"have two additional methods of being launched:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:362
msgid "Simply *calling* the function"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:363
msgid "Using the internal run method attributes"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:365
msgid ""
"Using a calculation function to add two numbers as an example, these two "
"methods look like the following:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:374
msgid "Process builder"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:375
msgid ""
"As explained in a :ref:`previous section<topics:processes:usage:spec>`, the "
"inputs for a :py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` "
"and :py:class:`~aiida.engine.processes.workchains.workchain.WorkChain` are "
"defined in the :py:meth:`~aiida.engine.processes.process.Process.define` "
"method. To know what inputs they take, one would have to read the "
"implementation, which can be annoying if you are not a developer. To "
"simplify this process, these two process classes provide a utility called "
"the 'process builder'. The process builder is essentially a tool that helps "
"you build the inputs for the specific process class that you want to run. To"
" get a *builder* for a particular ``CalcJob`` or a ``WorkChain`` "
"implementation, all you need is the class itself, which can be loaded "
"through the :py:class:`~aiida.plugins.factories.CalculationFactory` and "
":py:class:`~aiida.plugins.factories.WorkflowFactory`, respectively. Let's "
"take the "
":py:class:`~aiida.calculations.arithmetic.add.ArithmeticAddCalculation` as "
"an example::"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:385
msgid ""
"The string ``arithmetic.add`` is the entry point of the "
"``ArithmeticAddCalculation`` and passing it to the ``CalculationFactory`` "
"will return the corresponding class. Calling the ``get_builder`` method on "
"that class will return an instance of the "
":py:class:`~aiida.engine.processes.builder.ProcessBuilder` class that is "
"tailored for the ``ArithmeticAddCalculation``. The builder will help you in "
"defining the inputs that the ``ArithmeticAddCalculation`` requires and has a"
" few handy tools to simplify this process."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:389
msgid ""
"To find out which inputs the builder exposes, you can simply use tab "
"completion. In an interactive python shell, by simply typing ``builder.`` "
"and hitting the tab key, a complete list of all the available inputs will be"
" shown. Each input of the builder can also show additional information about"
" what sort of input it expects. In an interactive shell, you can get this "
"information to display as follows::"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:404
msgid ""
"In the ``Docstring`` you will see a ``help`` string that contains more "
"detailed information about the input port. Additionally, it will display a "
"``valid_type``, which when defined shows which data types are expected. If a"
" default value has been defined, that will also be displayed. The ``non_db``"
" attribute defines whether that particular input will be stored as a proper "
"input node in the database, if the process is submitted."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:409
msgid ""
"Defining an input through the builder is as simple as assigning a value to "
"the attribute. The following example shows how to set the ``parameters`` "
"input, as well as the ``description`` and ``label`` metadata inputs::"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:417
msgid ""
"If you evaluate the ``builder`` instance, simply by typing the variable name"
" and hitting enter, the current values of the builder's inputs will be "
"displayed::"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:430
msgid ""
"In this example, you can see the value that we just set for the "
"``description`` and the ``label``. In addition, it will also show any "
"namespaces, as the inputs of processes support nested namespaces, such as "
"the ``metadata.options`` namespace in this example. Note that nested "
"namespaces are also all autocompleted, and you can traverse them recursively"
" with tab-completion."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:434
msgid ""
"All that remains is to fill in all the required inputs and we are ready to "
"launch the process builder. When all the inputs have been defined for the "
"builder, it can be used to actually launch the ``Process``. The process can "
"be launched by passing the builder to any of the free functions "
":py:mod:`~aiida.engine.launch` module, just as you would do a normal process"
" as :ref:`described above<topics:processes:usage:launching>`, i.e.:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:441
msgid ""
"Note that the process builder is in principle designed to be used in an "
"interactive shell, as there is where the tab-completion and automatic input "
"documentation really shines. However, it is perfectly possible to use the "
"same builder in scripts where you simply use it as an input container, "
"instead of a plain python dictionary."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:448
msgid "Monitoring processes"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:449
msgid ""
"When you have launched a process, you may want to investigate its status, "
"progression and the results. The :ref:`verdi<reference:command-line>` "
"command line tool provides various commands to do just this."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:456
msgid "verdi process list"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:457
msgid ""
"Your first point of entry will be the ``verdi`` command ``verdi process "
"list``. This command will print a list of all active processes through the "
"``ProcessNode`` stored in the database that it uses to represent its "
"execution. A typical example may look something like the following:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:471
msgid ""
"The 'State' column is a concatenation of the ``process_state`` and the "
"``exit_status`` of the ``ProcessNode``. By default, the command will only "
"show active items, i.e. ``ProcessNodes`` that have not yet reached a "
"terminal state. If you want to also show the nodes in a terminal states, you"
" can use the ``-a`` flag and call ``verdi process list -a``:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:487
msgid ""
"For more information on the meaning of the 'state' column, please refer to "
"the documentation of the :ref:`process state "
"<topics:processes:concepts:state>`. The ``-S`` flag let's you query for "
"specific process states, i.e. issuing ``verdi process list -S created`` will"
" return:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:499
msgid ""
"To query for a specific exit status, one can use ``verdi process list -E "
"0``:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:511
msgid ""
"This simple tool should give you a good idea of the current status of "
"running processes and the status of terminated ones. For a complete list of "
"all the available options, please refer to the documentation of :ref:`verdi "
"process<reference:command-line:verdi-process>`."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:514
msgid ""
"If you are looking for information about a specific process node, the "
"following three commands are at your disposal:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:516
msgid ""
"``verdi process report`` gives a list of the log messages attached to the "
"process"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:517
msgid ""
"``verdi process status`` print the call hierarchy of the process and status "
"of all its nodes"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:518
msgid ""
"``verdi process show`` print details about the status, inputs, outputs, "
"callers and callees of the process"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:520
msgid ""
"In the following sections, we will explain briefly how the commands work. "
"For the purpose of example, we will show the output of the commands for a "
"completed ``PwBaseWorkChain`` from the ``aiida-quantumespresso`` plugin, "
"which simply calls a ``PwCalculation``."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:527
msgid "verdi process report"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:528
msgid ""
"The developer of a process can attach log messages to the node of a process "
"through the :py:meth:`~aiida.engine.processes.process.Process.report` "
"method. The ``verdi process report`` command will display all the log "
"messages in chronological order:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:538
msgid ""
"The log message will include a timestamp followed by the level of the log, "
"which is always ``REPORT``. The second block has the format ``pk|class "
"name|function name`` detailing information about, in this case, the work "
"chain itself and the step in which the message was fired. Finally, the "
"message itself is displayed. Of course how many messages are logged and how "
"useful they are is up to the process developer. In general they can be very "
"useful for a user to understand what has happened during the execution of "
"the process, however, one has to realize that each entry is stored in the "
"database, so overuse can unnecessarily bloat the database."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:548
msgid "verdi process status"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:549
msgid ""
"This command is most useful for ``WorkChain`` instances, but also works for "
"``CalcJobs``. One of the more powerful aspects of work chains, is that they "
"can call ``CalcJobs`` and other ``WorkChains`` to create a nested call "
"hierarchy. If you want to inspect the status of a work chain and all the "
"children that it called, ``verdi process status`` is the go-to tool. An "
"example output is the following:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:559
msgid ""
"The command prints a tree representation of the hierarchical call structure,"
" that recurses all the way down. In this example, there is just a single "
"``PwBaseWorkChain`` which called a ``PwCalculation``, which is indicated by "
"it being indented one level. In addition to the call tree, each node also "
"shows its current process state and for work chains at which step in the "
"outline it is. This tool can be very useful to inspect while a work chain is"
" running at which step in the outline it currently is, as well as the status"
" of all the children calculations it called."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:568
msgid "verdi process show"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:569
msgid ""
"Finally, there is a command that displays detailed information about the "
"``ProcessNode``, such as its inputs, outputs and the optional other "
"processes it called and or was called by. An example output for a "
"``PwBaseWorkChain`` would look like the following:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:613
msgid ""
"This overview should give you all the information if you want to inspect a "
"process' inputs and outputs in closer detail as it provides you their pk's."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:619
msgid "Manipulating processes"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:620
msgid ""
"To understand how one can manipulate running processes, one has to "
"understand the principles of the :ref:`process/node "
"distinction<topics:processes:concepts:node_distinction>` and a "
":ref:`process' lifetime<topics:processes:concepts:lifetime>` first, so be "
"sure to have read those sections first."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:626
msgid "verdi process pause/play/kill"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:627
msgid ""
"The ``verdi`` command line interface provides three commands to interact "
"with 'live' processes."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:629
msgid "``verdi process pause``"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:630
msgid "``verdi process play``"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:631
msgid "``verdi process kill``"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:633
msgid ""
"The first pauses a process temporarily, the second resumes any paused "
"processes and the third one permanently kills them. The sub command names "
"might seem to tell you this already and it might look like that is all there"
" is to know, but the functionality underneath is quite complicated and "
"deserves additional explanation nonetheless."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:636
msgid ""
"As the section on :ref:`the distinction between the process and the "
"node<topics:processes:concepts:node_distinction>` explained, manipulating a "
"process means interacting with the live process instance that lives in the "
"memory of the runner that is running it. By definition, these runners will "
"always run in a different system process than the one from which you want to"
" interact, because otherwise, you would *be* the runner, given that there "
"can only be a single runner in an interpreter and if it is running, the "
"interpreter would be blocked from performing any other operations. This "
"means that in order to interact with the live process, one has to interact "
"with another interpreter running in a different system process. This is once"
" again facilitated by the RabbitMQ message broker. When a runner starts to "
"run a process, it will also add listeners for incoming messages that are "
"being sent for that specific process over RabbitMQ."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:644
msgid ""
"This does not just apply to daemon runners, but also normal runners. That is"
" to say that if you were to launch a process in a local runner, that "
"interpreter will be blocked, but it will still setup the listeners for that "
"process on RabbitMQ. This means that you can manipulate the process from "
"another terminal, just as if you would do with a process that is being run "
"by a daemon runner."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:648
msgid ""
"In the case of 'pause', 'play' and 'kill', one is sending what is called a "
"Remote Procedure Call (RPC) over RabbitMQ. The RPC will include the process "
"identifier for which the action is intended and RabbitMQ will send it to "
"whoever registered itself to be listening for that specific process, in this"
" case the runner that is running the process. This immediately reveals a "
"potential problem: the RPC will fall on deaf ears if there is no one "
"listening, which can have multiple causes. For example, as explained in the "
"section on a :ref:`process' lifetime<topics:processes:concepts:lifetime>`, "
"this can be the case for a submitted process, where the corresponding task "
"is still queued, as all available process slots are occupied. But even if "
"the task *were* to be with a runner, it might be too busy to respond to the "
"RPC and the process appears to be unreachable. Whenever a process is "
"unreachable for an RPC, the command will return an error:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:659
msgid ""
"Depending on the cause of the process being unreachable, the problem may "
"resolve itself automatically over time and one can try again at a later "
"time, as for example in the case of the runner being too busy to respond. "
"However, to prevent this from happening, the runner has been designed to "
"have the communication happen over a separate thread and to schedule "
"callbacks for any necessary actions on the main thread, which performs all "
"the heavy lifting. This should make occurrences of the runner being too busy"
" to respond very rare. However, there is unfortunately no way of telling "
"what the actual problem is for the process not being reachable. The problem "
"will manifest itself identically if the runner just could not respond in "
"time or if the task has accidentally been lost forever due to a bug, even "
"though these are two completely separate situations."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:665
msgid ""
"This brings us to another potential unintuitive aspect of interacting with "
"processes. The previous paragraph already mentioned it in passing, but when "
"a remote procedure call is sent, it first needs to be answered by the "
"responsible runner, if applicable, but it will not *directly execute* the "
"call. This is because the call will be incoming on the communcation thread "
"who is not allowed to have direct access to the process instance, but "
"instead it will schedule a callback on the main thread who can perform the "
"action. The callback will however not necessarily be executed directly, as "
"there may be other actions waiting to be performed. So when you pause, play "
"or kill a process, you are not doing so directly, but rather you are "
"*scheduling* a request to do so. If the runner has successfully received the"
" request and scheduled the callback, the command will therefore show "
"something like the following:"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:676
msgid ""
"The 'scheduled' indicates that the actual killing might not necessarily have"
" happened just yet. This means that even after having called ``verdi process"
" kill`` and getting the success message, the corresponding process may still"
" be listed as active in the output of ``verdi process list``."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:679
msgid ""
"By default, the ``pause``, ``play`` and ``kill`` commands will only ask for "
"the confirmation of the runner that the request has been scheduled and not "
"actually wait for the command to have been executed. This is because, as "
"explained, the actual action being performed might not be instantaneous as "
"the runner may be busy working with other processes, which would mean that "
"the command would block for a long time. If you want to send multiple "
"requests to a lot of processes in one go, this would be ineffective, as each"
" one would have to wait for the previous one to be completed. To change the "
"default and actually wait for the action to be completed and await its "
"response, you can use the ``--wait`` flag. If you know that your daemon "
"runners may be experiencing a heavy load, you can also increase the time "
"that the command waits before timing out, with the ``-t/--timeout`` flag."
msgstr ""

#: ../docs/source/topics/processes/usage.rst:687
#: ../docs/source/topics/workflows/usage.rst:593
msgid "Footnotes"
msgstr ""

#: ../docs/source/topics/processes/usage.rst:688
msgid ""
"Note that the "
":py:class:`~aiida.calculations.arithmetic.add.ArithmeticAddCalculation` "
"process class also takes a ``code`` as input, but that has been omitted for "
"the purposes of the example."
msgstr ""

#: ../docs/source/topics/provenance/concepts.rst:8
msgid "Nodes and links"
msgstr ""

#: ../docs/source/topics/provenance/concepts.rst:10
msgid ""
"Two of the most important concepts in AiiDA are **data** and **processes**. "
"The former are pieces of data, such as a simple integer or float, all the "
"way to more complex data concepts such as a dictionary of parameters, a "
"folder of files or a crystal structure. Processes operate on this data in "
"order to produce new data."
msgstr ""

#: ../docs/source/topics/provenance/concepts.rst:14
msgid "Processes come in two different forms:"
msgstr ""

#: ../docs/source/topics/provenance/concepts.rst:16
msgid ""
"**Calculations** are processes that are able to **create** new data. This is"
" the case, for instance, for externals simulation codes, that generate new "
"data"
msgstr ""

#: ../docs/source/topics/provenance/concepts.rst:17
msgid ""
"**Workflows** are processes that **orchestrate** other workflows and "
"calculations, i.e. they manage the logical flow, being able to **call** "
"other processes. Workflows have data inputs, but cannot generate new data. "
"They can only return data that is already in the database (one typical case "
"is to return data created by a calculation they called)."
msgstr ""

#: ../docs/source/topics/provenance/concepts.rst:19
msgid ""
"Data and processes are represented in the AiiDA provenance graph as the "
"**nodes** of that graph. The graph edges are referred to as **links** and "
"come in different forms:"
msgstr ""

#: ../docs/source/topics/provenance/concepts.rst:22
msgid ""
"**input** links: connect data nodes to the process nodes that used them as "
"input, both calculations and workflows"
msgstr ""

#: ../docs/source/topics/provenance/concepts.rst:23
msgid ""
"**create** links: connect calculation nodes to the data nodes that they "
"created"
msgstr ""

#: ../docs/source/topics/provenance/concepts.rst:24
msgid ""
"**return** links: connect workflow nodes to the data nodes that they "
"returned"
msgstr ""

#: ../docs/source/topics/provenance/concepts.rst:25
msgid ""
"**call** links: connecting workflow nodes to the process nodes that they "
"directly called, be it calculations or workflows"
msgstr ""

#: ../docs/source/topics/provenance/concepts.rst:27
msgid ""
"Note that the **create** and **return** links are often collectively "
"referred to as **output** links."
msgstr ""

#: ../docs/source/topics/provenance/concepts.rst:31
msgid "Data provenance and logical provenance"
msgstr ""

#: ../docs/source/topics/provenance/concepts.rst:33
msgid ""
"AiiDA automatically stores entities in its database and links them forming a"
" **directed graph**. This directed graph automatically tracks the "
"**provenance** of all data produced by calculations or returned by "
"workflows. By tracking the provenance in this way, one can always fully "
"retrace how a particular piece of data came into existence, thus ensuring "
"its reproducibility."
msgstr ""

#: ../docs/source/topics/provenance/concepts.rst:37
msgid "In particular, we define two types of provenance:"
msgstr ""

#: ../docs/source/topics/provenance/concepts.rst:39
msgid ""
"The **data provenance**, consisting of the part of the graph that *only* "
"consists of data and calculations (i.e. without considering workflows), and "
"only the **input** and **create** links that connect them. The data "
"provenance records the full history of how data has been generated. Due to "
"the causality principle, the data provenance part of the graph is a "
"**directed acyclic graph** (DAG), i.e. its nodes are connected by directed "
"edges and it does not contain any cycles."
msgstr ""

#: ../docs/source/topics/provenance/concepts.rst:40
msgid ""
"The **logical provenance** which consists of workflow and data nodes, "
"together with the **input**, **return** and **call** links that connect "
"them. The logical provenance is *not* acyclic, e.g. a workflow that acts as "
"a filter can return one of its own inputs, directly introducing a cycle."
msgstr ""

#: ../docs/source/topics/provenance/concepts.rst:42
msgid ""
"The data provenance is essentially a log of which calculation generated what"
" data using certain inputs. The data provenance alone already guarantees "
"reproducibility (one could run again one by one the calculations with the "
"provided input and would obtain the same outputs). The logical provenance "
"gives additional information on why a specific calculation was run. Imagine "
"the case in which you start from 100 structures, you have a filter operation"
" that picks one, and then you run a simulation on it. The data provenance "
"only shows the simulation you run on the structure that was picked, while "
"the logical provenance can also show that the specific structure was not "
"picked at random but via a specific workflow logic."
msgstr ""

#: ../docs/source/topics/provenance/concepts.rst:49
msgid "Other entities"
msgstr ""

#: ../docs/source/topics/provenance/concepts.rst:51
msgid ""
"Beside nodes (data and processes), AiiDA defines a few more entities, like a"
" :py:class:`~aiida.orm.computers.Computer` (representing a computer, "
"supercomputer or computer cluster where calculations are run or data is "
"stored), a :py:class:`~aiida.orm.groups.Group` (that group nodes together "
"for organizational purposes) and the :py:class:`~aiida.orm.users.User` (to "
"keep track of the user who first generated a given node, computer or group)."
msgstr ""

#: ../docs/source/topics/provenance/concepts.rst:53
msgid ""
"In the following section we describe in more detail how the general "
"provenance concepts above are actually implemented in AiiDA, with specific "
"reference to the python classes that implement them and the class-"
"inheritance relationships."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:5
msgid "Consistency"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:7
msgid ""
"Because of the very nature of scientific research, it becomes indispensable "
"to be able to both delete parts of a database (e.g., if errors are made, "
"inputs are misspelled, or useless calculations are performed) or export it "
"(for collaboration or publication purposes). Both these features, which are "
"provided by AiiDA, have one aspect in common: they can easily lead to a "
"provenance graph with incomplete information. To better understand why, "
"let's take a look at the following basic provenance graph:"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:14
msgid ""
"Even in this simple case, if we were to export only the calculation node and"
" the output data node (or, equivalently, delete just the input data node), "
"then we would have lost part of the critical information needed to run the "
"calculation (the |D_1| node), thus losing the reproducibility of the "
"calculation |C_1|. In this simple case, therefore, in order to have a "
"consistent provenance, whenever you export a calculation node you must also "
"import *all* of its input nodes (or, symmetrically, whenever you delete a "
"data node you must also delete all calculations that used it as an input)."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:17
msgid ""
"This is just one of the many rules that must be considered when trying to "
"manually edit a provenance database. The key message to remember is that "
"AiiDA will not only delete or export the nodes explicitly targeted by the "
"user, but will also include any other nodes that are needed for keeping a "
"consistent provenance in the resulting database."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:20
msgid ""
"It is also worth noting that if you do successive exports of partial "
"information, AiiDA will be able to reconstruct links that might have been "
"broken when dividing the data for export. So if you first where to export "
"the previous graph, and then you exported the next section of your full "
"database:"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:26
msgid ""
"Then AiiDA will be able to automatically identify the shared node |D_2| and "
"connect both sections back together during the import process. For this kind"
" of recognition it doesn't matter which sub-graph was exported first."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:29
msgid ""
"In the following section we will explain in more detail the criteria for "
"including other nodes and the corresponding traversal rules."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:34
msgid "Traversal Rules"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:36
msgid ""
"When you run ``verdi node delete [NODE_IDS]`` or ``verdi export create -N "
"[NODE_IDS]``, AiiDA will look at the links incoming or outgoing from the "
"nodes that you specified and decide if there are other nodes that are "
"critical to keep."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:38
msgid ""
"For this decision, it is not only important to consider the type of link, "
"but also if we are following it along its direction (we will call this "
"``forward`` direction) or in the reversed direction (``backward`` "
"direction). To clarify this, in the example above, when deleting data node "
"|D_1|, AiiDA will follow the ``input_calc`` link in the ``forward`` "
"direction (in this case, it will decide that the linked node (|C_1|) must "
"then also be deleted). If the initial target node was, instead, |C_1| the "
"``input_calc`` link would be followed in the ``backward`` direction (and in "
"this case the node |D_1| will not be deleted, as we will explain below)."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:42
msgid ""
"This process will be repeated recursively for every node that has just been "
"included for deletion or export, until no more nodes need to be added. The "
"rules defining whether a linked node should be added or not to the "
"delete/export list (based on the kind and direction of the link) are called "
"*traversal rules*. In the following section we will describe these rules "
"both for the export and delete procedures."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:46
msgid ""
"The tables below are grouped according to the type of nodes and links "
"involved. We also provide illustrations of the cases considered, where the "
"encircled node is the one being targeted, and the other node (to which the "
"red arrow is pointing) is the one that is being considered for addition into"
" the delete/export list."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:50
msgid "Data and Calculation Nodes"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:52
msgid ""
"The first example above already discusses the case of deleting an input "
"node: in this case, it is necessary to also delete any calculation that uses"
" it as an input."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:54
msgid ""
"In AiiDA, we apply the same criterion also when deleting an output: in this "
"case, we follow the ``create`` link in the ``backward`` direction and we "
"mark for deletion also the calculation that created it. The reason for this "
"is that a calculation with missing outputs could be misleading. For "
"instance, some calculations produce optional outputs depending on the "
"combination of input flags that are used. A missing output might be "
"interpreted as if that piece of information was not computed by the "
"calculation. In the case of export, the rules are typically the reverse of "
"those used for deletion. Therefore, in this case, the following rule "
"applies: when exporting a calculation node, all its input data nodes and "
"created output nodes must be exported as well."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:60
msgid ""
"On the other hand, when exporting a data node, users typically do not need "
"to also export all the calculations that used it as an input. These may "
"represent further work that, by default, does not need to be exported as "
"well (unless explicitly specified by the user in the list of nodes). "
"Equivalently, when deleting a calculation, one typically wants to keep its "
"inputs, as they might be used by other unrelated calculations."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:64
msgid ""
"What should happen instead for the outputs of a calculation to be deleted? "
"Often, one might want to delete (recursively) all the outputs generated by "
"it. However, we leave the option to users to just delete the calculation, "
"keeping its outputs in the database. While we emphasize that this operation "
"removes all provenance information for the output nodes, there are cases in "
"which this is useful or even needed (removal of inputs that are protected by"
" copyright, or creating a smaller export file to transfer to collaborators "
"who want to work with the output data)."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:70
#: ../docs/source/topics/provenance/consistency.rst:101
#: ../docs/source/topics/provenance/consistency.rst:137
msgid "Illustrative diagram (explicitly targeted node is encircled)"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:70
#: ../docs/source/topics/provenance/consistency.rst:101
#: ../docs/source/topics/provenance/consistency.rst:137
msgid "Name of Rule"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:70
#: ../docs/source/topics/provenance/consistency.rst:101
#: ../docs/source/topics/provenance/consistency.rst:137
msgid "Behavior when exporting target node"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:70
#: ../docs/source/topics/provenance/consistency.rst:101
#: ../docs/source/topics/provenance/consistency.rst:137
msgid "Behavior when deleting target node"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:73
msgid "``input_calc_forward``"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:73
#: ../docs/source/topics/provenance/consistency.rst:104
msgid "Default Value: ``False``"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:74
#: ../docs/source/topics/provenance/consistency.rst:105
#: ../docs/source/topics/provenance/consistency.rst:114
msgid "Linked node **won't** be exported **by default**."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:73
#: ../docs/source/topics/provenance/consistency.rst:76
#: ../docs/source/topics/provenance/consistency.rst:79
#: ../docs/source/topics/provenance/consistency.rst:82
#: ../docs/source/topics/provenance/consistency.rst:104
#: ../docs/source/topics/provenance/consistency.rst:107
#: ../docs/source/topics/provenance/consistency.rst:110
#: ../docs/source/topics/provenance/consistency.rst:113
#: ../docs/source/topics/provenance/consistency.rst:140
#: ../docs/source/topics/provenance/consistency.rst:143
#: ../docs/source/topics/provenance/consistency.rst:146
#: ../docs/source/topics/provenance/consistency.rst:149
msgid "Fixed Value: ``True``"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:74
#: ../docs/source/topics/provenance/consistency.rst:83
#: ../docs/source/topics/provenance/consistency.rst:105
#: ../docs/source/topics/provenance/consistency.rst:114
#: ../docs/source/topics/provenance/consistency.rst:144
#: ../docs/source/topics/provenance/consistency.rst:150
msgid "Linked node **will always** be deleted."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:76
msgid "``input_calc_backward``"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:77
#: ../docs/source/topics/provenance/consistency.rst:80
#: ../docs/source/topics/provenance/consistency.rst:108
#: ../docs/source/topics/provenance/consistency.rst:111
#: ../docs/source/topics/provenance/consistency.rst:141
#: ../docs/source/topics/provenance/consistency.rst:147
msgid "Linked node **will always** be exported."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:76
msgid "Fixed Value: ``False`` [#f01]_"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:77
#: ../docs/source/topics/provenance/consistency.rst:108
#: ../docs/source/topics/provenance/consistency.rst:111
msgid "Linked node **will never** be deleted."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:79
msgid "``create_forward``"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:79
#: ../docs/source/topics/provenance/consistency.rst:140
#: ../docs/source/topics/provenance/consistency.rst:143
#: ../docs/source/topics/provenance/consistency.rst:146
msgid "Default Value: ``True``"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:80
#: ../docs/source/topics/provenance/consistency.rst:141
#: ../docs/source/topics/provenance/consistency.rst:147
msgid "Linked node **will** be deleted **by default**."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:82
msgid "``create_backward``"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:82
#: ../docs/source/topics/provenance/consistency.rst:149
msgid "Default Value: ``True``."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:83
#: ../docs/source/topics/provenance/consistency.rst:144
#: ../docs/source/topics/provenance/consistency.rst:150
msgid "Linked node **will** be exported **by default**."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:87
msgid ""
"Although we provide the option to automatically export all calculations that"
" use as input any targeted data node (by specifying "
"``input_calc_forward=True``) we *currently* do not provide the reciprocal "
"option to delete all the data node inputs when targeting calculation nodes. "
"This is mainly for the potential danger that would imply automatically "
"enabling upwards traversal of the data provenance when deleting, which would"
" make it extremely hard to predict or control the nodes that will be "
"ultimately affected."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:92
msgid "Data and Workflow Nodes"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:94
msgid ""
"The behavior when considering ``input_work`` links is exactly the same as "
"when considering ``input_calc`` links for the same reasons. The case for "
"``return`` links is partially similar to the one for ``create`` one. Indeed,"
" it isn't desirable to have a resulting database with missing outputs, so "
"when exporting a workflow the returned data nodes will also be included (and"
" when deleting a data node, the returning workflow will also be removed). "
"However, when exporting a returned node, the default behavior is *not* to "
"traverse backwards through the ``return`` links, since a data node might be "
"returned by several unrelated workflows (representing selection procedures "
"for other studies, for example) that are unrelated to its creation. The "
"workflow responsible for coordinating its creation will be included in the "
"export, not directly, but through the chain effect of including the creating"
" calculation (through ``create_backward``) and then including its calling "
"workflows (through ``call_calc_backward`` and ``call_work_backward``, see "
"next sections)."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:104
msgid "``input_work_forward``"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:107
msgid "``input_work_backward``"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:107
msgid "Fixed Value: ``False``"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:110
msgid "``return_forward``"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:110
msgid "Fixed Value: ``False`` [#f02]_"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:113
msgid "``return_backward``"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:113
msgid "Default Value: ``False``."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:118
msgid ""
"The reason to prevent the deletion of returned data nodes is that, since the"
" logical provenance can be cyclical, this might end up deleting inputs and "
"thus propagating the deletion process to other unrelated parts of the "
"database. In most cases where you will want to delete a returned data node, "
"you will be able to do so by setting ``call_calc_forward=True`` (see below) "
"and ``create_forward=True`` (which is the default value)."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:124
msgid "Workflows and Calculation Nodes"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:126
msgid ""
"Finally, we will consider the possible (call) links between processes. The "
"results of a parent workflow depend critically on the sub-workflows or "
"calculations launched by it. When exporting a workflow node, we therefore "
"always traverse its ``call`` links (both ``call_calc`` and ``call_work``) in"
" the ``forward`` direction to include all children processes (i.e. processes"
" directly called by it). Since the traversal rules are applied recursively, "
"this means that also the children processes of any workflow that was a child"
" of the targeted one will be exported as well, and so on. Analogously, when "
"deleting a process the same applies but in the opposite direction "
"(``backward``), including the parent workflow of the targeted node (if there"
" is one), and the parent of that parent, etc."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:132
msgid ""
"Since ``call`` links are followed backward by default, targeting one process"
" for either export or deletion results in selecting not only all of its "
"child processes but also all children of any of its parent processes. As a "
"result of all ``call`` links being traversed in both directions, targeting "
"any of the process nodes in a workflow will mean the inclusion of the other "
"processes of that workflow as well. Users can disable the traversal of "
"``call`` links in one of the directions (``forward`` for deletion, "
"``backward`` for export) for fine-grained control (see examples below)."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:140
msgid "``call_calc_forward``"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:143
msgid "``call_calc_backward``"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:146
msgid "``call_work_forward``"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:149
msgid "``call_work_backward``"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:155
msgid "Cascading rules: an example"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:157
msgid ""
"In the previous sections we have described the basic rules used by AiiDA to "
"decide which nodes should also be included from an initial list of nodes to "
"delete or export. These rules are applied recursively: as new nodes are "
"included in the deletion (or export)list, the rules are applied to them as "
"well until no new nodes are included. Therefore, the consequence of using "
"these features on a given set of nodes may not always be straightforward, "
"and the final set might include more nodes than naively expected."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:161
msgid ""
"Let us first focus on the data provenance only (i.e., only ``input_calc`` "
"and ``create`` links). The following two rules apply when going in the "
"``forward`` direction:"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:163
msgid ""
"If you delete a data node, any calculation that uses it as input will "
"*always* be deleted as well (``input_calc_forward=True``)."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:164
msgid ""
"If you delete a calculation node, any output data node will be deleted *by "
"default* (``create_forward=True``)."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:166
msgid ""
"The consequence of these two together is a \"chain reaction\" in which every"
" node that can be traced back through the data provenance to any of the "
"initial targeted nodes will end up being deleted as well. The reciprocal is "
"true for the export: the default behavior is that every ancestor will also "
"be exported by default (because ``create_backward`` is ``True`` by default "
"and ``input_calc_backward`` is always ``True``)."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:169
msgid ""
"In regards to the connection between data provenance and logical provenance,"
" the most important thing to understand is how the default behavior of the "
"program treats the highest-level workflows as the units to be handled. The "
"logic behind this is the assumption that the typical user of the program "
"will be dealing with it mostly in an interactive way, running pre-defined "
"workflows through the verdi command line without needing a detailed "
"knowledge of their internal procedures. The default behavior then was "
"designed to reproduce the most intuitive outcomes for this type of usage."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:173
msgid ""
"This behavior is basically the result of the settings of "
"``call_calc_forward=True`` and ``call_work_forward=True``, which makes that "
"the inclusion of a process node will also imply the inclusion of any child "
"or parent process node as well. Following these rules in a recursive way "
"leads to the command affecting all the processes within any given workflow: "
"in this way, nodes that are sub-processes of a given highest-level workflow "
"will end up grouped together, in the sense that (by default) they will all "
"be affected in the same way when deleting or exporting."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:176
msgid ""
"More freedom to further customize the selection of sections to export or "
"delete is available through the specific switchable flags for each "
"functionality (although the final sections must always comply with the non-"
"switchable rules, see above). However, this usually requires a deeper "
"understanding of the traversal rules and may imply a more thorough analysis "
"of the particular graph. To better illustrate this, we will now consider the"
" application of the deletion procedure to the following graph:"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:184
msgid ""
"As you can see, |W_1| and |W_2| describe two similar but independent "
"procedures that were launched by a single parent workflow |W_0|. A typical "
"user would have obtained this by directly running this workflow |W_0| to "
"obtain the results |D_3| and |D_4| from the inputs |D_1| and |D_2|, and may "
"even be unaware of the internal division of |W_0| into two sub-Workflows "
"|W_1| and |W_2|. Hence, if the user considers the workflow (meaning, the "
"whole set of nodes produced by it) no longer necessary, the intuitive thing "
"to do in order to remove it from its database would be by targeting the "
"workflow node |W_0| for deletion. Indeed, this would produce the desired "
"result:"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:193
msgid ""
"The nodes |W_1| and |W_2| would be included because |W_0| is being targeted "
"(``call_work_forward=True``), then the nodes |C_1| and |C_2| would also be "
"included (``call_calc_forward=True``), and finally the nodes |D_3| and |D_4|"
" would end up being included as well (``create_forward=True``). In the end, "
"only the inputs |D_1| and |D_2| remain (since ``input_work_backward=False`` "
"always and ``input_calc_backward=False`` by default)."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:196
msgid ""
"The same result would occur if the user were to target the output nodes "
"instead (intending to delete everything associated with the obtention of "
"those results). It is important to notice that even if the user deletes only"
" one of the outputs, the whole set of nodes generated by the workflow would "
"be deleted, and not just the ones associated to the targeted data node. As "
"the results |D_3| and |D_4| where obtained from the same high-level process "
"|W_0|, then the default behavior has the underlying assumption that they are"
" interconnected and not independent from one another (as if they were two "
"different outputs of a single calculation)."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:204
msgid ""
"In this case, the node |C_1| would first be included because the data node "
"|D_3| is being targeted (``create_reverse=True``), and this in turn would "
"include the node |W_1| (``call_calc_reverse=True``) and then its parent "
"workflow |W_0| (``call_work_reverse=True``). Then nodes |W_2|, |C_2| and "
"|D_4| will be included because |W_0| was included, for the same reasons that"
" were explained in the paragraphs above."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:209
msgid "Customizing the graph traversal (for deletion or export)"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:211
msgid ""
"This dependency between nodes becomes particularly relevant when, for "
"example, a user with more knowledge of the internal procedures of the parent"
" workflow |W_0| wants to only delete the calculations and results associated"
" to workflow |W_1|. The intuitive action of targeting |W_1| does not produce"
" the desired outcome:"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:218
msgid ""
"Indeed |C_1| and |D_4| will be deleted (through ``call_calc_forward`` from "
"|W_1| to |C_1| and ``create_forward`` from |C_1| to |D_3|), but so will "
"|W_0| (through ``call_work_reverse`` from |W_1|), |W_2| "
"(``call_work_forward`` from |W_0|), |C_2| (``call_calc_forward`` from |W_2|)"
" and |D_4| (``create_forward`` from |C_2|). The way to achieve the desired "
"outcome is not trivial, although in some situations like this, one could "
"propose case-specific solutions such as targeting |W_1| with the switchable "
"flag ``call_work_forward=False`` (preventing the traversal from |W_0| to "
"|W_2|):"
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:225
msgid ""
"However, this approach is not generally applicable, and wouldn't work if "
"|W_1| had sub-workflows that needed to be deleted as well. A more general "
"approach is to first sever the connection to |W_2| by deleting node |W_0| "
"with all switchable traversal rules turned off. Then, once the independence "
"of |W_1| and |W_2| is explicitly reflected in the graph, node |W_1| can be "
"deleted with the default settings."
msgstr ""

#: ../docs/source/topics/provenance/consistency.rst:233
msgid ""
"It is worth noting that if the workflow |W_0| was itself part of a higher-"
"level workflow, all that higher-level logic would be deleted due to the non-"
"switchable rule ``call_work_reverse=True``. This is an inevitable outcome of"
" deleting part of a workflow, since due to the loss of that information it "
"has become incomplete and it makes no sense to keep it."
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:5
#: ../docs/source/topics/workflows/concepts.rst:119
msgid "Implementation"
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:8
msgid "Graph nodes"
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:10
msgid ""
"The **nodes** of the AiiDA provenance graph can be grouped into two main "
"**types**: **process nodes** (``ProcessNode``), that represent the execution"
" of calculations or workflows, and **data nodes** (``Data``), that represent"
" pieces of data."
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:12
msgid "In particular, **process nodes** are divided into two sub categories:"
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:14
msgid ""
"**calculation nodes** (``CalculationNode``): Represent code execution that "
"creates new data. These are further subdivided in two subclasses:"
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:16
msgid ""
":py:class:`~aiida.orm.nodes.process.calculation.calcjob.CalcJobNode`: "
"Represents the execution of a calculation external to AiiDA, typically via a"
" job batch scheduler (see the concept of :ref:`calculation "
"jobs<topics:calculations:concepts:calcjobs>`)."
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:17
msgid ""
":py:class:`~aiida.orm.nodes.process.calculation.calcfunction.CalcFunctionNode`:"
" Represents the execution of a python function (see the concept of "
":ref:`calculation functions<topics:calculations:concepts:calcfunctions>`)."
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:19
msgid ""
"**workflow nodes** (``WorkflowNode``): Represent python code that "
"orchestrates the execution of other workflows and calculations, that "
"optionally return the data created by the processes they called. These are "
"further subdivided in two subclasses:"
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:21
msgid ""
":py:class:`~aiida.orm.nodes.process.workflow.workchain.WorkChainNode`: "
"Represents the execution of a python class instance with built-in "
"checkpoints, such that the process may be paused/stopped/resumed (see the "
"concept of :ref:`work chains<topics:workflows:concepts:workchains>`)."
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:22
msgid ""
":py:class:`~aiida.orm.nodes.process.workflow.workfunction.WorkFunctionNode`:"
" Represents the execution of a python function calling other processes (see "
"the concept of :ref:`work "
"functions<topics:workflows:concepts:workfunctions>`)."
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:24
msgid "The class hierarchy of the process nodes is shown in the figure below."
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:29
msgid ""
"The hierarchy of the ORM classes for the process nodes. Only instances of "
"the lowest level of classes will actually enter into the provenance graph. "
"The two upper levels have a mostly taxonomical purpose as they allow us to "
"refer to multiple classes at once when reasoning about the graph as well as "
"a place to define common functionality (see section on :ref:`processes "
"<topics:processes:concepts>`)."
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:32
msgid ""
"For what concerns data nodes, the base class (``Data``) is subclassed to "
"provide functionalities specific to the data type and python methods to "
"operate on it. Often, the name of the subclass contains the word ‚ÄúData‚Äù "
"appended to it, but this is not a requirement. A few examples:"
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:35
msgid ""
":py:class:`~aiida.orm.nodes.data.float.Float`, "
":py:class:`~aiida.orm.nodes.data.int.Int`, "
":py:class:`~aiida.orm.nodes.data.bool.Bool`, "
":py:class:`~aiida.orm.nodes.data.str.Str`, "
":py:class:`~aiida.orm.nodes.data.list.List`, ..."
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:36
msgid ""
":py:class:`~aiida.orm.nodes.data.dict.Dict`: represents a dictionary of key-"
"value pairs - these are parameters of a general nature that do not need to "
"belong to more specific data sub-classes"
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:37
msgid ""
":py:class:`~aiida.orm.nodes.data.structure.StructureData`: represents "
"crystal structure data (containing chemical symbols, atomic positions of the"
" atoms, periodic cell for periodic structures, ‚Ä¶)"
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:38
msgid ""
":py:class:`~aiida.orm.nodes.data.array.array.ArrayData`: represents generic "
"numerical arrays of data (python numpy arrays)"
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:39
msgid ""
":py:class:`~aiida.orm.nodes.data.array.kpoints.KpointsData`: represents a "
"numerical array of k-points data, is a sub-class of ``ArrayData``"
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:41
msgid "For more detailed information see :ref:`AiiDA data types <DataTypes>`."
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:43
msgid ""
"In the next section we introduce the links between nodes, creating the AiiDA"
" graph, and then we show some examples to clarify what we introduced up to "
"now."
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:46
msgid "Graph links"
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:48
msgid ""
"Process nodes are connected to their input and output data nodes through "
"directed links. Calculation processes can *create* data, while workflow "
"processes can *call* calculations and *return* their outputs. Consider the "
"following graph example, where we represent **data nodes** with circles, "
"**calculation nodes** with squares and **workflow nodes** with diamond "
"shapes."
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:55
msgid ""
"Simple provenance graph for a workflow (W\\ :sub:`1`) *calling* a "
"calculation (C\\ :sub:`1`). The workflow takes a single **data node** (D\\ "
":sub:`1`\\) as input, and passes it to the calculation when *calling* it. "
"The calculation *creates* a new **data node** (D\\ :sub:`2`\\) that is also "
"*returned* by the **workflow node**."
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:57
msgid ""
"Notice that the different style and names for the two links coming into D\\ "
":sub:`2` is intentional, because it was the calculation that *created* the "
"new data, whereas the workflow merely *returned* it. This subtle distinction"
" has big consequences. By allowing workflow processes to *return* data, it "
"can also *return* data that was among its inputs."
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:64
msgid ""
"Provenance graph example of a **workflow node** that receives three **data "
"nodes** as input and *returns* one of those inputs. The input link from D\\ "
":sub:`3` to W\\ :sub:`1` and the return link from W\\ :sub:`1` to D\\ "
":sub:`3` introduce a cycle in the graph."
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:66
msgid ""
"A scenario like this, represented in :numref:`fig_provenance_cycle`, would "
"create a cycle in the provenance graph, breaking the ‚Äúacyclicity‚Äù of the "
"DAG. To restore the directed acyclic graph, we separate the entire "
"provenance graph into two planes as described above: the **data provenance**"
" and the **logical provenance**. With this division, the acyclicity of the "
"graph is restored in the data provenance plane."
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:70
msgid ""
"An additional benefit of thinking of the provenance graph in these two "
"planes, is that it allows you to inspect it with different layers of "
"granularity. Imagine a high level workflow that calls a large number of "
"calculations and sub-workflows, that each may also call more sub-processes, "
"to finally produce and return one or more data nodes as its result."
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:75
msgid "Graph examples"
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:77
msgid ""
"With these basic definitions of AiiDA‚Äôs provenance graph in place, let‚Äôs "
"take a look at some examples. Consider the sequence of computations that "
"adds two numbers `x` and `y`, and then multiplies the result with a third "
"number `z`. This sequence as represented in the provenance graph would look "
"something like what is shown in :numref:`fig_provenance_add_multiply_data`."
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:84
msgid ""
"The DAG for computing `(x+y)*z`. We have two simple calculations: C\\ "
":sub:`1` represents the addition and C\\ :sub:`2` the multiplication. The "
"two data nodes D\\ :sub:`1` and D\\ :sub:`2` are the inputs of C\\ :sub:`1`,"
" which *creates* the data node D\\ :sub:`4`\\. Together with D\\ :sub:`3`, "
"D\\ :sub:`4` then forms the input of C\\ :sub:`2`, which multiplies their "
"values that *creates* the product, represented by D\\ :sub:`5`."
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:88
msgid ""
"In this simple example, there was no external process that controlled the "
"exact sequence of these operations. This may be imagined however, by adding "
"a workflow that calls the two calculations in succession, as shown in "
":numref:`fig_provenance_add_multiply_full`."
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:94
msgid ""
"The same calculation `(x+y)*z` is performed using a workflow. Here the data "
"nodes D\\ :sub:`1`, D\\ :sub:`2`, and D\\ :sub:`3` are the inputs of the "
"workflow W\\ :sub:`1`, which *calls* calculation C\\ :sub:`1` with inputs "
"D\\ :sub:`1` and D\\ :sub:`2`. It then *calls* calculation C\\ :sub:`2`, "
"using as inputs D\\ :sub:`3` and D\\ :sub:`4` (which was *created* by C\\ "
":sub:`2`\\). Calculation C\\ :sub:`2` *creates* data node D\\ :sub:`5`, "
"which is finally *returned* by workflow W\\ :sub:`1`\\."
msgstr ""

#: ../docs/source/topics/provenance/implementation.rst:98
msgid ""
"Notice that if we were to omit the workflow nodes and all its links from the"
" provenance graph in :numref:`fig_provenance_add_multiply_full`, one would "
"end up with the exact same graph as shown in "
":numref:`fig_provenance_add_multiply_data` (the **data provenance** graph)."
msgstr ""

#: ../docs/source/topics/provenance/index.rst:7
msgid ""
"In this topic section, the concept of the provenance graph and its "
"implementation will be explained. The "
":ref:`consistency<topics:provenance:consistency>` section details the rules "
"that are imposed on the consistency of the provenance graph when nodes are "
"exported or deleted."
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:7
#: ../docs/source/topics/workflows/usage.rst:9
msgid ""
"A workflow in AiiDA is a process (see the :ref:`process "
"section<topics:processes:concepts>` for details) that calls other workflows "
"and calculations and optionally *returns* data and as such can encode the "
"logic of a typical scientific workflow. Currently, there are two ways of "
"implementing a workflow process:"
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:10
msgid ":ref:`work functions<topics:workflows:concepts:workfunctions>`"
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:11
msgid ":ref:`work chains<topics:workflows:concepts:workchains>`"
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:13
msgid ""
"The first one is the simplest of the two and is basically a python function "
"that is magically transformed into a process. This is ideal for workflows "
"that are not very computationally intensive and can be easily implemented in"
" a python function. For more complex workflows, the work chain is a better "
"alternative. By chaining work chains and work functions together, that each "
"can run other sub processes, we can define a workflow. For simplicity, from "
"here on out, we will use the terms, workflows, work chains, and work "
"functions interchangeably, as a *pars pro toto* and *totum pro parte*."
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:19
msgid ""
"In the following sections, both concepts will be explained but without going"
" too much into detail on how to implement or run them. For a more detailed "
"expos√©, please refer to the respective advanced sections on :ref:`work "
"functions<topics:workflows:usage:workfunctions>` and :ref:`work "
"chains<topics:workflows:usage:workchains>`."
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:26
#: ../docs/source/topics/workflows/usage.rst:21
msgid "Work functions"
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:28
msgid ""
"A work function is implemented just as a :ref:`calculation "
"function<topics:calculations:concepts:calcfunctions>`, however, they have "
"very distinct use cases. Since the work function is a 'workflow-like' "
"process, it can only *return* existing data, whereas the calculation "
"function creates a 'calculation-like' process which can only *create* new "
"data. This difference is addressed in greater detail in the "
":ref:`process<topics:processes:concepts:types>` section and it is very "
"important that one understands this distinction."
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:32
msgid ""
"To explain the use of the ``@workfunction``, we will continue with the "
"example of the :ref:`calculation "
"functions<topics:calculations:concepts:calcfunctions>`, so before "
"continuing, read that section first. The example showed how the "
"``@calcfunction`` decorator can be used to create two functions that, for "
"three given integers, computes the sum of the first two, which is then "
"multiplied with the third, all the while keeping the provenance. Even though"
" the calculation functions ensured that the provenance of the data was kept,"
" the logic of *who* called these functions was not explicitly kept. From the"
" provenance graph generated by the calculation functions, it is impossible "
"to deduce whether the functions were called straight after another in a "
"single script, or whether first the ``add`` function was called and a long "
"time later, the output was used as an input for the ``multiply`` function. "
"Capturing this logical provenance of the *sequence of calls* of processes is"
" exactly what workflow-like processes, such as the ``workfunction`` are "
"designed for."
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:38
msgid ""
"Consider the following example, where we implement a function called "
"``add_and_multiply`` that we decorate with the ``@workfunction`` decorator."
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:43
msgid ""
"Instead of calling the calculation functions directly in the script, we call"
" the work function, which then consecutively calls the calculation "
"functions, passing the intermediate result from the first to the second. If "
"we look at the provenance graph generated by this example, we would see "
"something like the following:"
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:49
msgid "The full provenance generated by the work function example"
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:51
msgid ""
"It is clear that this provenance graph contains a lot more information than "
"the one for the calculation function example. Whether this information is "
"actually necessary or useful depends on the situation and is entirely up to "
"the user, but there is a big advantage. The strict separation between "
"calculation-like and workflow-like processes and the different allowed links"
" between them, as codified in the :ref:`provenance graph "
"implementation<topics:provenance:implementation>`, may seem a bit excessive "
"at a first glance and to new users. However, the addition of this parallel "
"yet distinct workflow layer that represents the logical provenance, allows "
"one to ignore all the details of the computation. This is demonstrated by "
"the provenance graph below, which is the exact same as the one before, "
"except only data and workflow nodes are shown:"
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:60
msgid ""
"The 'logical' provenance generated by the work function example, where only "
"the workflow and data nodes, with their links, are shown"
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:62
msgid ""
"With this reduced representation, the big picture of how the original inputs"
" led to the final result becomes immediately clear. Conversely, none of the "
"actual data provenance is lost. In the figure below, all the workflow nodes "
"are omitted and what we end up with is the exact same provenance graph as in"
" :numref:`fig_calculation_functions_provenance_add_multiply` of the "
":ref:`original example<topics:calculations:concepts:calcfunctions>` that "
"only used calculation functions."
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:69
msgid ""
"The 'data' provenance generated by the work function example, where only the"
" calculation and data nodes, with their links, are shown"
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:71
msgid ""
"In this simple example, the power of being able to select what part of the "
"provenance graph one is interested in is obviously limited. But workflows "
"can quickly become complex and deeply nested, at which point the ability to "
"group parts of the provenance graph together under a single node and "
"effectively 'hide' its internal parts in a transparent way, becomes "
"invaluable."
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:74
msgid ""
"In addition to the orchestration role that the work function can fullfill, "
"it can also be used as a filter or selection function. Imagine that you want"
" to write a process function that takes a set of input integer nodes and "
"returns the one with the highest value. We cannot employ the "
"``calcfunction`` for this, because it would have to return one of its input "
"nodes, which is explicitly forbidden. However, for the ``workfunction``, "
"returning existing nodes, even one of its inputs, is perfectly fine. An "
"example implementation might look like the following:"
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:83
msgid ""
"The work function above will return the input node ``x`` as one of its "
"outputs as it has the highest value. The provenance of the execution of this"
" select work function will look like the following:"
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:89
msgid ""
"The provenance generated by the work function that selects one of its input "
"nodes"
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:92
msgid ""
"It is important to realize once again that in the work function examples "
"given above, all the nodes returned by the work functions are *already "
"stored*. That is to say, they were either created by a calculation function "
"called by the work function or were passed in as one of the inputs. This is "
"no accident, as the work function **can** only return stored nodes. Trying "
"to return a node that was created by the work function itself, will raise an"
" exception. You can find a more detailed explanation for the reasoning "
"behind this design choice in the documentation on the various :ref:`process "
"types<topics:processes:concepts:types>` present in AiiDA and the "
":ref:`implementation of the provenance "
"graph<topics:provenance:implementation>`."
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:102
#: ../docs/source/topics/workflows/usage.rst:129
msgid "Work chains"
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:105
msgid "Why?"
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:107
msgid ""
"Now that we have demonstrated how easily ``workfunctions`` can be used to "
"write your workflow that automatically keeps the provenance, it is time to "
"confess that work functions are not perfect and have their shortcomings. In "
"the simple example of adding and multiplying numbers, the time to execute "
"the functions is very short, but imagine that you are performing a more "
"costly calculation, e.g. you want to run an actual ``CalcJob`` that will be "
"submitted to the scheduler and may run for a long time. If anywhere during "
"the chain, the workflow is interrupted, for whatever reason, all progress is"
" lost. There are no 'checkpoints', so to speak, by simply chaining work "
"functions together."
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:112
msgid ""
"But fret not! To tackle this problem, AiiDA defines the concept of the work "
"chain. As the name suggests, this construct is a way to chain multiple "
"logical steps of a workflow together in a way that allows to save the "
"progress between those steps as soon as they are successfully completed. The"
" work chain is therefore the preferred solution for parts of the workflow "
"that involve more expensive and complex calculations. To define a work "
"chain, AiiDA provides the "
":py:class:`~aiida.engine.processes.workchains.workchain.WorkChain` class."
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:121
msgid ""
"If we were to reimplement our work function solution of the simple example "
"problem of the previous section, but this time using a work chain, it would "
"look something like the following:"
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:126
msgid ""
"Don't be intimidated by all the code in this snippet. The point of this "
"example is not to explain the exact syntax, which will be done in greater "
"detail in the :ref:`advanced workflows<topics:workflows:usage:workchains>` "
"section, but to merely introduce the concept of the work chain. The core "
"attributes of a work chain are defined by its :ref:`process "
"specification<topics:processes:usage:spec>` which is setup in the "
":py:meth:`~aiida.engine.processes.process.Process.define` method. The only "
"thing you need to notice here, is that it defines the *inputs* that the work"
" chain takes, its logical *outline* and the *outputs* that it will produce. "
"The steps of the outline are implemented as class methods of the work chain."
" The ``add`` step will add the first two integers by calling the ``add`` "
"calculation function, and store the sum temporarily in the "
":ref:`context<topics:workflows:usage:workchains:context>`. The next step in "
"the outline, ``multiply``, will take the sum stored in the context that was "
"computed in the first outline step and call the ``multiply`` calculation "
"function with the third input integer. Finally, the ``result`` step will "
"take the product produced by the previous step and record it as an output of"
" the work chain. The resulting provenance when we run this work chain looks "
"like the following:"
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:139
msgid ""
"The provenance generated by the work chain example calling calculation "
"functions to perform the addition and multiplication."
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:141
msgid ""
"As you can see, the produced provenance graph is identical to that of "
":numref:`fig_work_functions_provenance_add_multiply_full` that was produced "
"by the work function solution, except that the workflow node is a work chain"
" instead of a work function node. Full data provenance is kept as the "
"calculation of the sum and the product through the work chain are "
"represented explicitly by the calculation nodes of the ``add`` and "
"``multiply`` calculation functions that are called."
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:146
msgid ""
"The usage of calculation functions for the computation of the sum and the "
"product is not an accident, but a concious design choice. Since work chains "
"are workflow-like processes and as such cannot *create* data, performing the"
" calculations directly in the work chain outline steps itself, would result "
"in a loss in the data provenance."
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:149
msgid ""
"To illustrate what it means for worklow processes not being able to *create*"
" new data and how doing so causes a loss of data provenance, let's change "
"the previous implementation to perform the sum and product in the work chain"
" outline steps itself, instead of calling the calculation functions."
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:154
msgid "The resulting provenance would look like the following:"
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:159
msgid ""
"The provenance generated by the work chain example that computes the sum and"
" product directly in its outline steps, instead of delegating it to "
"calculation functions"
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:161
msgid ""
"Note how, in contrast with the provenance of the previous correct solution "
"from :numref:`fig_work_chains_provenance_add_multiply_workchain_full`, there"
" are no explicit calculation nodes representing the computation of the sum "
"and the product. Instead, all that computation is abstracted and represented"
" by the single workflow node that represents the execution of the work "
"chain. The logic inside of those outline steps is then 'hidden' or "
"'encapsulated' in the provenance graph by a single workflow node. "
"Additionally, the output node representing the final product, only has a "
"``return`` link, even though it was *created* by the work chain. This is "
"because :ref:`workflow processes do not have the capacity to create new "
"nodes<topics:workflows:usage:workfunctions:returning_data>`, and therefore "
"in this example, the data provenance is lost."
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:167
msgid ""
"An important thing to remember is that *any computation* that happens in the"
" body of outline steps of a work chain, will not be explicitly represented, "
"but will be encapsulated by a single node in the graph that represents that "
"work chain execution. Whether that loss of data provenance is relevant "
"depends on the use case and is left to the developer of the workflow to "
"determine. These two examples demonstrate that AiiDA does not force any "
"particular method, but allows the user to choose exactly what level of "
"granularity they would like to maintain in the provenance. However, the rule"
" of thumb is that if you want to reduce the loss, or 'hiding' of provenance "
"to a minimum, one should keep real computation within the body of work "
"functions and work chains to a minimum and delegate that to calculations. "
"For any real computational work that is relevant to the data provenance, it "
"is better to implement it in explicit calculation processes, usually a "
"separate calculation function."
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:174
msgid "Advantages"
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:175
msgid ""
"The work chain solution to the add-multiply problem requires significantly "
"more code, compared to the work function solution presented in the beginning"
" of this section. Why should one then bother using the work chain? The "
"advantages for this trivial example may be difficult to see, but imagine the"
" logic of the workflow becomes more complicated and the calculations become "
"more intensive. The process specification of the work chain provides a "
"central way of defining the inputs and outputs, making it easy to see at a "
"glance how the work chain operates. In addition, the ``outline`` can give a "
"succinct summary of the logical steps that the work chain will perform, all "
"of which a work function does not have. The outline in this example was "
"trivially simple, but the :ref:`advanced work chain development "
"section<topics:workflows:usage:workchains>` will show how complex logic can "
"be implemented directly in the process specification. The process "
"specification also makes it easy to 'wrap' existing work chains into more "
"complex work chains through the :ref:`expose "
"functionality<topics:workflows:usage:workchains:expose_inputs_outputs>`."
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:183
msgid ""
"Finally, as mentioned before, the work chain provides the possibility of "
"checkpoints, i.e. to save progress at certain points from which the "
"computation can be continued after it had been interrupted. The state of the"
" work chain is saved after each outline step. If expensive calculation jobs "
"are performed in an individual outline step, they will be saved as soon as "
"they finish. This is impossible for work functions, and if it were to be "
"interrupted before *all* the computations had been completed, all "
"intermediate progress would be lost. The rule of thumb therefore is, as soon"
" as the worfklow becomes only slightly complex or computationally intensive,"
" preference should be given to :ref:`work "
"chains<topics:workflows:concepts:workchains>` and :ref:`calculation "
"jobs<topics:calculations:concepts:calcjobs>`."
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:189
msgid ""
"This was a very quick overview of the intended use of work chains and how "
"they work, but of course they have a lot more features. To learn how to "
"write work chains for real life problems, continue reading at the :ref:`work"
" chain development<topics:workflows:usage:workchains>` section, but before "
"you do, read the following part on when to use a work function and when it "
"is better to use a work chain."
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:194
msgid "When to use which"
msgstr ""

#: ../docs/source/topics/workflows/concepts.rst:195
msgid ""
"Now that we know how the two workflow components, work functions and work "
"chains, work in AiiDA, you might wonder: when should I use which one? For "
"simple operations that do not take long, the simplicity of the work function"
" may be all you need, so by all means use it. However, a good rule of thumb "
"is that as soon as the code is expected to take longer, for example when you"
" want to launch a :ref:`calculation "
"job<topics:calculations:concepts:calcjobs>` or another complex workflow, it "
"is always best to go for the work chain. The automatic checkpointing, which "
"guarantees that work between steps is saved, becomes very important. But the"
" work chain offers a lot more features than just checkpointing that may make"
" it more preferable over the work function, which you can read about in the "
"advanced :ref:`work chain development <topics:workflows:usage:workchains>` "
"section."
msgstr ""

#: ../docs/source/topics/workflows/index.rst:5
msgid "Workflows"
msgstr ""

#: ../docs/source/topics/workflows/index.rst:7
msgid ""
"This topic section provides detailed information on the concept of workflows"
" in AiiDA and an extensive guide on how to work with them. An introductory "
"guide to working with workflows can be found in :ref:`\"How to run multi-"
"step workflows\"<how-to:workflows>`."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:7
msgid ""
"This chapter assumes knowledge of the :ref:`basic "
"concept<topics:workflows:concepts>` and difference between work functions "
"and work chains is known and when one should use on or the other."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:12
msgid ":ref:`work function<topics:workflows:usage:workfunctions>`"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:13
msgid ":ref:`work chain<topics:workflows:usage:workchains>`"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:15
msgid ""
"This section will provide detailed information and best practices on how to "
"implement these two workflow types."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:23
msgid ""
"The concept of work functions and the basic rules of implementation are "
"documented in detail elsewhere:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:25
msgid ""
":ref:`concept of work functions<topics:workflows:concepts:workfunctions>`"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:26
msgid ":ref:`implementation of process functions<topics:processes:functions>`"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:28
msgid ""
"Since work functions are a sub type of process functions, just like "
"calculation functions, their implementation rules are as good as identical. "
"However, their intended aim and heuristics are very different. Where "
":ref:`calculation functions<topics:calculations:usage:calcfunctions>` are "
"'calculation'-like processes that *create* new data, work functions behave "
"like 'workflow'-like processes and can only *return* data. What this entails"
" in terms of intended usage and limitations for work functions is the scope "
"of this section."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:36
msgid "Returning data"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:37
msgid ""
"It has been said many times before: work functions, like all 'workflow'-like"
" processes, `return` data, but what does `return` mean exactly? In this "
"context, the term 'return' is not intended to refer to a piece of python "
"code returning a value. Instead it refers to a workflow process recording a "
"data node as one of its outputs, that *it itself did not create*, but which "
"rather was created by some other process, that was called by the workflow. "
"The calculation process was responsable for *creating* the data node and the"
" workflow is merely *returning* it as one of its outputs."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:42
msgid ""
"This is then exactly what the workfunction function does. It takes one or "
"more data nodes as inputs, calls other processes to which it passes those "
"inputs and optionally returns some or all of the outputs created by the "
"calculation processes it called. As explained in the :ref:`technical "
"section<topics:processes:functions>`, outputs are recorded as 'returned' "
"nodes simply by returning the nodes from the function. The engine will "
"inspect the return value from the function and attach the output nodes to "
"the node that represents the work function. To verify that the output nodes "
"are in fact not 'created', the engine will check that the nodes are stored. "
"Therefore, it is very important that you **do not store the nodes you create"
" yourself**, or the engine will raise an exception, as shown in the "
"following example:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:52
msgid ""
"Because the returned node is a newly created node and not stored, the engine"
" will raise the following exception:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:60
msgid ""
"Note that you could of course circumvent this check by calling ``store`` "
"yourself on the node, but that misses the point. The problem with using a "
"``workfunction`` to 'create' new data, is that the provenance is lost. To "
"illustrate this problem, let's go back to the simple problem of implementing"
" a workflow to add two integer and multiply the result with a third. The "
":ref:`correct implementation<topics:workflows:concepts:workfunctions>` has a"
" resulting provenance graph that clearly captures the addition and the "
"multiplication as separate calculation nodes, as shown in "
":numref:`fig_work_functions_provenance_add_multiply_full`. To illustrate "
"what would happen if one does does not call calculation functions to perform"
" the computations, but instead directly perform them in the work function "
"itself and return the result, consider the following example:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:69
#: ../docs/source/topics/workflows/usage.rst:88
msgid ""
"For the documentation skimmers: this is an explicit example on **how not to "
"use** work functions. The :ref:`correct "
"implementation<topics:workflows:concepts:workfunctions>` calls calculation "
"functions to perform the computation"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:71
msgid ""
"Note that in this example implementation we explicitly had to call ``store``"
" on the result before returning it to avoid the exception thrown by the "
"engine. The resulting provenance would look like the following:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:77
msgid ""
"The provenance generated by the incorrect work function implementation. Note"
" how the addition and multiplication are not explicitly represented, but are"
" implicitly hidden inside the workflow node. Moreover, the result node does "
"not have a 'create' link, because a work function cannot create new data."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:79
msgid ""
"However, looking at the generated provenance shows exactly why we shouldn't."
" This faulty implementation loses provenance as it has no explicit "
"representations of the addition and the multiplication and the `result` node"
" does not have a `create` link, which means that if only the data provenance"
" is followed, it is as if it appears out of thin air! Compare this to the "
"provenance graph of "
":numref:`fig_work_functions_provenance_add_multiply_full`, which was "
"generated by a solution that correctly uses calculation functions to perform"
" the computations. In this trivial example, one may think that this loss of "
"information is not so important, because it is implicitly captured by the "
"workflow node. But a halfway solution may make the problem more apparent, as"
" demonstrated by the following snippet where the addition is properly done "
"by calling a calculation function, but the final product is still performed "
"by the work function itself:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:90
msgid ""
"This time around the addition is correctly performed by a calculation "
"function as it should, however, its result is multiplied by the work "
"function itself and returned. Note that once again ``store`` had to be "
"called explicitly on ``product`` to avoid the engine throwing a "
"``ValueError``, which is only for the purpose of this example **and should "
"not be done in practice**. The resulting provenance would look like the "
"following:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:97
msgid ""
"The provenance generated by the incorrect work function implementation that "
"uses only a calculation function for the addition but performs the "
"multiplication itself. The red cross is there to indicate that there is no "
"actual connection between the intermediate sum `D4` and the final result "
"`D5`, even though the latter in reality derives from the former."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:100
msgid ""
"The generated provenance shows, that although the addition is explicitly "
"represented because the work function called the calculation function, there"
" is no connection between the sum and the final result. That is to say, "
"there is no direct link between the sum `D4` and the final result `D5`, as "
"indicated by the red cross, even though we know that the final answer was "
"based on the intermediate sum. This is a direct cause of the work function "
"'creating' new data and illustrates how, in doing so, the provenance of data"
" creation is lost."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:110
msgid ""
"To terminate the execution of a work function and mark it as failed, one "
"simply has to return an :ref:`exit code<topics:processes:usage:exit_codes>`."
" The :py:class:`~aiida.engine.processes.exit_code.ExitCode` class is "
"constructed with an integer, to denote the desired exit status and an "
"optional message When such as exit code is returned, the engine will mark "
"the node of the work function as ``Finished`` and set the exit status and "
"message to the value of the exit code. Consider the following example:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:122
msgid ""
"The execution of the work function will be immediately terminated as soon as"
" the exit code is returned, and the exit status and message will be set to "
"``418`` and ``I am a teapot``, respectively. Since no output nodes are "
"returned, the ``WorkFunctionNode`` node will have no outputs and the value "
"returned from the function call will be an empty dictionary."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:131
msgid ""
"The :ref:`basic concept of the work "
"chain<topics:workflows:concepts:workchains>` has been explained elsewhere. "
"This section will provide details on how a work chain can and should be "
"implemented. A work chain is implemented by the "
":py:class:`~aiida.engine.processes.workchains.workchain.WorkChain` class. "
"Since it is a sub class of the "
":py:class:`~aiida.engine.processes.process.Process` class, it shares all its"
" properties. It will be very valuable to have read the section on working "
"with :ref:`generic processes<topics:processes:usage>` before continuing, "
"because all the concepts explained there will apply also to work chains."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:137
msgid ""
"Let's continue with the example presented in the section on the "
":ref:`concept of workchains<topics:workflows:concepts:workchains>`, where we"
" sum two integers and multiply the result with a third. We provided a very "
"simple implementation in a code snippet, whose generated provenance graph, "
"when executed, is shown in "
":numref:`fig_work_chains_provenance_add_multiply_workchain_full`. For "
"convenience we copy the snippet here once more:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:144
msgid ""
"We will now got through the implementation step-by-step and go into more "
"detail on the interface and best practices."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:151
msgid ""
"To implement a new work chain, simply create a new class that sub classes "
":py:class:`~aiida.engine.processes.workchains.workchain.WorkChain`. You can "
"give the new class any valid python class name, but the convention is to "
"have it end in ``WorkChain`` so that it is always immediately clear what it "
"references. After having created a new work chain class, the first and most "
"important method to implement is the "
":py:meth:`~aiida.engine.processes.process.Process.define` method. This is a "
"class method that allows the developer to define the characteristics of the "
"work chain, such as what inputs it takes, what outputs it can generate, what"
" potential exit codes it can return and the logical outline through which it"
" will accomplish all this."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:156
msgid ""
"To implement the ``define`` method, you have to start with the following "
"three lines:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:164
msgid ""
"where you replace ``AddAndMultiplyWorkChain`` with the actual name of your "
"work chain. The ``@classmethod`` decorator indicates that this method is a "
"class method  [#f1]_ and not an instance method. The second line is the "
"method signature and specified that it will receive the class itself ``cls``"
" and ``spec`` which will be an instance of the "
":py:class:`~aiida.engine.processes.process_spec.ProcessSpec`. This is the "
"object that we will use to define our inputs, outputs and other relevant "
"properties of the work chain. The third and final line is extremely "
"important, as it will call the ``define`` method of the parent class, in "
"this case the "
":py:class:`~aiida.engine.processes.workchains.workchain.WorkChain` class."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:172
msgid ""
"If you forget to call ``super`` in the ``define`` method, your work chain "
"will fail miserably!"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:178
msgid "Inputs and outputs"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:179
msgid ""
"With those formalities out of the way, you can start defining the "
"interesting properties of the work chain through the ``spec``. In the "
"example you can see how the method :py:meth:`~plumpy.ProcessSpec.input` is "
"used to define multiple input ports, which document exactly which inputs the"
" work chain expects. Similarly, :py:meth:`~plumpy.ProcessSpec.output` is "
"called to instruct that the work chain will produce an output with the label"
" ``result``. These two port creation methods support a lot more "
"functionality, such as adding help string, validation and more, all of which"
" is documented in detail in the section on :ref:`ports and port "
"namespace<topics:processes:usage:ports_portnamespaces>`."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:188
msgid "Outline"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:189
msgid ""
"The outline is what sets the work chain apart from other processes. It is a "
"way of defining the higher-level logic that encodes the workflow that the "
"work chain takes. The outline is defined in the ``define`` method through "
"the :py:meth:`~plumpy.WorkChainSpec.outline`. It takes a sequence of "
"instructions that the work chain will execute, each of which is implemented "
"as a method of the work chain class. In the simple example above, the "
"outline consists of three simple instructions: ``add``, ``multiply``, "
"``results``. Since these are implemented as instance methods, they are "
"prefixed with ``cls.`` to indicate that they are in fact methods of the work"
" chain class. For that same reason, their implementation should take "
"``self`` as its one and only argument, as demonstrated in the example "
"snippet."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:197
msgid ""
"The outline in this simple example is not particular interesting as it "
"consists of three simple instructions that will be executed sequentially. "
"However, the outline also supports various logical constructs, such as "
"while-loops, conditionals and return statements. As usual, the best way to "
"illustrate these constructs is by example. The currently available logical "
"constructs for the work chain outline are:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:202
msgid "``if``, ``elif``, ``else``"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:203
msgid "``while``"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:204
msgid "``return``"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:206
msgid ""
"To distinguish these constructs from the python builtins, they are suffixed "
"with an underscore, like so ``while_``. To use these in your work chain "
"design, you will have to import them:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:213
msgid ""
"The following example shows how to use these logical constructs to define "
"the outline of a work chain:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:233
msgid ""
"This is an implementation (and an extremely contrived one at that) of the "
"well known FizzBuzz [#f2]_ problem. The idea is that the program is supposed"
" to print in sequence the numbers from zero to some limit, except when the "
"number is a multiple of three ``Fizz`` is printed, for a multiple of five "
"``Buzz`` and when it is a multiple of both, the program should print "
"``FizzBuzz``. Note how the syntax looks very much like that of normal python"
" syntax. The methods that are used in the conditionals (between the "
"parentheses of the ``while_`` and ``if_`` constructs) for example should "
"return a boolean; ``True`` when the condition holds and ``False`` otherwise."
" The actual implementation of the outline steps themselves is now trivial:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:259
msgid ""
"The intention of this example is to show that with a well designed outline, "
"a user only has to look at the outline to have a good idea *what* the work "
"chain does and *how* it does it. One should not have to look at the "
"implementation of the outline steps as all the important information is "
"captured by the outline itself. Since the goal of a work chain should be to "
"execute a very well defined task, it is the goal of the outline to capture "
"the required logic to achieve that goal, in a clear and short yet not overly"
" succint manner. The outline supports various logical flow constructs, such "
"as conditionals and while loops, so where possible this logic should be "
"expressed in the outline and not in the body of the outline functions. "
"However, one can also go overboard and put too finely grained logical blocks"
" into the outline, causing it to become bulky and difficult to understand."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:265
msgid ""
"A good rule of thumb in designing the outline is the following: before you "
"start designing a work chain, define very clearly the task that it should "
"carry out. Once the goal is clear, draw a schematic block diagram of the "
"necessary steps and logical decisions that connect them, in order to "
"accomplish that goal. Converting the resulting flow diagram in a one-to-one "
"fashion into an outline, often results in very reasonable outline designs."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:274
msgid ""
"There is one more property of a work chain that is specified through its "
"process specification, in addition to its inputs, outputs and outline. Any "
"work chain may have one to multiple failure modes, which are modeled by "
":ref:`exit codes<topics:processes:usage:exit_codes>`. A work chain can be "
"stopped at any time, simply by returning an exit code from an outline "
"method. To retrieve an exit code that is defined on the spec, one can use "
"the :py:meth:`~aiida.engine.processes.process.Process.exit_codes` property. "
"This returns an attribute dictionary where the exit code labels map to their"
" corresponding exit code. For example, with the following process spec:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:286
msgid ""
"To see how exit codes can be used to terminate the execution of work chains "
"gracefully, refer to the section "
":ref:`topics:workflows:usage:workchains:aborting_and_exit_codes`."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:292
msgid "Launching work chains"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:294
msgid ""
"The rules for launching work chains are the same as those for any other "
"process, which are detailed in :ref:`this "
"section<topics:processes:usage:launching>`. On top of those basic rules, "
"there is one peculiarity in the case of work chains when submitting to the "
"daemon. When you submit a ``WorkChain`` over the daemon, or any other "
"process for that matter, you need to make sure that the daemon can find the "
"class when it needs to load it. Registering your class through the plugin "
"system with a designated entry point is one way to make sure that the daemon"
" will be able to find it. If, however, you simply have a test class and do "
"not want to go through the effort of creating an entry point for it, you "
"should make sure that the module where you define the class is in the python"
" path. Additionally, make sure that the definition of the work chain **is "
"not in the same file from which you submit it**, or the engine won't be able"
" to load it."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:305
msgid "Context"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:306
msgid ""
"In the simplest work chain example presented in the introductory section, we"
" already saw how the context can be used to persist information during the "
"execution of a work chain and pass it between outline steps. The context is "
"essentially a data container, very similar to a dictionary that can hold all"
" sorts of data. The engine will ensure that its contents are saved and "
"persisted in between steps and when the daemon shuts down or restarts. A "
"trivial example of this would be the following:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:319
msgid ""
"In the ``step_one`` outline step we store the string ``'store me in the "
"context'`` in the context, which can be addressed as ``self.ctx``, under the"
" key ``some_variable``. Note that for the key you can use anything that "
"would be a valid key for a normal python dictionary. In the second outline "
"step ``step_two``, we can verify that the string was successfully persisted,"
" by checking the value stored in the context ``self.ctx.some_variable``."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:325
msgid "Any data that is stored in the context **has** to be serializable."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:327
msgid ""
"This was just a simple example to introduce the concept of the context, "
"however, it really is one of the more important parts of the work chain. The"
" context really becomes crucial when you want to submit a calculation or "
"another work chain from within the work chain. How this is accomplished, we "
"will show in the next section."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:334
msgid "Submitting sub processes"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:335
msgid ""
"One of the main tasks of a ``WorkChain`` will be to launch other processes, "
"such as a ``CalcJob`` or another ``WorkChain``. How to submit processes was "
"explained in :ref:`another section<topics:processes:usage:launch>` and is "
"accomplished by using the :py:func:`~aiida.engine.launch.submit` launch "
"function. However, when submitting a sub process from within a work chain, "
"**this should not be used**. Instead, the "
":py:class:`~aiida.engine.processes.process.Process` class provides its own "
":py:meth:`~aiida.engine.processes.process.Process.submit` method. If you do,"
" you will be greeted with the exception:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:345
msgid ""
"The only change you have to make is to replace the top-level ``submit`` "
"method with the built-in method of the process class:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:353
msgid ""
"The ``self.submit`` method has the exact same interface as the global "
"``aiida.engine.launch.submit`` launcher. When the ``submit`` method is "
"called, the process is created and submitted to the daemon, but at that "
"point it is not yet done. So the value that is returned by the ``submit`` "
"call is not the result of the submitted process, but rather it is the "
"process node that represents the execution of the process in the provenance "
"graph and acts as a *future*. We somehow need to tell the work chain that it"
" should wait for the sub process to be finished, and the future to resolve, "
"before it continues. To do so, however, control has to be returned to the "
"engine, which can then, when the process is completed, call the next step in"
" the outline, where we can analyse the results. The snippet above already "
"revealed that this is accomplished by returning an instance of the "
"``ToContext`` class."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:361
msgid "To context"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:362
msgid ""
"In order to store the future of the submitted process, we can store it in "
"the context with a special construct that will tell the engine that it "
"should wait for that process to finish before continuing the work chain. To "
"illustrate how this works, consider the following minimal example:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:368
msgid ""
"As explained in the previous section, calling ``self.submit`` for a given "
"process that you want to submit, will return a future. To add this future to"
" the context, we can not access the context directly as explained in the "
":ref:`context section<topics:workflows:usage:workchains:context>`, but "
"rather we need to use the class "
":py:class:`~aiida.engine.processes.workchains.context.ToContext`. This class"
" has to be imported from the ``aiida.engine`` module. To add the future to "
"the context, simply construct an instance of ``ToContext``, passing the "
"future as a keyword argument, and returning it from the outline step. The "
"keyword used, ``workchain`` in this example, will be the key used under "
"which to store the node in the context once its execution has terminated. "
"Returning an instance of ``ToContext`` signals to the engine that it has to "
"wait for the futures contained within it to finish execution, store their "
"nodes in the context under the specified keys and then continue to the next "
"step in the outline. In this example, that is the ``inspect_workchain`` "
"method. At this point we are sure that the process, a work chain in this "
"case, has terminated its execution, although not necessarily successful, and"
" we can continue the logic of the work chain."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:379
msgid ""
"Using the ``ToContext`` construct alone is not enough to tell the engine "
"that it should wait for the sub process to finish. There **needs** to be at "
"least another step in the outline to follow the step that added the "
"awaitables. If there is no more step to follow, according to the outline, "
"the engine interprets this as the work chain being done and so it will not "
"wait for the sub process to finish. Think about it like this: if there is "
"not even a single step to follow, there is also nothing the work chain could"
" do with the results of the sub process, so there is no point in waiting."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:384
msgid ""
"Sometimes one wants to launch not just one, but multiple processes at the "
"same time that can run in parallel. With the mechanism described above, this"
" will not be possible since after submitting a single process and returning "
"the ``ToContext`` instance, the work chain has to wait for the process to be"
" finished before it can continue. To solve this problem, there is another "
"way to add futures to the context:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:391
msgid ""
"Here we submit three work chains in a for loop in a single outline step, but"
" instead of returning an instance of ``ToContext``, we call the "
":meth:`~aiida.engine.processes.workchains.workchain.WorkChain.to_context` "
"method. This method has exactly the same syntax as the ``ToContext`` class, "
"except it is not necessary to return its value, so we can call it multiple "
"times in one outline step. Under the hood the functionality is also the same"
" as the ``ToContext`` class. At the end of the ``submit_workchains`` outline"
" step, the engine will find the futures that were added by calling "
"``to_context`` and will wait for all of them to be finished. The good thing "
"here is that these three sub work chains can be run in parallel and once all"
" of them are done, the parent work chain will go to the next step, which is "
"``inspect_workchains``. There we can find the nodes of the work chains in "
"the context under the key that was used as the keyword argument in the "
"``to_context`` call in the previous step."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:398
msgid ""
"Since we do not want the subsequent calls of ``to_context`` to override the "
"previous future, we had to create unique keys to store them under. In this "
"example, we chose to use the index of the for-loop. The name carries no "
"meaning and is just required to guarantee unique key names. This pattern "
"will occur often where you will want to launch multiple work chains or "
"calculations in parallel and will have to come up with unique names. In "
"essence, however, you are really just creating a list and it would be better"
" to be able to create a list in the context and simply append the future to "
"that list as you submit them. How this can be achieved is explained in the "
"next section."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:406
msgid "Appending"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:407
msgid ""
"When you want to add a future of a submitted sub process to the context, but"
" append it to a list rather than assign it to a key, you can use the "
":func:`~aiida.engine.processes.workchains.context.append_` function. "
"Consider the example from the previous section, but now we will use the "
"``append_`` function instead:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:413
msgid ""
"Notice that in the ``submit_workchains`` step we no longer have to generate "
"a unique key based on the index but we simply wrap the future in the "
"``append_`` function and assign it to the generic key ``workchains``. The "
"engine will see the ``append_`` function and instead of assigning the node "
"corresponding to the future to the key ``workchains``, it will append it to "
"the list stored under that key. If the list did not yet exist, it will "
"automatically be created. The ``self.ctx.workchains`` now contains a list "
"with the nodes of the completed work chains, with the same order as they had"
" been inserted, and so in the ``inspect_workchains`` step we can simply "
"iterate over it to access all of them. Note that the use of ``append_`` is "
"not just limited to the ``to_context`` method. You can also use it in "
"exactly the same way with ``ToContext`` to append a process to a list in the"
" context in multiple outline steps."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:423
msgid "Reporting"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:424
msgid ""
"During the execution of a ``WorkChain``, we may want to keep the user "
"abreast of its progress and what is happening. For this purpose, the "
"``WorkChain`` implements the "
":py:meth:`~aiida.engine.processes.process.Process.report` method, which "
"functions as a logger of sorts. It takes a single argument, a string, that "
"is the message that needs to be reported:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:433
msgid ""
"This will send that message to the internal logger of python, which will "
"cause it to be picked up by the default AiiDA logger, but it will also "
"trigger the database log handler, which will store the message in the "
"database and link it to the node of the work chain. This allows the ``verdi "
"process report`` command to retrieve all those messages that were fired "
"using the ``report`` method for a specific process. Note that the report "
"method, in addition to the pk of the work chain, will also automatically "
"record the name of the work chain and the name of the outline step in which "
"the report message was fired. This information will show up in the output of"
" ``verdi process report``, so you never have to explicitly reference the "
"work chain name, outline step name or date and time in the message itself."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:438
msgid ""
"It is important to note that the report system is a form of logging and as "
"such has been designed to be read by humans only. That is to say, the report"
" system is not designed to pass information programmatically by parsing the "
"log messages."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:444
msgid "Aborting and exit codes"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:445
msgid ""
"At the end of every outline step, the return value will be inspected by the "
"engine. If a non-zero integer value is detected, the engine will interpret "
"this as an exit code and will stop the execution of the work chain, while "
"setting its process state to ``Finished``. In addition, the integer return "
"value will be set as the ``exit_status`` of the work chain, which combined "
"with the ``Finished`` process state will denote that the worchain is "
"considered to be ``Failed``, as explained in the section on the "
":ref:`process state <topics:processes:concepts:state>`. This is useful "
"because it allows a workflow designer to easily exit from a work chain and "
"use the return value to communicate programmatically the reason for the work"
" chain stopping."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:450
msgid ""
"We assume that you have read the `section on how to define exit code "
"<exit_codes>`_ through the process specification of the work chain. Consider"
" the following example work chain that defines such an exit code:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:457
msgid ""
"Now imagine that in the outline, we launch a calculation and in the next "
"step check whether it finished successfully. In the event that the "
"calculation did not finish successfully, the following snippet shows how you"
" can retrieve the corresponding exit code and abort the ``WorkChain`` by "
"returning it:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:474
msgid ""
"In the ``inspect_calculation`` outline, we retrieve the calculation that was"
" submitted and added to the context in the previous step and check if it "
"finished successfully through the property ``is_finished_ok``. If this "
"returns ``False``, in this example we simply fire a report message and "
"return the exit code corresponding to the label "
"``ERROR_CALCULATION_FAILED``. Note that the specific exit code can be "
"retrieved through the ``WorkChain`` property ``exit_codes``. This will "
"return a collection of exit codes that have been defined for that "
"``WorkChain`` and any specific exit code can then be retrieved by accessing "
"it as an attribute. Returning this exit code, which will be an instance of "
"the :py:class:`~aiida.engine.processes.exit_code.ExitCode` class, will cause"
" the work chain to be aborted and the ``exit_status`` and ``exit_message`` "
"to be set on the node, which were defined in the spec."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:482
msgid ""
"The notation ``self.exit_codes.ERROR_CALCULATION_FAILED`` is just syntactic "
"sugar to retrieve the ``ExitCode`` instance that was defined in the spec "
"with that error label. Constructing your own ``ExitCode`` directly and "
"returning that from the outline step will have exactly the same effect in "
"terms of aborting the work chain execution and setting the exit status and "
"message. However, it is strongly advised to define the exit code through the"
" spec and retrieve it through the ``self.exit_codes`` collection, as that "
"makes it easily retrievable through the spec by the caller of the work "
"chain."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:486
msgid ""
"The ``message`` attribute of an ``ExitCode`` can also be a string that "
"contains placeholders. This is useful when the exit code's message is "
"generic enough to a host of situations, but one would just like to "
"parameterize the exit message. To concretize the template message of an exit"
" code, simply call the "
":meth:`~aiida.engine.processes.exit_code.ExitCode.format` method and pass "
"the parameters as keyword arguments::"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:492
msgid ""
"exit_code_template = ExitCode(450, 'the parameter {parameter} is invalid.') "
"exit_code_concrete = "
"exit_code_template.format(parameter='some_specific_key')"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:495
msgid ""
"This concept can also be applied within the scope of a process. In the "
"process spec, we can declare a generic exit code whose exact message should "
"depend on one or multiple parameters::"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:500
msgid ""
"spec.exit_code(450, 'ERROR_INVALID_PARAMETER, 'the parameter {parameter} is "
"invalid.')"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:502
msgid ""
"Through the ``self.exit_codes`` collection of a ``WorkChain``, this generic "
"can be easily customized as follows:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:509
msgid ""
"This is no different than the example before, because "
"``self.exit_codes.ERROR_INVALID_PARAMETER`` simply returns an instance of "
"``ExitCode``, which we then call ``format`` on with the substitution "
"parameters."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:511
msgid ""
"In conclusion, the best part about using exit codes to abort a work chain's "
"execution, is that the exit status can now be used programmatically, by for "
"example a parent work chain. Imagine that a parent work chain submitted this"
" work chain. After it has terminated its execution, the parent work chain "
"will want to know what happened to the child work chain. As already noted in"
" the :ref:`report<topics:workflows:usage:workchains:reporting>` section, the"
" report messages of the work chain should not be used. The exit status, "
"however, is a perfect way. The parent work chain can easily request the exit"
" status of the child work chain through the ``exit_status`` property, and "
"based on its value determine how to proceed."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:520
msgid "Modular workflow design"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:521
msgid ""
"When creating complex workflows, it is a good idea to split them up into "
"smaller, modular parts. At the lowest level, each workflow should perform "
"exactly one task. These workflows can then be wrapped together by a "
"\"parent\" workflow to create a larger logical unit."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:525
msgid ""
"In order to make this approach manageable, it needs to be as simple as "
"possible to glue together multiple workflows in a larger parent workflow. "
"One of the tools that AiiDA provides to simplify this is the ability to "
"*expose* the ports of another work chain."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:531
msgid "Exposing inputs and outputs"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:532
msgid ""
"Consider the following example work chain, which simply takes a few inputs "
"and returns them again as outputs:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:537
msgid ""
"As a first example, we will implement a thin wrapper workflow, which simply "
"forwards its inputs to ``ChildWorkChain``, and forwards the outputs of the "
"child to its outputs:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:542
msgid ""
"In the ``define`` method of this simple parent work chain, we use the "
":meth:`~plumpy.process_spec.ProcessSpec.expose_inputs` and "
":meth:`~plumpy.process_spec.ProcessSpec.expose_outputs`. This creates the "
"corresponding input and output ports in the parent work chain. Additionally,"
" AiiDA remembers which inputs and outputs were exposed from that particular "
"work chain class. This is used when calling the child in the ``run_child`` "
"method. The :meth:`~aiida.engine.processes.process.Process.exposed_inputs` "
"method returns a dictionary of inputs that the parent received which were "
"exposed from the child, and so it can be used to pass these on to the child."
" Finally, in the ``finalize`` method, we use "
":meth:`~aiida.engine.processes.process.Process.exposed_outputs` to retrieve "
"the outputs of the child which were exposed to the parent. Using "
":meth:`~aiida.engine.processes.process.Process.out_many`, these outputs are "
"added to the outputs of the parent work chain. This work chain can now be "
"run in exactly the same way as the child itself:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:554
msgid ""
"Next, we will see how a more complex parent work chain can be created by "
"using the additional features of the expose functionality. The following "
"work chain launches two children. These children share the input ``a``, but "
"have different ``b`` and ``c``. The output ``e`` will be taken only from the"
" first child, whereas ``d`` and ``f`` are taken from both children. In order"
" to avoid name conflicts, we need to create a *namespace* for each of the "
"two children, where the inputs and outputs which are not shared are stored. "
"Our goal is that the workflow can be called as follows:"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:564
msgid ""
"This is achieved by the following workflow. In the next section, we will "
"explain each of the steps."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:570
msgid ""
"First of all, we want to expose the ``a`` input and the ``e`` output at the "
"top-level. For this, we again use "
":meth:`~plumpy.process_spec.ProcessSpec.expose_inputs` and "
":meth:`~plumpy.process_spec.ProcessSpec.expose_outputs`, but with the "
"optional keyword ``include``. This specifies a list of keys, and only inputs"
" or outputs which are in that list will be exposed. So by passing "
"``include=['a']`` to :meth:`~plumpy.process_spec.ProcessSpec.expose_inputs`,"
" only the input ``a`` is exposed."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:575
msgid ""
"Additionally, we want to expose the inputs ``b`` and ``c`` (outputs ``d`` "
"and ``f``), but in a namespace specific for each of the two children. For "
"this purpose, we pass the ``namespace`` parameter to the expose functions. "
"However, since we now shouldn't expose ``a`` (``e``) again, we use the "
"``exclude`` keyword, which specifies a list of keys that will not be "
"exposed."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:579
msgid ""
"When calling the children, we again use the "
":meth:`~aiida.engine.processes.process.Process.exposed_inputs` method to "
"forward the exposed inputs. Since the inputs ``b`` and ``c`` are now in a "
"specific namespace, we need to pass this namespace as an additional "
"parameter. By default, "
":meth:`~aiida.engine.processes.process.Process.exposed_inputs` will search "
"through all the parent namespaces of the given namespace to search for "
"input, as shown in the call for ``child_1``. If the same input key exists in"
" multiple namespaces, the input in the lowest namespace takes precedence. "
"It's also possible to disable this behavior, and instead search only in the "
"explicit namespace that was passed. This is done by setting "
"``agglomerate=False``, as shown in the call to ``child_2``. Of course, we "
"then need to explicitly pass the input ``a``."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:587
msgid ""
"Finally, we use "
":meth:`~aiida.engine.processes.process.Process.exposed_outputs` and "
":meth:`~aiida.engine.processes.process.Process.out_many` to forward the "
"outputs of the children to the outputs of the parent. Again, the "
"``namespace`` and ``agglomerate`` options can be used to select which "
"outputs are returned by the "
":meth:`~aiida.engine.processes.process.Process.exposed_outputs` method."
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:594
msgid "https://docs.python.org/3.5/library/functions.html#classmethod"
msgstr ""

#: ../docs/source/topics/workflows/usage.rst:595
msgid "https://en.wikipedia.org/wiki/Fizz_buzz"
msgstr ""

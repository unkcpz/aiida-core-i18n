# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2019, ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE (Theory and Simulation of Materials (THEOS) and National Centre for Computational Design and Discovery of Novel Materials (NCCR MARVEL)), Switzerland and ROBERT BOSCH LLC, USA. All rights reserved
# This file is distributed under the same license as the AiiDA package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: AiiDA 1.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2019-05-17 21:47+0200\n"
"PO-Revision-Date: 2019-05-17 20:00+0000\n"
"Language-Team: Chinese (China) (https://www.transifex.com/aiidateam/teams/98967/zh_CN/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: zh_CN\n"
"Plural-Forms: nplurals=1; plural=0;\n"

#: ../docs/source/scheduler/index.rst:4
msgid "Supported schedulers"
msgstr ""

#: ../docs/source/scheduler/index.rst:6
msgid ""
"The list below describes the supported *schedulers*, i.e. the batch job "
"schedulers that manage the job queues and execution on any given computer."
msgstr ""

#: ../docs/source/scheduler/index.rst:9
msgid "PBSPro"
msgstr ""

#: ../docs/source/scheduler/index.rst:10
msgid ""
"The `PBSPro`_ scheduler is supported (and it has been tested with version "
"12.1)."
msgstr ""

#: ../docs/source/scheduler/index.rst:12 ../docs/source/scheduler/index.rst:23
#: ../docs/source/scheduler/index.rst:36 ../docs/source/scheduler/index.rst:55
#: ../docs/source/scheduler/index.rst:78
msgid "All the main features are supported with this scheduler."
msgstr ""

#: ../docs/source/scheduler/index.rst:14 ../docs/source/scheduler/index.rst:25
#: ../docs/source/scheduler/index.rst:57
msgid ""
"The :ref:`JobResource <job_resources>` class to be used when setting the job"
" resources is the :ref:`NodeNumberJobResource`."
msgstr ""

#: ../docs/source/scheduler/index.rst:19
msgid "SLURM"
msgstr ""

#: ../docs/source/scheduler/index.rst:21
msgid ""
"The `SLURM`_ scheduler is supported (and it has been tested with version "
"2.5.4)."
msgstr ""

#: ../docs/source/scheduler/index.rst:30
msgid "SGE"
msgstr ""

#: ../docs/source/scheduler/index.rst:32
msgid ""
"The `SGE`_ scheduler (Sun Grid Engine, now called Oracle Grid Engine) is "
"supported (and it has been tested with version GE 6.2u3), together with some"
" of the main variants/forks."
msgstr ""

#: ../docs/source/scheduler/index.rst:38
msgid ""
"The :ref:`JobResource <job_resources>` class to be used when setting the job"
" resources is the :ref:`ParEnvJobResource`."
msgstr ""

#: ../docs/source/scheduler/index.rst:43
msgid "LSF"
msgstr ""

#: ../docs/source/scheduler/index.rst:45
msgid ""
"The IBM `LSF`_ scheduler is supported and has been tested with version 9.1.3"
" on the CERN `lxplus` cluster."
msgstr ""

#: ../docs/source/scheduler/index.rst:51
msgid "Torque"
msgstr ""

#: ../docs/source/scheduler/index.rst:53
msgid ""
"`Torque`_ (based on OpenPBS) is supported (and it has been tested with "
"Torque v.2.4.16 from Ubuntu)."
msgstr ""

#: ../docs/source/scheduler/index.rst:64
msgid "Direct execution (bypassing schedulers)"
msgstr ""

#: ../docs/source/scheduler/index.rst:66
msgid ""
"The direct scheduler, to be used mainly for debugging, is an implementation "
"of a scheduler plugin that does not require a real scheduler installed, but "
"instead directly executes a command, puts it in the background, and checks "
"for its process ID (PID) to discover if the execution is completed."
msgstr ""

#: ../docs/source/scheduler/index.rst:69
msgid ""
"The direct execution mode is very fragile. Currently, it spawns a separate "
"Bash shell to execute a job and track each shell by process ID (PID). This "
"poses following problems:"
msgstr ""

#: ../docs/source/scheduler/index.rst:71
msgid "PID numeration is reset during reboots;"
msgstr ""

#: ../docs/source/scheduler/index.rst:72
msgid ""
"PID numeration is different from machine to machine, thus direct execution "
"is *not* possible in multi-machine clusters, redirecting each SSH login to a"
" different node in round-robin fashion;"
msgstr ""

#: ../docs/source/scheduler/index.rst:73
msgid ""
"there is no real queueing, hence, all calculation started will be run in "
"parallel."
msgstr ""

#: ../docs/source/scheduler/index.rst:76
msgid ""
"Direct execution bypasses schedulers, so it should be used with care in "
"order not to disturb the functioning of machines."
msgstr ""

#: ../docs/source/scheduler/index.rst:80
msgid ""
"The :ref:`JobResource <job_resources>` class to be used when setting the job"
" resources is the :ref:`NodeNumberJobResource`"
msgstr ""

#: ../docs/source/scheduler/index.rst:86
msgid "Job resources"
msgstr ""

#: ../docs/source/scheduler/index.rst:88
msgid ""
"When asking a scheduler to allocate some nodes/machines for a given job, we "
"have to specify some job resources, such as the number of required nodes or "
"the numbers of MPI processes per node."
msgstr ""

#: ../docs/source/scheduler/index.rst:90
msgid ""
"Unfortunately, the way of specifying this information is different on "
"different clusters. In AiiDA, this is implemented in different subclasses of"
" the :py:class:`aiida.schedulers.datastructures.JobResource` class. The "
"subclass that should be used is given by the scheduler, as described in the "
"previous section."
msgstr ""

#: ../docs/source/scheduler/index.rst:92
msgid ""
"The interfaces of these subclasses are not all exactly the same. Instead, "
"specifying the resources is similar to writing a scheduler script.  All "
"classes define at least one method, :meth:`get_tot_num_mpiprocs "
"<aiida.schedulers.datastructures.JobResource.get_tot_num_mpiprocs>`, that "
"returns the total number of MPI processes requested."
msgstr ""

#: ../docs/source/scheduler/index.rst:94
msgid ""
"In the following, the different :class:`JobResource "
"<aiida.schedulers.datastructures.JobResource>` subclasses are described:"
msgstr ""

#: ../docs/source/scheduler/index.rst:100
msgid ""
"you can manually load a `specific` :class:`JobResource "
"<aiida.schedulers.datastructures.JobResource>` subclass by directly "
"importing it, e..g. ::"
msgstr ""

#: ../docs/source/scheduler/index.rst:105
msgid ""
"However, in general, you will pass the fields to set directly to the "
":meth:`set_option "
"<aiida.orm.nodes.process.calculation.calcjob.CalcJobNode.set_option>` method"
" of a :class:`CalcJobNode "
"<aiida.orm.nodes.process.calculation.calcjob.CalcJobNode>` object with the "
"``resources`` key. For instance::"
msgstr ""

#: ../docs/source/scheduler/index.rst:118
msgid "NodeNumberJobResource (PBS-like)"
msgstr ""

#: ../docs/source/scheduler/index.rst:119
msgid ""
"This is the way of specifying the job resources in PBS and SLURM. The class "
"is :py:class:`aiida.schedulers.datastructures.NodeNumberJobResource`."
msgstr ""

#: ../docs/source/scheduler/index.rst:121
#: ../docs/source/scheduler/index.rst:178
msgid ""
"Once an instance of the class is obtained, you have the following fields "
"that you can set:"
msgstr ""

#: ../docs/source/scheduler/index.rst:123
msgid ""
"``res.num_machines``: specify the number of machines (also called nodes) on "
"which the code should run"
msgstr ""

#: ../docs/source/scheduler/index.rst:124
msgid ""
"``res.num_mpiprocs_per_machine``: number of MPI processes to use on each "
"machine"
msgstr ""

#: ../docs/source/scheduler/index.rst:125
#: ../docs/source/scheduler/index.rst:181
msgid ""
"``res.tot_num_mpiprocs``: the total number of MPI processes that this job is"
" requesting"
msgstr ""

#: ../docs/source/scheduler/index.rst:126
msgid ""
"``res.num_cores_per_machine``: specify the number of cores to use on each "
"machine"
msgstr ""

#: ../docs/source/scheduler/index.rst:127
msgid ""
"``res.num_cores_per_mpiproc``: specify the number of cores to run each MPI "
"process"
msgstr ""

#: ../docs/source/scheduler/index.rst:129
msgid ""
"Note that you need to specify only two among the first three fields above, "
"for instance::"
msgstr ""

#: ../docs/source/scheduler/index.rst:135
msgid ""
"asks the scheduler to allocate 4 machines, with 16 MPI processes on each "
"machine. This will automatically ask for a total of ``4*16=64`` total number"
" of MPI processes."
msgstr ""

#: ../docs/source/scheduler/index.rst:137
msgid ""
"The same can be achieved passing the fields directly to the constructor::"
msgstr ""

#: ../docs/source/scheduler/index.rst:141
msgid ""
"or, even better, directly calling the :meth:`set_option "
"<aiida.orm.nodes.process.calculation.calcjob.CalcJobNode.set_option>` method"
" of the :class:`CalcJobNode "
"<aiida.orm.nodes.process.calculation.calcjob.CalcJobNode>` class (assuming "
"here that ``calc`` is your calculation object) for the ``resources`` key::"
msgstr ""

#: ../docs/source/scheduler/index.rst:146
msgid ""
"If you specify res.num_machines, res.num_mpiprocs_per_machine, and "
"res.tot_num_mpiprocs fields (not recommended), make sure that they satisfy::"
msgstr ""

#: ../docs/source/scheduler/index.rst:150
msgid ""
"Moreover, if you specify ``res.tot_num_mpiprocs``, make sure that this is a "
"multiple of ``res.num_machines`` and/or ``res.num_mpiprocs_per_machine``."
msgstr ""

#: ../docs/source/scheduler/index.rst:153
msgid ""
"When creating a new computer, you will be asked for a "
"``default_mpiprocs_per_machine``. If you specify it, then you can avoid to "
"specify ``num_mpiprocs_per_machine`` when creating the resources for that "
"computer, and the default number will be used."
msgstr ""

#: ../docs/source/scheduler/index.rst:155
msgid ""
"Of course, all the requirements between ``num_machines``, "
"``num_mpiprocs_per_machine`` and ``tot_num_mpiprocs`` still apply."
msgstr ""

#: ../docs/source/scheduler/index.rst:157
msgid ""
"Moreover, you can explicitly specify ``num_mpiprocs_per_machine`` if you "
"want to use a value different from the default one."
msgstr ""

#: ../docs/source/scheduler/index.rst:160
msgid ""
"The num_cores_per_machine and num_cores_per_mpiproc fields are optional. If "
"you specify num_mpiprocs_per_machine and num_cores_per_machine fields, make "
"sure that::"
msgstr ""

#: ../docs/source/scheduler/index.rst:164
msgid ""
"If you want to specifiy single value in num_mpiprocs_per_machine and  "
"num_cores_per_machine, please make sure that res.num_cores_per_machine is "
"multiple of res.num_cores_per_mpiproc and/or res.num_mpiprocs_per_machine."
msgstr ""

#: ../docs/source/scheduler/index.rst:167
msgid ""
"In PBSPro, the num_mpiprocs_per_machine and num_cores_per_machine fields are"
" used for mpiprocs and ppn respectively."
msgstr ""

#: ../docs/source/scheduler/index.rst:170
msgid ""
"In Torque, the num_mpiprocs_per_machine field is used for ppn unless the "
"num_mpiprocs_per_machine is specified."
msgstr ""

#: ../docs/source/scheduler/index.rst:175
msgid "ParEnvJobResource (SGE-like)"
msgstr ""

#: ../docs/source/scheduler/index.rst:176
msgid ""
"In SGE and similar schedulers, one has to specify a *parallel environment* "
"and the *total number of CPUs* requested. The class is "
":py:class:`aiida.schedulers.datastructures.ParEnvJobResource`."
msgstr ""

#: ../docs/source/scheduler/index.rst:180
msgid ""
"``res.parallel_env``: specify the parallel environment in which you want to "
"run your job (a string)"
msgstr ""

#: ../docs/source/scheduler/index.rst:183
msgid ""
"Remember to always specify both fields. No checks are done on the "
"consistency between the specified parallel environment and the total number "
"of MPI processes requested (for instance, some parallel environments may "
"have been configured by your cluster administrator to run on a single "
"machine). It is your responsibility to make sure that the information is "
"valid, otherwise the  submission will fail."
msgstr ""

#: ../docs/source/scheduler/index.rst:185
msgid "Some examples:"
msgstr ""

#: ../docs/source/scheduler/index.rst:187
msgid "setting the fields one by one::"
msgstr ""

#: ../docs/source/scheduler/index.rst:193
msgid "setting the fields directly in the class constructor::"
msgstr ""

#: ../docs/source/scheduler/index.rst:197
msgid ""
"even better, directly calling the :meth:`set_option "
"<aiida.orm.nodes.process.calculation.calcjob.CalcJobNode.set_option>` method"
" of the :meth:`CalcJobNode "
"<aiida.orm.nodes.process.calculation.calcjob.CalcJobNode>` class (assuming "
"here that ``calc`` is your calculation object) for the ``resources`` key::"
msgstr ""

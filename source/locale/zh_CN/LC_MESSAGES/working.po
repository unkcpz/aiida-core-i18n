# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2019, ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE (Theory and Simulation of Materials (THEOS) and National Centre for Computational Design and Discovery of Novel Materials (NCCR MARVEL)), Switzerland and ROBERT BOSCH LLC, USA. All rights reserved
# This file is distributed under the same license as the AiiDA package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: AiiDA 1.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2019-05-15 14:09+0800\n"
"PO-Revision-Date: 2019-05-15 06:24+0000\n"
"Language-Team: Chinese (China) (https://www.transifex.com/scut-ccmp/teams/98995/zh_CN/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: zh_CN\n"
"Plural-Forms: nplurals=1; plural=0;\n"

#: ../../source/working/calculations.rst:5
msgid "Calculations"
msgstr ""

#: ../../source/working/calculations.rst:7
msgid ""
"A calculation is a process (see the :ref:`process "
"section<concepts_processes>` for details) that *creates* new data. "
"Currently, there are two ways of implementing a calculation process:"
msgstr ""

#: ../../source/working/calculations.rst:10
msgid ":ref:`calculation function<working_calcfunctions>`"
msgstr ""

#: ../../source/working/calculations.rst:11
msgid ":ref:`calculation job<working_calcjobs>`"
msgstr ""

#: ../../source/working/calculations.rst:13
msgid ""
"This section will provide detailed information and best practices on how to "
"implement these two calculation types."
msgstr ""

#: ../../source/working/calculations.rst:16
msgid ""
"This chapter assumes that the basic concept and difference between "
"calculation functions and calculation jobs is known and when one should use "
"on or the other. It is therefore crucial that, before you continue, you have"
" read and understood the basic concept of :ref:`calculation "
"processes<concepts_calculations>`."
msgstr ""

#: ../../source/working/calculations.rst:22
msgid "Calculation functions"
msgstr ""

#: ../../source/working/calculations.rst:24
msgid ""
"The section on the :ref:`concept of calculation "
"functions<concepts_calcfunctions>` already addressed their aim: automatic "
"recording of their execution with their inputs and outputs in the provenance"
" graph. The :ref:`section on process functions<working_process_functions>` "
"subsequently detailed the rules that apply when implementing them, all of "
"which to calculation functions, which are a sub type, just like work "
"functions. However, there are some differences given that calculation "
"functions are 'calculation'-like processes and work function behave like "
"'workflow'-like processes. What this entails in terms of intended usage and "
"limitations for calculation functions is the scope of this section."
msgstr ""

#: ../../source/working/calculations.rst:30
msgid "Creating data"
msgstr ""

#: ../../source/working/calculations.rst:31
msgid ""
"It has been said many times before: calculation functions, like all "
"'calculation'-like processes, `create` data, but what does `create` mean "
"exactly? In this context, the term 'create' is not intended to refer to the "
"simple creation of a new data node in the graph, in an interactive shell or "
"a script for example. But rather it indicates the creation of a new piece of"
" data from some other data through a computation implemented by a process. "
"This is then exactly what the calculation function does. It takes one or "
"more data nodes as inputs and returns one or more data nodes as outputs, "
"whose content is based on those inputs. As explained in the :ref:`technical "
"section<working_process_functions>`, outputs are created simply by returning"
" the nodes from the function. The engine will inspect the return value from "
"the function and attach the output nodes to the calculation node that "
"represents the calculation function. To verify that the output nodes are in "
"fact 'created', the engine will check that the nodes are not stored. "
"Therefore, it is very important that you **do not store the nodes you create"
" yourself**, or the engine will raise an exception, as shown in the "
"following example:"
msgstr ""

#: ../../source/working/calculations.rst:44
msgid ""
"Because the returned node is already stored, the engine will raise the "
"following exception:"
msgstr ""

#: ../../source/working/calculations.rst:52
msgid ""
"The reason for this strictness is that a node that was stored after being "
"created in the function body, is indistinguishable from a node that was "
"already stored and had simply been loaded in the function body and returned,"
" e.g.:"
msgstr ""

#: ../../source/working/calculations.rst:57
msgid ""
"The loaded node would also have gotten a `create` link from the calculation "
"function, even though it was not really created by it at all. It is exactly "
"to prevent this ambiguity that calculation functions require all returned "
"output nodes to be *unstored*."
msgstr ""

#: ../../source/working/calculations.rst:60
msgid ""
"Note that work functions have exactly the opposite required and all the "
"outputs that it returns **have to be stored**, because as a 'workflow'-like "
"process, it *cannot* create new data. For more details refer to the "
":ref:`work function section<working_workfunctions>`."
msgstr ""

#: ../../source/working/calculations.rst:66
msgid "Calculation jobs"
msgstr ""

#: ../../source/working/calculations.rst:68
msgid "`Issue [#2628] <https://github.com/aiidateam/aiida_core/issues/2628>`_"
msgstr ""

#: ../../source/working/functions.rst:5
msgid "Calculation and work functions"
msgstr ""

#: ../../source/working/functions.rst:7
msgid ""
"A process function is a process (see the :ref:`process "
"section<concepts_processes>` for details) that is implemented as a decorated"
" python function. Currently, there are two types of process functions:"
msgstr ""

#: ../../source/working/functions.rst:10
msgid ":ref:`calculation function<concepts_calcfunctions>`"
msgstr ""

#: ../../source/working/functions.rst:11
msgid ":ref:`work function<concepts_workfunctions>`"
msgstr ""

#: ../../source/working/functions.rst:13
msgid ""
"The former can *create* new data, whereas the latter can orchestrate other "
"processes and *return* their results. This section will provide detailed "
"information and best practices on how to implement these two process types. "
"Since the calculation function and work function are both process functions "
"and have the same implementation, all the rules explained below apply to "
"both process types."
msgstr ""

#: ../../source/working/functions.rst:18
msgid ""
"This chapter assumes that the basic concept and difference between "
"calculation functions and work functions is known and when one should use on"
" or the other. It is therefore crucial that, before you continue, you have "
"read and understood the basic concept of :ref:`calculation "
"functions<concepts_calcfunctions>` and :ref:`work "
"functions<concepts_workfunctions>`."
msgstr ""

#: ../../source/working/functions.rst:21
msgid ""
"The simple example in the :ref:`introductory section on calculation "
"functions<concepts_calcfunctions>` showed how a simple python function can "
"be turned into a calculation function simply by adorning it with the "
":py:func:`~aiida.engine.processes.functions.calcfunction` decorator. When "
"the function is run, AiiDA will dynamically generate a "
":py:class:`~aiida.engine.processes.functions.FunctionProcess` and build its "
":ref:`process specification<working_processes_spec>` based on the function "
"signature. Here we will explain how this is accomplished and what features "
"of the python function signature standard are supported."
msgstr ""

#: ../../source/working/functions.rst:26
msgid "Function signatures"
msgstr ""

#: ../../source/working/functions.rst:27
msgid ""
"To explain what features of python function definitions and calls are "
"supported we first need to be clear about some terminology. When dealing "
"with functions, there are two distinct parts:"
msgstr ""

#: ../../source/working/functions.rst:30
msgid ""
"`function definitions "
"<https://docs.python.org/3/reference/compound_stmts.html#function-"
"definitions>`_"
msgstr ""

#: ../../source/working/functions.rst:31
msgid ""
"`function calls "
"<https://docs.python.org/3/reference/expressions.html#calls>`_"
msgstr ""

#: ../../source/working/functions.rst:33
msgid ""
"Consider the following code snippet that defines a simple python function:"
msgstr ""

#: ../../source/working/functions.rst:38
msgid ""
"The function takes three 'parameters', named ``x``, ``y`` and ``z``. In "
"addition, the function ``plain_function`` is said to have default values, "
"because one or more parameters (``z`` in this case) have the form `parameter"
" = expression`. When *calling* a function, the terminology changes slightly "
"and values for parameters can be passed as either 'positional' or 'keyword'."
" In the example below, the function is called with 'positional' arguments:"
msgstr ""

#: ../../source/working/functions.rst:46
msgid ""
"They are called positional, because the arguments are not explicitly named "
"and so will be matched to the corresponding parameter solely based on their "
"position in the function call. In this example, ``x``, ``y`` and ``z`` will "
"have the values ``1``, ``2`` and ``3``, respectively. Since we specified "
"three values, the default for the third parameter ``z`` was not actually "
"used. However, we are allowed to only specify two arguments, in which case "
"the default *will* be used as can be seen below:"
msgstr ""

#: ../../source/working/functions.rst:54
msgid ""
"By not specifying the third argument, the default will be used, so in this "
"case ``z`` will equal ``1``. Additionally, one can employ 'named' arguments "
"to specifically target a parameter based on its name, instead of having to "
"rely on its position:"
msgstr ""

#: ../../source/working/functions.rst:60
msgid ""
"Notice how the order in which we pass the arguments is irrelevant because we"
" specify the name of each argument explicitly when assigning the value. Now "
"that we know the difference between positional and named arguments, it is "
"important to realize a python requirement that **positional arguments have "
"to come before named arguments**. What this means is that *both* the "
"function definition and function call below are illegal, because there are "
"named arguments before positional ones:"
msgstr ""

#: ../../source/working/functions.rst:67
msgid ""
"Finally, python knows the concept of ``*args`` and ``**kwargs``, also "
"referred to as variable arguments and keyword arguments, which allow one to "
"define a function which accepts an undetermined number of positional and "
"keyword arguments."
msgstr ""

#: ../../source/working/functions.rst:72
msgid ""
"The variable arguments ``*args`` will receive the positionally passed "
"arguments as a tuple and the keyword arguments ``**kwargs`` will receive the"
" named arguments as a dictionary. With the formal definitions out of the "
"way, let's now see which of these concepts are supported by process "
"functions."
msgstr ""

#: ../../source/working/functions.rst:76
msgid "Default arguments"
msgstr ""

#: ../../source/working/functions.rst:77
msgid ""
"Default arguments are supported by calculation functions just as normal "
"python functions as long as it is a :py:class:`~aiida.orm.nodes.node.Node` "
"instance, just like the inputs or ``None``. However, just as with python "
"functions, one should only use immutable objects as function defaults "
"because mutable objects can give unexpected results as they will be kept "
"between function calls. Therefore, in order to use a default value for "
"process functions, simply use ``None`` as the default value and check for "
"its presence in the function body settings the default value if it is "
"``None``. This pattern looks like the following:"
msgstr ""

#: ../../source/working/functions.rst:85
msgid ""
"Both function calls in the example above will have the exact same result."
msgstr ""

#: ../../source/working/functions.rst:88
msgid "Variable and keyword arguments"
msgstr ""

#: ../../source/working/functions.rst:89
msgid ""
"Variable arguments are *not* supported by process functions. The reasoning "
"behind this is that the process specification for the "
":py:class:`~aiida.engine.processes.functions.FunctionProcess` is built "
"dynamically based on the function signature and so the names of the inputs "
"are based on the parameter name from the function definition, or the named "
"argument when the function is called. Since for variable arguments, neither "
"at function definition nor at function call, explicit parameter names are "
"used, the engine can impossibly determine what names, and by extensions link"
" label, to use for the inputs."
msgstr ""

#: ../../source/working/functions.rst:93
msgid ""
"In contrast, keyword arguments for that reason *are* supported and it is the"
" keyword used when the function is called that determines the names of the "
"parameters and the labels of the input links. The following snippet is "
"therefore perfectly legal and will return the sum of all the nodes that are "
"passed:"
msgstr ""

#: ../../source/working/functions.rst:99
msgid "The provenance generated by this example looks like the following:"
msgstr ""

#: ../../source/working/functions.rst:104
msgid ""
"The link labels of the inputs are determined based on the naming of the "
"parameters when the function is called."
msgstr ""

#: ../../source/working/functions.rst:106
msgid ""
"Note that the inputs **have to be passed as keyword arguments** because they"
" are used for the link labels. If the inputs would simply have been passed "
"as positional arguments, the engine could have impossibly determined what "
"label to use for the links that connect the input nodes with the calculation"
" function node. For this reason, invoking a 'dynamic' function, i.e. one "
"that supports ``**kwargs`` in its signature, with more positional arguments "
"that explicitly named in the signature, will raise a ``TypeError``."
msgstr ""

#: ../../source/working/functions.rst:111
msgid "Return values"
msgstr ""

#: ../../source/working/functions.rst:112
msgid ""
"In :numref:`fig_calculation_functions_kwargs` you can see that the engine "
"used the label ``result`` for the link connecting the calculation function "
"node with its output node. This is the default link label if only a single "
"result is returned from the calculation function. If you want to specify a "
"label yourself, you can return the result in the form of a dictionary, where"
" the key will be used as the link label. By using a dictionary you can also "
"record multiple nodes as output. Consider the following snippet:"
msgstr ""

#: ../../source/working/functions.rst:121
msgid ""
"The provenance generated by running this calculation function will look "
"like:"
msgstr ""

#: ../../source/working/functions.rst:126
msgid ""
"If a dictionary is returned, the keys will be used as the labels for the "
"links that connect the output nodes with the calculation node."
msgstr ""

#: ../../source/working/functions.rst:128
msgid ""
"As always, all the values returned by a calculation function have to be "
"storable, which means they have to be instances of the "
":py:class:`~aiida.orm.nodes.node.Node` class."
msgstr ""

#: ../../source/working/functions.rst:131
msgid ""
"It is very important that you **do not call** "
":py:meth:`~aiida.orm.nodes.node.Node.store` **yourself** on the nodes before"
" returning them from a ``calcfunction``. Because of the calculation/workflow"
" duality in AiiDA, a ``calcfunction``, which is a calculation-like process, "
"can only *create* and not *return* data nodes. This means that if a node is "
"returned from a ``calcfunction`` that *is already stored*, the engine will "
"throw an exception."
msgstr ""

#: ../../source/working/functions.rst:137
#: ../../source/working/processes.rst:211
#: ../../source/working/workflows.rst:109
#: ../../source/working/workflows.rst:274
msgid "Exit codes"
msgstr ""

#: ../../source/working/functions.rst:138
msgid ""
"So far we have only seen examples of calculation functions where everything "
"works out just fine. However, the real world is different, and often we will"
" encounter situations where problems arise. A calculation function may "
"receive incorrect or incoherent inputs, or the code it executes may throw an"
" exception. Of course we could throw an input validation exception or not "
"even catch the exceptions that the code we call throws, but that will lead "
"the function process to be put in the ``Excepted`` terminal state. As "
"explained in the :ref:`process state<concepts_process_state>` section, this "
"state is indeed reserved for processes that incurred an exception during "
"execution. Consider the following calculation function definition and call:"
msgstr ""

#: ../../source/working/functions.rst:148
msgid ""
"Because the value for ``y`` that is being passed is zero, the engine will "
"encounter a ``ZeroDivisionError`` exception when the calculation function is"
" run. The output of ``verdi process list`` will confirm that the process has"
" excepted:"
msgstr ""

#: ../../source/working/functions.rst:159
msgid ""
"Exceptions that occur during the execution of a process are recorded as a "
"log message on the corresponding process node. To show these log messages, "
"one can use ``verdi process report``. In the case of the example above, it "
"would look something like the following:"
msgstr ""

#: ../../source/working/functions.rst:178
msgid ""
"However, in this particular example the exception is not so much an "
"unexpected error, but one we could have considered and have seen coming, so "
"it might be more applicable to simply mark the process as failed. To "
"accomplish this, there is the concept of an :ref:`exit "
"status<concepts_process_exit_codes>` that can be set on the process, which "
"is an integer that, when non-zero, marks a process in the ``Finished`` state"
" as 'failed'. Since the exit status is set as an attribute on the process "
"node, it also makes it very easy to query for failed processes. To set a "
"non-zero exit status on a calculation function to indicate it as failed, "
"simply return an instance of the "
":py:class:`~aiida.engine.processes.exit_code.ExitCode` named tuple. Time for"
" a demonstration:"
msgstr ""

#: ../../source/working/functions.rst:187
msgid ""
"When we run the calculation function now, with the same inputs, instead of "
"excepting, the process will successfully terminate and its exit status will "
"be set to the value stored in the ``ExitCode``. The exit status is also "
"displayed by ``verdi process list``:"
msgstr ""

#: ../../source/working/functions.rst:199
msgid ""
"Both approaches are valid and which one to use depends on your use case. The"
" question you should ask yourself is whether a potential problem merits "
"throwing the process on the pile of 'excepted' processes. Or maybe, as in "
"the example above, the problem is easily foreseeable and classifiable with a"
" well defined exit status, in which case it might make more sense to return "
"the exit code. At the end one should think which solution makes it easier "
"for a workflow calling the function to respond based on the result and what "
"makes it easier to query for these specific failure modes."
msgstr ""

#: ../../source/working/functions.rst:206
msgid "Provenance"
msgstr ""

#: ../../source/working/functions.rst:207
msgid ""
"In addition to the basic attributes that are stored for all processes such "
"as the process state and label, the process functions automatically store "
"additional information that relates to the source code of the function they "
"represent:"
msgstr ""

#: ../../source/working/functions.rst:209
msgid "Function name"
msgstr ""

#: ../../source/working/functions.rst:210
msgid "Function namespace"
msgstr ""

#: ../../source/working/functions.rst:211
msgid "Function starting line number"
msgstr ""

#: ../../source/working/functions.rst:212
msgid "Function source file"
msgstr ""

#: ../../source/working/functions.rst:214
msgid ""
"The first three are retrieved by inspecting the python source code as soon "
"as the process function is executed and are stored as attributes on the "
"process node. They can be accessed through the corresponding properties on "
"the process node as follows:"
msgstr ""

#: ../../source/working/functions.rst:220
msgid ""
"The source code of the file in which the function is defined is also stored,"
" but since it can be quite big, it is stored as a raw file in the repository"
" of the process node. It can be retrieved through the "
":py:meth:`~aiida.orm.utils.mixins.FunctionCalculationMixin.get_function_source_code`"
" method."
msgstr ""

#: ../../source/working/functions.rst:223
msgid ""
"The attributes give some querability to the process functions stored in the "
"provenance graph and by storing the source code of the function that was "
"executed, there will be some reference in the future to track how the "
"function created its output nodes. Note, however, that just storing the "
"source file of the function does not guarantee that one can reproduce the "
"exact result. For example, one can 'leak' data into the function by reading "
"a file or loading an existing node from the database that was not explicitly"
" passed as an input. Alternatively, external code can be imported and "
"called, the source code of which will not be recorded."
msgstr ""

#: ../../source/working/functions.rst:229
msgid "Reproducibility guidelines"
msgstr ""

#: ../../source/working/functions.rst:230
msgid ""
"Due to the nature of the way process functions are implemented, it is "
"impossible to guarantee 100% reproducibility, but by following the following"
" guidelines, one can come as close as possible."
msgstr ""

#: ../../source/working/functions.rst:232
msgid "Do not leak data into functions"
msgstr ""

#: ../../source/working/functions.rst:233
msgid "Limit importing of external code"
msgstr ""

#: ../../source/working/functions.rst:234
msgid "Keep functions self-consistent and in separate files"
msgstr ""

#: ../../source/working/functions.rst:236
msgid ""
"Leaking data into functions is accomplished for example by reading a file on"
" the local file system in the function body and using its contents for the "
"creation of the outputs. Even if you store the source code, if you don't "
"possess the file that was read, it is impossible to reproduce the results. "
"Likewise, you should not load any existing data from the database through "
"the API, but rather they should be direct inputs of the process function."
msgstr ""

#: ../../source/working/functions.rst:240
msgid ""
"A similar problem occurs when importing other python code. Practically, it "
"is almost impossible to never import code into process functions, as this "
"would force massive code duplication. However, there is still a difference "
"between importing code from the ``aiida-core`` library or the repository in "
"which the process function is hosted, and the importing of a local python "
"file. Even though for both cases there can no be guarantee of "
"reproducibility, the former stands a better chance by far, as the version "
"number of the plugin should be recorded. The rule of thumb then is to keep "
"the importing of code to a minimum, but if you have to, make sure to make it"
" part of a plugin package with a well-defined version number."
msgstr ""

#: ../../source/working/functions.rst:246
msgid ""
"Finally, as mentioned in the introduction, the source file of a process "
"function is stored as a file in the repository for *each execution*. "
"Currently there is no automatic deduplication for identical files by the "
"engine, so these files may occupy quite a bit of space. For this reason it "
"is advisable to keep each process function in its own separate file. This "
"not only improves readability, but it also minimizes the impact on the size "
"of the file repository."
msgstr ""

#: ../../source/working/processes.rst:5
msgid "Processes"
msgstr ""

#: ../../source/working/processes.rst:7
msgid ""
"Before you start working with processes, make sure you have read and "
"understood the :ref:`basic concept<concepts_processes>`. This section will "
"explain the aspects of working with processes that apply to all the various "
"types of processes. Details that only pertain to a specific sub type of "
"process, will be documented in their respective sections:"
msgstr ""

#: ../../source/working/processes.rst:11
msgid ":ref:`calculation functions<working_calcfunctions>`"
msgstr ""

#: ../../source/working/processes.rst:12
msgid ":ref:`calculation jobs<working_calcjobs>`"
msgstr ""

#: ../../source/working/processes.rst:13
msgid ":ref:`work functions<working_workfunctions>`"
msgstr ""

#: ../../source/working/processes.rst:14
msgid ":ref:`work chains<working_workchains>`"
msgstr ""

#: ../../source/working/processes.rst:16
msgid ""
"Since all of these are types of processes, everything that will be explained"
" in this section, will apply to each and everyone of them. That makes it "
"very useful to read and understand this section well, as the concepts apply "
"so broadly. However, for the same reason, at times this section may feel a "
"bit abstract. It may therefore be advisable to start reading a section on "
"one of the more specific processes listed above first, to get a more "
"concrete example, and then simply refer back here for a more extensive "
"explanation of the details."
msgstr ""

#: ../../source/working/processes.rst:25
msgid "Defining processes"
msgstr ""

#: ../../source/working/processes.rst:30
msgid "Process specification"
msgstr ""

#: ../../source/working/processes.rst:31
msgid ""
"How a process defines the inputs that it requires or can optionally take, "
"depends on the process type. The inputs of "
":py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` and "
":py:class:`~aiida.engine.processes.workchains.workchain.WorkChain` are given"
" by the :py:class:`~aiida.engine.processes.process_spec.ProcessSpec` class, "
"which is defined though  the "
":py:meth:`~aiida.engine.processes.process.Process.define` method. For "
"process functions, the "
":py:class:`~aiida.engine.processes.process_spec.ProcessSpec` is dynamically "
"generated by the engine from the signature of the decorated function. "
"Therefore, to determine what inputs a process takes, one simply has to look "
"at the process specification in the ``define`` method or the function "
"signature. For the "
":py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` and "
":py:class:`~aiida.engine.processes.workchains.workchain.WorkChain` there is "
"also the concept of the :ref:`process builder<working_processes_builder>`, "
"which will allow one to inspect the inputs with tab-completion and help "
"strings in the shell."
msgstr ""

#: ../../source/working/processes.rst:37
msgid ""
"The three most important attributes of the "
":py:class:`~aiida.engine.processes.process_spec.ProcessSpec` are:"
msgstr ""

#: ../../source/working/processes.rst:39
msgid "``inputs``"
msgstr ""

#: ../../source/working/processes.rst:40
msgid "``outputs``"
msgstr ""

#: ../../source/working/processes.rst:41
msgid "``exit_codes``"
msgstr ""

#: ../../source/working/processes.rst:43
msgid ""
"Through these attributes, one can define what inputs a process takes, what "
"outputs it will produce and what potential exit codes it can return in case "
"of errors. Just by looking at a process specification then, one will know "
"exactly *what* will happen, just not *how* it will happen. The ``inputs`` "
"and ``outputs`` attributes are *namespaces* that contain so called *ports*, "
"each one of which represents a specific input or output. The namespaces can "
"be arbitrarily nested with ports and so are called *port namespaces*. The "
"port and port namespace are implemented by the :py:class:`~plumpy.Port` and "
":py:class:`~aiida.engine.processes.ports.PortNamespace` class, respectively."
msgstr ""

#: ../../source/working/processes.rst:53
msgid "Ports and Port namespaces"
msgstr ""

#: ../../source/working/processes.rst:54
msgid ""
"To define an input for a process specification, we only need to add a port "
"to the ``inputs`` port namespace, as follows:"
msgstr ""

#: ../../source/working/processes.rst:61
msgid ""
"The ``input`` method, will create an instance of "
":py:class:`~aiida.engine.processes.ports.InputPort`, a sub class of the base"
" :py:class:`~plumpy.Port`, and will add it to the ``inputs`` port namespace "
"of the spec. Creating an output is just as easy, but one should use the "
":py:meth:`~plumpy.ProcessSpec.output` method instead:"
msgstr ""

#: ../../source/working/processes.rst:69
msgid ""
"This will cause an instance of "
":py:class:`~aiida.engine.processes.ports.OutputPort`, also a sub class of "
"the base :py:class:`~plumpy.Port`, to be created and to be added to the "
"``outputs`` specifcation attribute. Recall, that the ``inputs`` and "
"``output`` are instances of a "
":py:class:`~aiida.engine.processes.ports.PortNamespace`, which means that "
"they can contain any port. But the "
":py:class:`~aiida.engine.processes.ports.PortNamespace` itself is also a "
"port itself, so it can be added to another port namespace, allowing one to "
"create nested port namespaces. Creating a new namespace in for example the "
"inputs namespace is as simple as:"
msgstr ""

#: ../../source/working/processes.rst:79
msgid ""
"This will create a new ``PortNamespace`` named ``namespace`` in the "
"``inputs`` namespace of the spec. You can create arbitrarily nested "
"namespaces in one statement, by separating them with a ``.`` as shown here:"
msgstr ""

#: ../../source/working/processes.rst:87
msgid ""
"This command will result in the ``PortNamespace`` name ``namespace`` to be "
"nested inside another ``PortNamespace`` called ``nested``."
msgstr ""

#: ../../source/working/processes.rst:91
msgid ""
"Because the period is reserved to denote different nested namespaces, it "
"cannot be used in the name of terminal input and output ports as that could "
"be misinterpreted later as a port nested in a namespace."
msgstr ""

#: ../../source/working/processes.rst:93
msgid ""
"Graphically, this can be visualized as a nested dictionary and will look "
"like the following:"
msgstr ""

#: ../../source/working/processes.rst:103
msgid ""
"The ``outputs`` attribute of the ``ProcessSpec`` is also a ``PortNamespace``"
" just as the ``inputs``, with the only different that it will create "
"``OutputPort`` instead of ``InputPort`` instances. Therefore the same "
"concept of nesting through ``PortNamespaces`` applies to the outputs of a "
"``ProcessSpec``."
msgstr ""

#: ../../source/working/processes.rst:110
msgid "Validation and defaults"
msgstr ""

#: ../../source/working/processes.rst:111
msgid ""
"In the previous section, we saw that the ``ProcessSpec`` uses the "
"``PortNamespace``, ``InputPort`` and ``OutputPort`` to define the inputs and"
" outputs structure of the ``Process``. The underlying concept that allows "
"this nesting of ports is that the ``PortNamespace``, ``InputPort`` and "
"``OutputPort``, are all a subclass of :py:class:`~plumpy.ports.Port`. And as"
" different subclasses of the same class, they have more properties and "
"attributes in common, for example related to the concept of validation and "
"default values. All three have the following attributes (with the exception "
"of the ``OutputPort`` not having a ``default`` attribute):"
msgstr ""

#: ../../source/working/processes.rst:116
msgid "``default``"
msgstr ""

#: ../../source/working/processes.rst:117
msgid "``required``"
msgstr ""

#: ../../source/working/processes.rst:118
msgid "``valid_type``"
msgstr ""

#: ../../source/working/processes.rst:119
msgid "``validator``"
msgstr ""

#: ../../source/working/processes.rst:121
msgid ""
"These attributes can all be set upon construction of the port or after the "
"fact, as long as the spec has not been sealed, which means that they can be "
"altered without limit as long as it is within the ``define`` method of the "
"corresponding ``Process``. An example input port that explicitly sets all "
"these attributes is the following:"
msgstr ""

#: ../../source/working/processes.rst:128
msgid ""
"Here we define an input named ``positive_number`` that is not required, if a"
" value is not explicitly passed, the default ``Int(1)`` will be used and if "
"a value *is* passed, it should be of type ``Int`` or ``Float`` and it should"
" be valid according to the ``is_number_positive`` validator. Note that the "
"validator is nothing more than a free function which takes a single "
"argument, being the value that is to be validated and should return ``True``"
" if that value is valid or ``False`` otherwise, for example:"
msgstr ""

#: ../../source/working/processes.rst:136
msgid ""
"The ``valid_type`` can define a single type, or a tuple of valid types."
msgstr ""

#: ../../source/working/processes.rst:140
msgid ""
"Note that by default all ports are required, but specifying a default value "
"implies that the input is not required and as such specifying "
"``required=False`` is not necessary in that case. It was added to the "
"example above simply for clarity."
msgstr ""

#: ../../source/working/processes.rst:143
msgid ""
"The validation of input or output values with respect to the specification "
"of the corresponding port, happens at the instantiation of the process and "
"when it is finalized, respectively. If the inputs are invalid, a "
"corresponding exception will be thrown and the process instantiation will "
"fail. When the outputs fail to be validated, likewise an exception will be "
"thrown and the process state will be set to ``Excepted``."
msgstr ""

#: ../../source/working/processes.rst:151
msgid "Dynamic namespaces"
msgstr ""

#: ../../source/working/processes.rst:152
msgid ""
"In the previous section we described the various attributes related to "
"validation and claimed that all the port variants share those attributes, "
"yet we only discussed the ``InputPort`` and ``OutputPort`` explicitly. The "
"statement, however, is still correct and the ``PortNamespace`` has the same "
"attributes. You might then wonder what the meaning is of a ``valid_type`` or"
" ``default`` for a ``PortNamespace`` if all it does is contain "
"``InputPorts``, ``OutputPorts`` or other ``PortNamespaces``. The answer to "
"this question lies in the ``PortNamespace`` attribute ``dynamic``."
msgstr ""

#: ../../source/working/processes.rst:157
msgid ""
"Often when designing the specification of a ``Process``, we cannot know "
"exactly which inputs we want to be able to pass to the process. However, "
"with the concept of the ``InputPort`` and ``OutputPort`` one *does* need to "
"know exactly, how many value one expects at least, as they do have to be "
"defined. This is where the ``dynamic`` attribute of the ``PortNamespace`` "
"comes in. By default this is set to ``False``, but by setting it to "
"``True``, one indicates that that namespace can take a number of values that"
" is unknown at the time of definition of the specification. This now "
"explains the meaning of the ``valid_type``, ``validator`` and ``default`` "
"attributes in the context of the ``PortNamespace``. If you do mark a "
"namespace as dynamic, you may still want to limit the set of values that are"
" acceptable, which you can do by specifying the valid type and or validator."
" The values that will eventually be passed to the port namespace will then "
"be validated according to these rules exactly as a value for a regular input"
" port would be."
msgstr ""

#: ../../source/working/processes.rst:169
msgid "Non storable inputs"
msgstr ""

#: ../../source/working/processes.rst:170
msgid ""
"In principle, the only valid types for inputs and outputs should be "
"instances of a :py:class:`~aiida.orm.nodes.data.data.Data` node, or one of "
"its sub classes, as that is the only data type that can be recorded in the "
"provenance graph as an input or output of a process. However, there are "
"cases where you might want to pass an input to a process, whose provenance "
"you do not care about and therefore would want to pass a non-database "
"storable type anyway."
msgstr ""

#: ../../source/working/processes.rst:175
msgid ""
"AiiDA allows you to break the provenance as to be not too restrictive, but "
"always tries to urge you and guide you in a direction to keep the "
"provenance. There are legitimate reasons to break it regardless, but make "
"sure you think about the implications and whether you are really willing to "
"lose the information."
msgstr ""

#: ../../source/working/processes.rst:178
msgid ""
"For this situation, the ``InputPort`` has the attribute ``non_db``. By "
"default this is set to ``False``, but by setting it to ``True`` the port is "
"marked that the values that are passed to it should not be stored as a node "
"in the provenance graph and linked to the process node. This allows one to "
"pass any normal value that one would also be able to pass to a normal "
"function."
msgstr ""

#: ../../source/working/processes.rst:186
msgid "Automatic input serialization"
msgstr ""

#: ../../source/working/processes.rst:188
msgid ""
"Quite often, inputs which are given as python data types need to be cast to "
"the corresponding AiiDA type before passing them to a process. Doing this "
"manually can be cumbersome, so you can define a function when defining the "
"process specification, which does the conversion automatically. This "
"function, passed as ``serializer`` parameter to ``spec.input``, is invoked "
"if the given input is *not* already an AiiDA type."
msgstr ""

#: ../../source/working/processes.rst:192
msgid ""
"For inputs which are stored in the database (``non_db=False``), the "
"serialization function should return an AiiDA data type. For ``non_db`` "
"inputs, the function must be idempotent because it might be applied more "
"than once."
msgstr ""

#: ../../source/working/processes.rst:195
msgid ""
"The following example work chain takes three inputs ``a``, ``b``, ``c``, and"
" simply returns the given inputs. The "
":func:`aiida.orm.nodes.data.base.to_aiida_type` function is used as "
"serialization function."
msgstr ""

#: ../../source/working/processes.rst:200
msgid ""
"This work chain can now be called with native Python types, which will "
"automatically converted to AiiDA types by the "
":func:`aiida.orm.nodes.data.base.to_aiida_type` function. Note that the "
"module which defines the corresponding AiiDA type must be loaded for it to "
"be recognized by :func:`aiida.orm.nodes.data.base.to_aiida_type`."
msgstr ""

#: ../../source/working/processes.rst:205
msgid ""
"Of course, you can also use the serialization feature to perform a more "
"complex serialization of the inputs."
msgstr ""

#: ../../source/working/processes.rst:212
msgid ""
"Any ``Process`` most likely will have one or multiple expected failure "
"modes. To clearly communicate to the caller what went wrong, the ``Process``"
" supports setting its ``exit_status``. This ``exit_status``, a positive "
"integer, is an attribute of the process node and by convention, when it is "
"zero means the process was successful, whereas any other value indicates "
"failure. This concept of an exit code, with a positive integer as the exit "
"status, `is a common concept in programming <https://shapeshed.com/unix-"
"exit-codes/>`_ and a standard way for programs to communicate the result of "
"their execution."
msgstr ""

#: ../../source/working/processes.rst:217
msgid ""
"Potential exit codes for the ``Process`` can be defined through the "
"``ProcessSpec``, just like inputs and ouputs. Any exit code consists of a "
"positive non-zero integer, a string label to reference it and a more "
"detailed description of the problem that triggers the exit code. Consider "
"the following example:"
msgstr ""

#: ../../source/working/processes.rst:226
msgid ""
"This defines an exit code for the ``Process`` with exit status ``418`` and "
"exit message ``the work chain had an identity crisis``. The string "
"``ERROR_I_AM_A_TEAPOT`` is a label that the developer can use to reference "
"this particular exit code somewhere in the ``Process`` code itself."
msgstr ""

#: ../../source/working/processes.rst:229
msgid ""
"Whenever a ``Process`` exits through a particular error code, the caller "
"will be able to introspect it through the ``exit_status`` and "
"``exit_message`` attributes of the node. Assume for example that we ran a "
"``Process`` that threw the exit code described above, the caller would be "
"able to do the following:"
msgstr ""

#: ../../source/working/processes.rst:240
msgid ""
"This is useful, because the caller can now programmatically, based on the "
"``exit_status``, decide how to proceed. This is an infinitely more robust "
"way of communcating specific errors to a non-human then parsing text based "
"logs or reports. Additionally, The exit codes make it also very easy to "
"query for failed processes with specific error codes."
msgstr ""

#: ../../source/working/processes.rst:248
msgid "Process metadata"
msgstr ""

#: ../../source/working/processes.rst:250
msgid ""
"Each process, in addition to the normal inputs defined through its process "
"specifcation, can take optional 'metadata'. These metadata differ from "
"inputs in the sense that they are not nodes that will show up as inputs in "
"the provenance graph of the executed process. Rather, these are inputs that "
"slightly modify the behavior of the process or allow to set attributes on "
"the process node that represents its execution. The following metadata "
"inputs are available for *all* process classes:"
msgstr ""

#: ../../source/working/processes.rst:255
msgid "``label``: will set the label on the ``ProcessNode``"
msgstr ""

#: ../../source/working/processes.rst:256
msgid "``description``: will set the description on the ``ProcessNode``"
msgstr ""

#: ../../source/working/processes.rst:257
msgid ""
"``store_provenance``: boolean flag, by default ``True``, that when set to "
"``False``, will ensure that the execution of the process **is not** stored "
"in the provenance graph"
msgstr ""

#: ../../source/working/processes.rst:259
msgid ""
"Sub classes of the :py:class:`~aiida.engine.processes.process.Process` class"
" can specify further metadata inputs, refer to their specific documentation "
"for details. To pass any of these metadata options to a process, simply pass"
" them in a dictionary under the key ``metadata`` in the inputs when "
"launching the process. How a process can be launched is explained the "
"following section."
msgstr ""

#: ../../source/working/processes.rst:267
msgid "Launching processes"
msgstr ""

#: ../../source/working/processes.rst:268
msgid ""
"Any process can be launched by 'running' or 'submitting' it. Running means "
"to run the process in the current python interpreter in a blocking way, "
"whereas submitting means to send it to a daemon worker over RabbitMQ. For "
"long running processes, such as calculation jobs or complex workflows, it is"
" best advised to submit to the daemon. This has the added benefit that it "
"will directly return control to your interpreter and allow the daemon to "
"save intermediate progress during checkpoints and reload the process from "
"those if it has to restart. Running processes can be useful for trivial "
"computational tasks, such as simple calcfunctions or workfunctions, or for "
"debugging and testing purposes."
msgstr ""

#: ../../source/working/processes.rst:278
msgid "Process launch"
msgstr ""

#: ../../source/working/processes.rst:280
msgid ""
"To launch a process, one can use the free functions that can be imported "
"from the :py:mod:`aiida.engine` module. There are four different functions:"
msgstr ""

#: ../../source/working/processes.rst:283
msgid ":py:func:`~aiida.engine.launch.run`"
msgstr ""

#: ../../source/working/processes.rst:284
msgid ":py:func:`~aiida.engine.launch.run_get_node`"
msgstr ""

#: ../../source/working/processes.rst:285
msgid ":py:func:`~aiida.engine.launch.run_get_pk`"
msgstr ""

#: ../../source/working/processes.rst:286
msgid ":py:func:`~aiida.engine.launch.submit`"
msgstr ""

#: ../../source/working/processes.rst:288
msgid ""
"As the name suggest, the first three will 'run' the process and the latter "
"will 'submit' it to the daemon. Running means that the process will be "
"executed in the same interpreter in which it is launched, blocking the "
"interpreter, until the process is terminated. Submitting to the daemon, in "
"contrast, means that the process will be sent to the daemon for execution, "
"and the interpreter is released straight away."
msgstr ""

#: ../../source/working/processes.rst:292
msgid ""
"All functions have the exact same interface ``launch(process, **inputs)`` "
"where:"
msgstr ""

#: ../../source/working/processes.rst:294
msgid "``process`` is the process class or process function to launch"
msgstr ""

#: ../../source/working/processes.rst:295
msgid "``inputs`` are the inputs as keyword arguments to pass to the process."
msgstr ""

#: ../../source/working/processes.rst:297
msgid ""
"What inputs can be passed depends on the exact process class that is to be "
"launched. For example, when we want to run an instance of the "
":py:class:`~aiida.calculations.plugins.arithmetic.add.ArithmeticAddCalculation`"
" process, which takes two :py:class:`~aiida.orm.nodes.data.int.Int` nodes as"
" inputs under the name ``x`` and ``y`` [#f1]_, we would do the following:"
msgstr ""

#: ../../source/working/processes.rst:303
msgid ""
"The function will submit the calculation to the daemon and immediately "
"return control to the interpreter, returning the node that is used to "
"represent the process in the provenance graph."
msgstr ""

#: ../../source/working/processes.rst:306
msgid ""
"Process functions, i.e. python functions decorated with the ``calcfunction``"
" or ``workfunction`` decorators, **cannot be submitted** but can only be "
"run."
msgstr ""

#: ../../source/working/processes.rst:308
msgid "The ``run`` function is called identically:"
msgstr ""

#: ../../source/working/processes.rst:313
msgid ""
"except that it does not submit the process to the daemon, but executes it in"
" the current interpreter, blocking it until the process is terminated. The "
"return value of the ``run`` function is also **not** the node that "
"represents the executed process, but the results returned by the process, "
"which is a dictionary of the nodes that were produced as outputs. If you "
"would still like to have the process node or the pk of the process node you "
"can use one of the following variants:"
msgstr ""

#: ../../source/working/processes.rst:320
msgid ""
"Finally, the :py:func:`~aiida.engine.launch.run` launcher has two attributes"
" ``get_node`` and ``get_pk`` that are simple proxies to the "
":py:func:`~aiida.engine.launch.run_get_node` and "
":py:func:`~aiida.engine.launch.run_get_pk` methods. This is a handy "
"shortcut, as now you can choose to use any of the three variants with just a"
" single import:"
msgstr ""

#: ../../source/working/processes.rst:326
msgid ""
"If you want to launch a process class that takes a lot more inputs, often it"
" is useful to define them in a dictionary and use the python syntax ``**`` "
"that automatically expands it into keyword argument and value pairs. The "
"examples used above would look like the following:"
msgstr ""

#: ../../source/working/processes.rst:332
msgid ""
"Process functions, i.e. :ref:`calculation functions<concepts_calcfunctions>`"
" and :ref:`work functions<concepts_workfunctions>`, can be launched like any"
" other process as explained above, with the only exception that they "
"**cannot be submitted**. In addition to this limitation, process functions "
"have two additional methods of being launched:"
msgstr ""

#: ../../source/working/processes.rst:335
msgid "Simply *calling* the function"
msgstr ""

#: ../../source/working/processes.rst:336
msgid "Using the internal run method attributes"
msgstr ""

#: ../../source/working/processes.rst:338
msgid ""
"Using a calculation function to add two numbers as an example, these two "
"methods look like the following:"
msgstr ""

#: ../../source/working/processes.rst:347
msgid "Process builder"
msgstr ""

#: ../../source/working/processes.rst:348
msgid ""
"As explained in a :ref:`previous section<working_processes_spec>`, the "
"inputs for a :py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` "
"and :py:class:`~aiida.engine.processes.workchains.workchain.WorkChain` are "
"defined in the :py:meth:`~aiida.engine.processes.process.Process.define` "
"method. To know then what inputs they take, one would have to read the "
"implementation, which can be annoying if you are not a developer. To "
"simplify this process, these two process classes provide a utility called "
"the 'process builder'. The process builder is essentially a tool that helps "
"you build the inputs for the specific process class that you want to run. To"
" get a *builder* for a particular ``CalcJob`` or a ``WorkChain`` "
"implementation, all you need is the class itself, which can be loaded "
"through the :py:class:`~aiida.plugins.factories.CalculationFactory` and "
":py:class:`~aiida.plugins.factories.WorkflowFactory`, respectively. Let's "
"take the "
":py:class:`~aiida.calculations.plugins.arithmetic.add.ArithmeticAddCalculation`"
" as an example::"
msgstr ""

#: ../../source/working/processes.rst:358
msgid ""
"The string ``arithmetic.add`` is the entry point of the "
"``ArithmeticAddCalculation`` and passing it to the ``CalculationFactory`` "
"will return the corresponding class. Calling the ``get_builder`` method on "
"that class will return an instance of the "
":py:class:`~aiida.engine.processes.builder.ProcessBuilder` class that is "
"tailored for the ``ArithmeticAddCalculation``. The builder will help you in "
"defining the inputs that the ``ArithmeticAddCalculation`` requires and has a"
" few handy tools to simplify this process."
msgstr ""

#: ../../source/working/processes.rst:362
msgid ""
"To find out which inputs the builder exposes, you can simply use tab "
"completion. In an interactive python shell, by simply typing ``builder.`` "
"and hitting the tab key, a complete list of all the available inputs will be"
" shown. Each input of the builder can also show additional information about"
" what sort of input it expects. In an interactive shell, you can get this "
"information to display as follows::"
msgstr ""

#: ../../source/working/processes.rst:377
msgid ""
"In the ``Docstring`` you will see a ``help`` string that contains more "
"detailed information about the input port. Additionally, it will display a "
"``valid_type``, which when defined shows which data types are expected. If a"
" default value has been defined, that will also be displayed. The ``non_db``"
" attribute defines whether that particular input will be stored as a proper "
"input node in the database, if the process is submitted."
msgstr ""

#: ../../source/working/processes.rst:382
msgid ""
"Defining an input through the builder is as simple as assigning a value to "
"the attribute. The following example shows how to set the ``parameters`` "
"input, as well as the ``description`` and ``label`` metadata inputs::"
msgstr ""

#: ../../source/working/processes.rst:390
msgid ""
"If you evaluate the ``builder`` instance, simply by typing the variable name"
" and hitting enter, the current values of the builder's inputs will be "
"displayed::"
msgstr ""

#: ../../source/working/processes.rst:403
msgid ""
"In this example, you can see the value that we just set for the "
"``description`` and the ``label``. In addition, it will also show any "
"namespaces, as the inputs of processes support nested namespaces, such as "
"the ``metadata.options`` namespace in this example. Note that nested "
"namespaces are also all autocompleted, and you can traverse them recursively"
" with tab-completion."
msgstr ""

#: ../../source/working/processes.rst:407
msgid ""
"All that remains is to fill in all the required inputs and we are ready to "
"launch the process builder. When all the inputs have been defined for the "
"builder, it can be used to actually launch the ``Process``. The process can "
"be launched by passing the builder to any of the free functions "
":py:mod:`~aiida.engine.launch` module, just as you would do a normal process"
" as :ref:`described above<working_processes_launching>`, i.e.:"
msgstr ""

#: ../../source/working/processes.rst:414
msgid ""
"Note that the process builder is in principle designed to be used in an "
"interactive shell, as there is where the tab-completion and automatic input "
"documentation really shines. However, it is perfectly possible to use the "
"same builder in scripts where you simply use it as an input container, "
"instead of a plain python dictionary."
msgstr ""

#: ../../source/working/processes.rst:421
msgid "Monitoring processes"
msgstr ""

#: ../../source/working/processes.rst:422
msgid ""
"When you have launched a process, you may want to investigate its status, "
"progression and the results. The :ref:`verdi<verdi_overview>` command line "
"tool provides various commands to do just this."
msgstr ""

#: ../../source/working/processes.rst:429
msgid "verdi process list"
msgstr ""

#: ../../source/working/processes.rst:430
msgid ""
"Your first point of entry will be the ``verdi`` command ``verdi process "
"list``. This command will print a list of all active processes through the "
"``ProcessNode`` stored in the database that it uses to represent its "
"execution. A typical example may look something like the following:"
msgstr ""

#: ../../source/working/processes.rst:444
msgid ""
"The 'State' column is a concatenation of the ``process_state`` and the "
"``exit_status`` of the ``ProcessNode``. By default, the command will only "
"show active items, i.e. ``ProcessNodes`` that have not yet reached a "
"terminal state. If you want to also show the nodes in a terminal states, you"
" can use the ``-a`` flag and call ``verdi process list -a``:"
msgstr ""

#: ../../source/working/processes.rst:460
msgid ""
"For more information on the meaning of the 'state' column, please refer to "
"the documentation of the :ref:`process state <concepts_process_state>`. The "
"``-S`` flag let's you query for specific process states, i.e. issuing "
"``verdi process list -S created`` will return:"
msgstr ""

#: ../../source/working/processes.rst:472
msgid ""
"To query for a specific exit status, one can use ``verdi process list -E "
"0``:"
msgstr ""

#: ../../source/working/processes.rst:484
msgid ""
"This simple tool should give you a good idea of the current status of "
"running processes and the status of terminated ones. For a complete list of "
"all the available options, please refer to the documentation of :ref:`verdi "
"process<verdi_process>`."
msgstr ""

#: ../../source/working/processes.rst:487
msgid ""
"If you are looking for information about a specific process node, the "
"following three commands are at your disposal:"
msgstr ""

#: ../../source/working/processes.rst:489
msgid ""
"``verdi process report`` gives a list of the log messages attached to the "
"process"
msgstr ""

#: ../../source/working/processes.rst:490
msgid ""
"``verdi process status`` print the call hierarchy of the process and status "
"of all its nodes"
msgstr ""

#: ../../source/working/processes.rst:491
msgid ""
"``verdi process show`` print details about the status, inputs, outputs, "
"callers and callees of the process"
msgstr ""

#: ../../source/working/processes.rst:493
msgid ""
"In the following sections, we will explain briefly how the commands work. "
"For the purpose of example, we will show the output of the commands for a "
"completed ``PwBaseWorkChain`` from the ``aiida-quantumespresso`` plugin, "
"which simply calls a ``PwCalculation``."
msgstr ""

#: ../../source/working/processes.rst:500
msgid "verdi process report"
msgstr ""

#: ../../source/working/processes.rst:501
msgid ""
"The developer of a process can attach log messages to the node of a process "
"through the :py:meth:`~aiida.engine.processes.process.Process.report` "
"method. The ``verdi process report`` command will display all the log "
"messages in chronological order:"
msgstr ""

#: ../../source/working/processes.rst:511
msgid ""
"The log message will include a timestamp followed by the level of the log, "
"which is always ``REPORT``. The second block has the format ``pk|class "
"name|function name`` detailing information about, in this case, the work "
"chain itself and the step in which the message was fired. Finally, the "
"message itself is displayed. Of course how many messages are logged and how "
"useful they are is up to the process developer. In general they can be very "
"useful for a user to understand what has happened during the execution of "
"the process, however, one has to realize that each entry is stored in the "
"database, so overuse can unnecessarily bloat the database."
msgstr ""

#: ../../source/working/processes.rst:521
msgid "verdi process status"
msgstr ""

#: ../../source/working/processes.rst:522
msgid ""
"This command is most useful for ``WorkChain`` instances, but also works for "
"``CalcJobs``. One of the more powerful aspect of work chains, is that they "
"can call ``CalcJobs`` and other ``WorkChains`` to create a nested call "
"hierarchy. If you want to inspect the status of a work chain and all the "
"children that it called, ``verdi process status`` is the go-to tool. An "
"example output is the following:"
msgstr ""

#: ../../source/working/processes.rst:532
msgid ""
"The command prints a tree representation of the hierarchical call structure,"
" that recurses all the way down. In this example, there is just a single "
"``PwBaseWorkChain`` which called a ``PwCalculation``, which is indicated by "
"it being indented one level. In addition to the call tree, each node also "
"shows its current process state and for work chains at which step in the "
"outline it is. This tool can be very useful to inspect while a work chain is"
" running at which step in the outline it currently is, as well as the status"
" of all the children calculations it called."
msgstr ""

#: ../../source/working/processes.rst:541
msgid "verdi process show"
msgstr ""

#: ../../source/working/processes.rst:542
msgid ""
"Finally, there is a command that displays detailed information about the "
"``ProcessNode``, such as its inputs, outputs and the optional other "
"processes it called and or was called by. An example output for a "
"``PwBaseWorkChain`` would look like the following:"
msgstr ""

#: ../../source/working/processes.rst:586
msgid ""
"This overview should give you all the information if you want to inspect a "
"process' inputs and outputs in closer detail as it provides you their pk's."
msgstr ""

#: ../../source/working/processes.rst:592
msgid "Manipulating processes"
msgstr ""

#: ../../source/working/processes.rst:593
msgid ""
"To understand how one can manipulate running processes, one has to "
"understand the principles of the :ref:`process/node "
"distinction<concepts_process_node_distinction>` and a :ref:`process' "
"lifetime<concepts_process_lifetime>` first, so be sure to have read those "
"sections first."
msgstr ""

#: ../../source/working/processes.rst:599
msgid "verdi process pause/play/kill"
msgstr ""

#: ../../source/working/processes.rst:600
msgid ""
"The ``verdi`` command line interface provides three commands to interact "
"with 'live' processes."
msgstr ""

#: ../../source/working/processes.rst:602
msgid "``verdi process pause``"
msgstr ""

#: ../../source/working/processes.rst:603
msgid "``verdi process play``"
msgstr ""

#: ../../source/working/processes.rst:604
msgid "``verdi process kill``"
msgstr ""

#: ../../source/working/processes.rst:606
msgid ""
"The first pauses a process temporarily, the second resumes any paused "
"processes and the third one permanently kills them. The sub command names "
"might seem to tell you this already and it might look like that is all there"
" is to know, but the functionality underneath is quite complicated and "
"deserves additional explanation nonetheless."
msgstr ""

#: ../../source/working/processes.rst:609
msgid ""
"As the section on :ref:`the distinction between the process and the "
"node<concepts_process_node_distinction>` explained, manipulating a process "
"means interacting with the live process instance that lives in the memory of"
" the runner that is running it. By definition, these runners will always run"
" in a different system process then the one from which you want to interact,"
" because otherwise, you would *be* the runner, given that there can only be "
"a single runner in an interpreter and if it is running, the interpreter "
"would be blocked from performing any other operations. This means that in "
"order to interact with the live process, one has to interact with another "
"interpreter running in a different system process. This is once again "
"facilitated by the RabbitMQ message broker. When a runner starts to run a "
"process, it will also add listeners for incoming messages that are being "
"sent for that specific process over RabbitMQ."
msgstr ""

#: ../../source/working/processes.rst:617
msgid ""
"This does not just apply to daemon runners, but also normal runners. That is"
" to say that if you were to launch a process in a local runner, that "
"interpreter will be blocked, but it will still setup the listeners for that "
"process on RabbitMQ. This means that you can manipulate the process from "
"another terminal, just as if you would do with a process that is being run "
"by a daemon runner."
msgstr ""

#: ../../source/working/processes.rst:621
msgid ""
"In the case of 'pause', 'play' and 'kill', one is sending what is called a "
"Remote Procedure Call (RPC) over RabbitMQ. The RPC will include the process "
"identifier for which the action is intended and RabbitMQ will send it to "
"whoever registered itself to be listening for that specific process, in this"
" case the runner that is running the process. This immediately reveals a "
"potential problem: the RPC will fall on deaf ears if there is no one "
"listening, which can have multiple causes. For example, as explained in the "
"section on a :ref:`process' lifetime<concepts_process_lifetime>`, this can "
"be the case for a submitted process, where the corresponding task is still "
"queued, as all available process slots are occupied. But even if the task "
"*were* to be with a runner, it might be too busy to respond to the RPC and "
"the process appears to be unreachable. Whenever a process is unreachable for"
" an RPC, the command will return an error:"
msgstr ""

#: ../../source/working/processes.rst:632
msgid ""
"Depending on the cause of the process being unreachable, the problem may "
"resolve itself automatically over time and one can try again at a later "
"time, as for example in the case of the runner being too busy to respond. "
"However, to prevent this from happening, the runner has been designed to "
"have the communication happen over a separate thread and to schedule "
"callbacks for any necessary actions on the main thread, which performs all "
"the heavy lifting. This should make occurrences of the runner being too busy"
" to respond very rare. If you think the The problem is, however, there is "
"unfortunately no way of telling what the actual problem is for the process "
"not being reachable. The problem will manifest itself identically if the "
"runner just could not respond in time or if the task has accidentally been "
"lost forever due to a bug, even though these are two completely separate "
"situations."
msgstr ""

#: ../../source/working/processes.rst:639
msgid ""
"This brings us to another potential unintuitive aspect of interacting with "
"processes. The previous paragraph already mentioned it in passing, but when "
"a remote procedure call is sent, it first needs to be answered by the "
"responsible runner, if applicable, but it will not *directly execute* the "
"call. This is because the call will be incoming on the communcation thread "
"who is not allowed to have direct access to the process instance, but "
"instead it will schedule a callback on the main thread who can perform the "
"action. The callback will however not necessarily be executed directly, as "
"there may be other actions waiting to be performed. So when you pause, play "
"or kill a process, you are not doing so directly, but rather you are "
"*scheduling* a request to do so. If the runner has successfully received the"
" request and scheduled the callback, the command will therefore show "
"something like the following:"
msgstr ""

#: ../../source/working/processes.rst:650
msgid ""
"The 'scheduled' indicates that the actual killing might not necessarily have"
" happened just yet. This means that even after having called ``verdi process"
" kill`` and getting the success message, the corresponding process may still"
" be listed as active in the output of ``verdi process list``."
msgstr ""

#: ../../source/working/processes.rst:653
msgid ""
"By default, the ``pause``, ``play`` and ``kill`` commands will only ask for "
"the confirmation of the runner that the request has been scheduled and not "
"actually wait for the command to have been executed. This is because, as "
"explained, the actual action being performed might not be instantaneous as "
"the runner may be busy working with other processes, which would mean that "
"the command would block for a long time. If you want to send multiple "
"requests to a lot of processes in one go, this would be ineffective, as each"
" one would have to wait for the previous one to be completed. To change the "
"default and actually wait for the action to be completed and await its "
"response, you can use the ``--wait`` flag. If you know that your daemon "
"runners may be experiencing a heavy load, you can also increase the time "
"that the command waits before timing out, with the ``-t/--timeout`` flag."
msgstr ""

#: ../../source/working/processes.rst:661
#: ../../source/working/workflows.rst:569
msgid "Footnotes"
msgstr ""

#: ../../source/working/processes.rst:662
msgid ""
"Note that the "
":py:class:`~aiida.calculations.plugins.arithmetic.add.ArithmeticAddCalculation`"
" process class also takes a ``code`` as input, but that has been omitted for"
" the purposes of the example."
msgstr ""

#: ../../source/working/workflows.rst:5
msgid "Workflows"
msgstr ""

#: ../../source/working/workflows.rst:7
msgid ""
"A workflow in AiiDA is a process (see the :ref:`process "
"section<concepts_processes>` for details) that calls other workflows and "
"calculations and optionally *returns* data and as such can encode the logic "
"of a typical scientific workflow. Currently, there are two ways of "
"implementing a workflow process:"
msgstr ""

#: ../../source/working/workflows.rst:10
msgid ":ref:`work function<working_workfunctions>`"
msgstr ""

#: ../../source/working/workflows.rst:11
msgid ":ref:`work chain<working_workchains>`"
msgstr ""

#: ../../source/working/workflows.rst:13
msgid ""
"This section will provide detailed information and best practices on how to "
"implement these two workflow types."
msgstr ""

#: ../../source/working/workflows.rst:16
msgid ""
"This chapter assumes that the basic concept and difference between work "
"functions and work chains is known and when one should use on or the other. "
"It is therefore crucial that, before you continue, you have read and "
"understood the basic concept of :ref:`workflow "
"processes<concepts_workflows>`."
msgstr ""

#: ../../source/working/workflows.rst:22
msgid "Work functions"
msgstr ""

#: ../../source/working/workflows.rst:24
msgid ""
"The concept of work functions and the basic rules of implementation are "
"documented in detail elsewhere:"
msgstr ""

#: ../../source/working/workflows.rst:26
msgid ":ref:`concept of work functions<concepts_workfunctions>`"
msgstr ""

#: ../../source/working/workflows.rst:27
msgid ":ref:`implementation of process functions<working_process_functions>`"
msgstr ""

#: ../../source/working/workflows.rst:29
msgid ""
"Since work functions are a sub type of process functions, just like "
"calculation functions, their implementation rules are as good as identical. "
"However, their intended aim and heuristics are very different. Where "
":ref:`calculation functions<working_calcfunctions>` are 'calculation'-like "
"processes that *create* new data, work functions behave like 'workflow'-like"
" processes and can only *return* data. What this entails in terms of "
"intended usage and limitations for work functions is the scope of this "
"section."
msgstr ""

#: ../../source/working/workflows.rst:37
msgid "Returning data"
msgstr ""

#: ../../source/working/workflows.rst:38
msgid ""
"It has been said many times before: work functions, like all 'workflow'-like"
" processes, `return` data, but what does `return` mean exactly? In this "
"context, the term 'return' is not intended to refer to a piece of python "
"code returning a value. Instead it refers to a workflow process recording a "
"data node as one of its outputs, that *it itself did not create*, but which "
"rather was created by some other process, that was called by the workflow. "
"The calculation process was responsable for *creating* the data node and the"
" workflow is merely *returning* it as one of its outputs."
msgstr ""

#: ../../source/working/workflows.rst:43
msgid ""
"This is then exactly what the workfunction function does. It takes one or "
"more data nodes as inputs, calls other processes to which it passes those "
"inputs and optionally returns some or all of the outputs created by the "
"calculation processes it called. As explained in the :ref:`technical "
"section<working_process_functions>`, outputs are recorded as 'returned' "
"nodes simply by returning the nodes from the function. The engine will "
"inspect the return value from the function and attach the output nodes to "
"the node that represents the work function. To verify that the output nodes "
"are in fact not 'created', the engine will check that the nodes are stored. "
"Therefore, it is very important that you **do not store the nodes you create"
" yourself**, or the engine will raise an exception, as shown in the "
"following example:"
msgstr ""

#: ../../source/working/workflows.rst:53
msgid ""
"Because the returned node is a newly created node and not stored, the engine"
" will raise the following exception:"
msgstr ""

#: ../../source/working/workflows.rst:61
msgid ""
"Note that you could of course circumvent this check by calling ``store`` "
"yourself on the node, but that misses the point. The problem with using a "
"``workfunction`` to 'create' new data, is that the provenance is lost. To "
"illustrate this problem, let's go back to the simple problem of implementing"
" a workflow to add two integer and multiply the result with a third. The "
":ref:`correct implementation<concepts_workfunctions>` has a resulting "
"provenance graph that clearly captures the addition and the multiplication "
"as separate calculation nodes, as shown in "
":numref:`fig_work_functions_provenance_add_multiply_full`. To illustrate "
"what would happen if one does does not call calculation functions to perform"
" the computations, but instead directly perform them in the work function "
"itself and return the result, consider the following example:"
msgstr ""

#: ../../source/working/workflows.rst:70 ../../source/working/workflows.rst:89
msgid ""
"For the documentation skimmers: this is an explicit example on **how not to "
"use** work functions. The :ref:`correct "
"implementation<concepts_workfunctions>` calls calculation functions to "
"perform the computation"
msgstr ""

#: ../../source/working/workflows.rst:72
msgid ""
"Note that in this example implementation we explicitly had to call ``store``"
" on the result before returning it to avoid the exception thrown by the "
"engine. The resulting provenance would look like the following:"
msgstr ""

#: ../../source/working/workflows.rst:78
msgid ""
"The provenance generated by the incorrect work function implementation. Note"
" how the addition and multiplication are not explicitly represented, but are"
" implicitly hidden inside the workflow node. Moreover, the result node does "
"not have a 'create' link, because a work function cannot create new data."
msgstr ""

#: ../../source/working/workflows.rst:80
msgid ""
"However, looking at the generated provenance shows exactly why we shouldn't."
" This faulty implementation loses provenance as it has no explicit "
"representations of the addition and the multiplication and the `result` node"
" does not have a `create` link, which means that if only the data provenance"
" is followed, it is as if it appears out of thin air! Compare this to the "
"provenance graph of "
":numref:`fig_work_functions_provenance_add_multiply_full`, which was "
"generated by a solution that correctly uses calculation functions to perform"
" the computations. In this trivial example, one may think that this loss of "
"information is not so important, because it is implicitly captured by the "
"workflow node. But a halfway solution may make the problem more apparent, as"
" demonstrated by the following snippet where the addition is properly done "
"by calling a calculation function, but the final product is still performed "
"by the work function itself:"
msgstr ""

#: ../../source/working/workflows.rst:91
msgid ""
"This time around the addition is correctly performed by a calculation "
"function as it should, however, its result is multiplied by the work "
"function itself and returned. Note that once again ``store`` had to be "
"called explicitly on ``product`` to avoid the engine throwing a "
"``ValueError``, which is only for the purpose of this example **and should "
"not be done in practice**. The resulting provenance would look like the "
"following:"
msgstr ""

#: ../../source/working/workflows.rst:98
msgid ""
"The provenance generated by the incorrect work function implementation that "
"uses only a calculation function for the addition but performs the "
"multiplication itself. The red cross is there to indicate that there is no "
"actual connection between the intermediate sum `D4` and the final result "
"`D5`, even though the latter in reality derives from the former."
msgstr ""

#: ../../source/working/workflows.rst:101
msgid ""
"The generated provenance shows, that although the addition is explicitly "
"represented because the work function called the calculation function, there"
" is no connection between the sum and the final result. That is to say, "
"there is no direct link between the sum `D4` and the final result `D5`, as "
"indicated by the red cross, even though we know that the final answer was "
"based on the intermediate sum. This is a direct cause of the work function "
"'creating' new data and illustrates how, in doing so, the provenance of data"
" creation is lost."
msgstr ""

#: ../../source/working/workflows.rst:111
msgid ""
"To terminate the execution of a work function and mark it as failed, one "
"simply has to return an :ref:`exit code<working_processes_exit_codes>`. The "
":py:class:`~aiida.engine.processes.exit_code.ExitCode` named tuple is "
"constructed with an integer, to denote the desired exit status and an "
"optional message When such as exit code is returned, the engine will mark "
"the node of the work function as ``Finished`` and set the exit status and "
"message to the value of the tuple. Consider the following example:"
msgstr ""

#: ../../source/working/workflows.rst:123
msgid ""
"The execution of the work function will be immediately terminated as soon as"
" the tuple is returned, and the exit status and message will be set to "
"``418`` and ``I am a teapot``, respectively. Since no output nodes are "
"returned, the ``WorkFunctionNode`` node will have no outputs and the value "
"returned from the function call will be an empty dictionary."
msgstr ""

#: ../../source/working/workflows.rst:130
msgid "Work chains"
msgstr ""

#: ../../source/working/workflows.rst:132
msgid ""
"The :ref:`basic concept of the work chain<concepts_workchains>` has been "
"explained elsewhere. This section will provide details on how a work chain "
"can and should be implemented. A work chain is implemented by the "
":py:class:`~aiida.engine.processes.workchains.workchain.WorkChain` class. "
"Since it is a sub class of the "
":py:class:`~aiida.engine.processes.process.Process` class, it shares all its"
" properties. It will be very valuable to have read the section on working "
"with :ref:`generic processes<working_processes>` before continuing, because "
"all the concepts explained there will apply also to work chains."
msgstr ""

#: ../../source/working/workflows.rst:138
msgid ""
"Let's continue with the example presented in the section on the "
":ref:`concept of workchains<concepts_workchains>`, where we sum two integers"
" and multiply the result with a third. We provided a very simple "
"implementation in a code snippet, whose generated provenance graph, when "
"executed, is shown in "
":numref:`fig_work_chains_provenance_add_multiply_workchain_full`. For "
"convenience we copy the snippet here once more:"
msgstr ""

#: ../../source/working/workflows.rst:145
msgid ""
"We will now got through the implementation step-by-step and go into more "
"detail on the interface and best practices."
msgstr ""

#: ../../source/working/workflows.rst:151
msgid "Define"
msgstr ""

#: ../../source/working/workflows.rst:152
msgid ""
"To implement a new work chain, simply create a new class that sub classes "
":py:class:`~aiida.engine.processes.workchains.workchain.WorkChain`. You can "
"give the new class any valid python class name, but the convention is to "
"have it end in ``WorkChain`` so that it is always immediately clear what it "
"references. After having created a new work chain class, the first and most "
"important method to implement is the "
":py:meth:`~aiida.engine.processes.process.Process.define` method. This is a "
"class method that allows the developer to define the characteristics of the "
"work chain, such as what inputs it takes, what outputs it can generate, what"
" potential exit codes it can return and the logical outline through which it"
" will accomplish all this."
msgstr ""

#: ../../source/working/workflows.rst:157
msgid ""
"To implement the ``define`` method, you have to start with the following "
"three lines:"
msgstr ""

#: ../../source/working/workflows.rst:165
msgid ""
"where you replace ``AddAndMultiplyWorkChain`` with the actual name of your "
"work chain. The ``@classmethod`` decorator indicates that this method is a "
"class method  [#f1]_ and not an instance method. The second line is the "
"method signature and specified that it will receive the class itself ``cls``"
" and ``spec`` which will be an instance of the "
":py:class:`~aiida.engine.processes.process_spec.ProcessSpec`. This is the "
"object that we will use to define our inputs, outputs and other relevant "
"properties of the work chain. The third and final line is extremely "
"important, as it will call the ``define`` method of the parent class, in "
"this case the "
":py:class:`~aiida.engine.processes.workchains.workchain.WorkChain` class."
msgstr ""

#: ../../source/working/workflows.rst:173
msgid ""
"If you forget to call ``super`` in the ``define`` method, your work chain "
"will fail miserably!"
msgstr ""

#: ../../source/working/workflows.rst:179
msgid "Inputs and outputs"
msgstr ""

#: ../../source/working/workflows.rst:180
msgid ""
"With those formalities out of the way, you can start defining the "
"interesting properties of the work chain through the ``spec``. In the "
"example you can see how the method "
":py:meth:`~aiida.engine.processes.process_spec.ProcessSpec.input` is used to"
" define multiple input ports, which document exactly which inputs the work "
"chain expects. Similarly, "
":py:meth:`~aiida.engine.processes.process_spec.ProcessSpec.output` is called"
" to instruct that the work chain will produce an output with the label "
"``result``. These two port creation methods support a lot more "
"functionality, such as adding help string, validation and more, all of which"
" is documented in detail in the section on :ref:`ports and port "
"namespace<working_processes_ports_portnamespaces>`."
msgstr ""

#: ../../source/working/workflows.rst:189
msgid "Outline"
msgstr ""

#: ../../source/working/workflows.rst:190
msgid ""
"The outline is what sets the work chain apart from other processes. It is a "
"way of defining the higher-level logic that encodes the workflow that the "
"work chain takes. The outline is defined in the ``define`` method through "
"the :py:meth:`~aiida.engine.processes.process_spec.ProcessSpec.outline`. It "
"takes a sequence of instructions that the work chain will execute, each of "
"which is implemented as a method of the work chain class. In the simple "
"example above, the outline consists of three simple instructions: ``add``, "
"``multiply``, ``results``. Since these are implemented as instance methods, "
"they are prefixed with ``cls.`` to indicate that they are in fact methods of"
" the work chain class. For that same reason, their implementation should "
"take ``self`` as its one and only argument, as demonstrated in the example "
"snippet."
msgstr ""

#: ../../source/working/workflows.rst:198
msgid ""
"The outline in this simple example is not particular interesting as it "
"consists of three simple instructions that will be executed sequentially. "
"However, the outline also supports various logical constructs, such as "
"while-loops, conditionals and return statements. As usual, the best way to "
"illustrate these constructs is by example. The currently available logical "
"constructs for the work chain outline are:"
msgstr ""

#: ../../source/working/workflows.rst:203
msgid "``if``, ``elif``, ``else``"
msgstr ""

#: ../../source/working/workflows.rst:204
msgid "``while``"
msgstr ""

#: ../../source/working/workflows.rst:205
msgid "``return``"
msgstr ""

#: ../../source/working/workflows.rst:207
msgid ""
"To distinguish these constructs from the python builtins, they are suffixed "
"with an underscore, like so ``while_``. To use these in your work chain "
"design, you will have to import them:"
msgstr ""

#: ../../source/working/workflows.rst:214
msgid ""
"The following example shows how to use these logical constructs to define "
"the outline of a work chain:"
msgstr ""

#: ../../source/working/workflows.rst:234
msgid ""
"This is an implementation (and an extremely contrived one at that) of the "
"well known FizzBuzz [#f2]_ problem. The idea is that the program is supposed"
" to print in sequence the numbers from zero to some limit, except when the "
"number is a multiple of three ``Fizz`` is printed, for a multiple of five "
"``Buzz`` and when it is a multiple of both, the program should print "
"``FizzBuzz``. Note how the syntax looks very much like that of normal python"
" syntax. The methods that are used in the conditionals (between the "
"parentheses of the ``while_`` and ``if_`` constructs) for example should "
"return a boolean; ``True`` when the condition holds and ``False`` otherwise."
" The actual implementation of the outline steps themselves is now trivial:"
msgstr ""

#: ../../source/working/workflows.rst:260
msgid ""
"The intention of this example is to show that with a well designed outline, "
"a user only has to look at the outline to have a good idea *what* the work "
"chain does and *how* it does it. One should not have to look at the "
"implementation of the outline steps as all the important information is "
"captured by the outline itself. Since the goal of a work chain should be to "
"execute a very well defined task, it is the goal of the outline to capture "
"the required logic to achieve that goal, in a clear and short yet not overly"
" succint manner. The outline supports various logical flow constructs, such "
"as conditionals and while loops, so where possible this logic should be "
"expressed in the outline and not in the body of the outline functions. "
"However, one can also go overboard and put too finely grained logical blocks"
" into the outline, causing it to become bulky and difficult to understand."
msgstr ""

#: ../../source/working/workflows.rst:266
msgid ""
"A good rule of thumb in designing the outline is the following: before you "
"start designing a work chain, define very clearly the task that it should "
"carry out. Once the goal is clear, draw a schematic block diagram of the "
"necessary steps and logical decisions that connect them, in order to "
"accomplish that goal. Converting the resulting flow diagram in a one-to-one "
"fashion into an outline, often results in very reasonable outline designs."
msgstr ""

#: ../../source/working/workflows.rst:275
msgid ""
"There is one more property of a work chain that is specified through its "
"process specification, in addition to its inputs, outputs and outline. Any "
"work chain may have one to multiple failure modes, which are modeled by "
":ref:`exit codes<working_processes_exit_codes>`. A work chain can be stopped"
" at any time, simply by returning an exit code from an outline method. To "
"retrieve an exit code that is defined on the spec, one can use the "
":py:meth:`~aiida.engine.processes.process.Process.exit_codes` property. This"
" returns an attribute dictionary where the exit code labels map to their "
"corresponding exit code. For example, with the following process spec:"
msgstr ""

#: ../../source/working/workflows.rst:287
msgid ""
"To see how exit codes can be used to terminate the execution of work chains "
"gracefully, refer to the section "
":ref:`working_workchains_aborting_and_exit_codes`."
msgstr ""

#: ../../source/working/workflows.rst:293
msgid "Launching work chains"
msgstr ""

#: ../../source/working/workflows.rst:295
msgid ""
"The rules for launching work chains are the same as those for any other "
"process, which are detailed in :ref:`this "
"section<working_processes_launching>`. On top of those basic rules, there is"
" one peculiarity in the case of work chains when submitting to the daemon. "
"When you submit a ``WorkChain`` over the daemon, or any other process for "
"that matter, you need to make sure that the daemon can find the class when "
"it needs to load it. Registering your class through the plugin system with a"
" designated entry point is one way to make sure that the daemon will be able"
" to find it. If, however, you simply have a test class and do not want to go"
" through the effort of creating an entry point for it, you should make sure "
"that the module where you define the class is in the python path. "
"Additionally, make sure that the definition of the work chain **is not in "
"the same file from which you submit it**, or the engine won't be able to "
"load it."
msgstr ""

#: ../../source/working/workflows.rst:306
msgid "Context"
msgstr ""

#: ../../source/working/workflows.rst:307
msgid ""
"In the simplest work chain example presented in the introductory section, we"
" already saw how the context can be used to persist information during the "
"execution of a work chain and pass it between outline steps. The context is "
"essentially a data container, very similar to a dictionary that can hold all"
" sorts of data. The engine will ensure that its contents are saved and "
"persisted in between steps and when the daemon shuts down or restarts. A "
"trivial example of this would be the following:"
msgstr ""

#: ../../source/working/workflows.rst:320
msgid ""
"In the ``step_one`` outline step we store the string ``'store me in the "
"context'`` in the context, which can be addressed as ``self.ctx``, under the"
" key ``some_variable``. Note that for the key you can use anything that "
"would be a valid key for a normal python dictionary. In the second outline "
"step ``step_two``, we can verify that the string was successfully persisted,"
" by checking the value stored in the context ``self.ctx.some_variable``."
msgstr ""

#: ../../source/working/workflows.rst:326
msgid "Any data that is stored in the context **has** to be serializable."
msgstr ""

#: ../../source/working/workflows.rst:328
msgid ""
"This was just a simple example to introduce the concept of the context, "
"however, it really is one of the more important parts of the work chain. The"
" context really becomes crucial when you want to submit a calculation or "
"another work chain from within the work chain. How this is accomplished, we "
"will show in the next section."
msgstr ""

#: ../../source/working/workflows.rst:335
msgid "Submitting sub processes"
msgstr ""

#: ../../source/working/workflows.rst:336
msgid ""
"One of the main tasks of a ``WorkChain`` will be to launch other processes, "
"such as a ``CalcJob`` or another ``WorkChain``. How to submit processes was "
"explained in :ref:`another section<working_processes_launch>` and is "
"accomplished by using the :py:func:`~aiida.engine.launch.submit` launch "
"function. However, when submitting a sub process from within a work chain, "
"**this should not be used**. Instead, the "
":py:class:`~aiida.engine.processes.process.Process` class provides its own "
":py:meth:`~aiida.engine.processes.process.Process.submit` method. If you do,"
" you will be greeted with the exception:"
msgstr ""

#: ../../source/working/workflows.rst:346
msgid ""
"The only change you have to make is to replace the top-level ``submit`` "
"method with the built-in method of the process class:"
msgstr ""

#: ../../source/working/workflows.rst:354
msgid ""
"The ``self.submit`` method has the exact same interface as the global "
"``aiida.engine.launch.submit`` launcher. When the ``submit`` method is "
"called, the process is created and submitted to the daemon, but at that "
"point it is not yet done. So the value that is returned by the ``submit`` "
"call is not the result of the submitted process, but rather it is the "
"process node that represents the execution of the process in the provenance "
"graph and acts as a *future*. We somehow need to tell the work chain that it"
" should wait for the sub process to be finished, and the future to resolve, "
"before it continues. To do so, however, control has to be returned to the "
"engine, which can then, when the process is completed, call the next step in"
" the outline, where we can analyse the results. The snippet above already "
"revealed that this is accomplished by returning an instance of the "
"``ToContext`` class."
msgstr ""

#: ../../source/working/workflows.rst:362
msgid "To context"
msgstr ""

#: ../../source/working/workflows.rst:363
msgid ""
"In order to store the future of the submitted process, we can store it in "
"the context with a special construct that will tell the engine that it "
"should wait for that process to finish before continuing the work chain. To "
"illustrate how this works, consider the following minimal example:"
msgstr ""

#: ../../source/working/workflows.rst:369
msgid ""
"As explained in the previous section, calling ``self.submit`` for a given "
"process that you want to submit, will return a future. To add this future to"
" the context, we can not access the context directly as explained in the "
":ref:`context section<working_workchains_context>`, but rather we need to "
"use the class "
":py:class:`~aiida.engine.processes.workchains.context.ToContext`. This class"
" has to be imported from the ``aiida.engine`` module. To add the future to "
"the context, simply construct an instance of ``ToContext``, passing the "
"future as a keyword argument, and returning it from the outline step. The "
"keyword used, ``workchain`` in this example, will be the key used under "
"which to store the node in the context once its execution has terminated. "
"Returning an instance of ``ToContext`` signals to the engine that it has to "
"wait for the futures contained within it to finish execution, store their "
"nodes in the context under the specified keys and then continue to the next "
"step in the outline. In this example, that is the ``inspect_workchain`` "
"method. At this point we are sure that the process, a work chain in this "
"case, has terminated its execution, although not necessarily successful, and"
" we can continue the logic of the work chain."
msgstr ""

#: ../../source/working/workflows.rst:378
msgid ""
"Sometimes one wants to launch not just one, but multiple processes at the "
"same time that can run in parallel. With the mechanism described above, this"
" will not be possible since after submitting a single process and returning "
"the ``ToContext`` instance, the work chain has to wait for the process to be"
" finished before it can continue. To solve this problem, there is another "
"way to add futures to the context:"
msgstr ""

#: ../../source/working/workflows.rst:385
msgid ""
"Here we submit three work chains in a for loop in a single outline step, but"
" instead of returning an instance of ``ToContext``, we call the "
":meth:`~aiida.engine.processes.workchains.workchain.WorkChain.to_context` "
"method. This method has exactly the same syntax as the ``ToContext`` class, "
"except it is not necessary to return its value, so we can call it multiple "
"times in one outline step. Under the hood the functionality is also the same"
" as the ``ToContext`` class. At the end of the ``submit_workchains`` outline"
" step, the engine will find the futures that were added by calling "
"``to_context`` and will wait for all of them to be finished. The good thing "
"here is that these three sub work chains can be run in parallel and once all"
" of them are done, the parent work chain will go to the next step, which is "
"``inspect_workchains``. There we can find the nodes of the work chains in "
"the context under the key that was used as the keyword argument in the "
"``to_context`` call in the previous step."
msgstr ""

#: ../../source/working/workflows.rst:392
msgid ""
"Since we do not want the subsequent calls of ``to_context`` to override the "
"previous future, we had to create unique keys to store them under. In this "
"example, we chose to use the index of the for-loop. The name carries no "
"meaning and is just required to guarantee unique key names. This pattern "
"will occur often where you will want to launch multiple work chains or "
"calculations in parallel and will have to come up with unique names. In "
"essence, however, you are really just creating a list and it would be better"
" to be able to create a list in the context and simply append the future to "
"that list as you submit them. How this can be achieved is explained in the "
"next section."
msgstr ""

#: ../../source/working/workflows.rst:400
msgid "Appending"
msgstr ""

#: ../../source/working/workflows.rst:401
msgid ""
"When you want to add a future of a submitted sub process to the context, but"
" append it to a list rather than assign it to a key, you can use the "
":func:`~aiida.engine.processes.workchains.context.append_` function. "
"Consider the example from the previous section, but now we will use the "
"``append_`` function instead:"
msgstr ""

#: ../../source/working/workflows.rst:407
msgid ""
"Notice that in the ``submit_workchains`` step we no longer have to generate "
"a unique key based on the index but we simply wrap the future in the "
"``append_`` function and assign it to the generic key ``workchains``. The "
"engine will see the ``append_`` function and instead of assigning the node "
"corresponding to the future to the key ``workchains``, it will append it to "
"the list stored under that key. If the list did not yet exist, it will "
"automatically be created. The ``self.ctx.workchains`` now contains a list "
"with the nodes of the completed work chains and so in the "
"``inspect_workchains`` step we can simply iterate over it to access all of "
"them."
msgstr ""

#: ../../source/working/workflows.rst:414
msgid ""
"The process nodes of the completed processes will **not necessarily** be "
"added to the list in the context in the same order as the ``to_context`` "
"calls. This is because the futures may not necessarily be resolved in the "
"same order as they were submitted. Therefore it is dangerous to depend on "
"the order when using the append method."
msgstr ""

#: ../../source/working/workflows.rst:418
msgid ""
"Note that the use of ``append_`` is not just limited to the ``to_context`` "
"method. You can also use it in exactly the same way with ``ToContext`` to "
"append a process to a list in the context in multiple outline steps."
msgstr ""

#: ../../source/working/workflows.rst:424
msgid "Reporting"
msgstr ""

#: ../../source/working/workflows.rst:425
msgid ""
"During the execution of a ``WorkChain``, we may want to keep the user "
"abreast of its progress and what is happening. For this purpose, the "
"``WorkChain`` implements the "
":py:meth:`~aiida.engine.processes.process.Process.report` method, which "
"functions as a logger of sorts. It takes a single argument, a string, that "
"is the message that needs to be reported:"
msgstr ""

#: ../../source/working/workflows.rst:434
msgid ""
"This will send that message to the internal logger of python, which will "
"cause it to be picked up by the default AiiDA logger, but it will also "
"trigger the database log handler, which will store the message in the "
"database and link it to the node of the work chain. This allows the ``verdi "
"process report`` command to retrieve all those messages that were fired "
"using the ``report`` method for a specific process. Note that the report "
"method, in addition to the pk of the work chain, will also automatically "
"record the name of the work chain and the name of the outline step in which "
"the report message was fired. This information will show up in the output of"
" ``verdi process report``, so you never have to explicitly reference the "
"work chain name, outline step name or date and time in the message itself."
msgstr ""

#: ../../source/working/workflows.rst:439
msgid ""
"It is important to note that the report system is a form of logging and as "
"such has been designed to be read by humans only. That is to say, the report"
" system is not designed to pass information programmatically by parsing the "
"log messages."
msgstr ""

#: ../../source/working/workflows.rst:445
msgid "Aborting and exit codes"
msgstr ""

#: ../../source/working/workflows.rst:446
msgid ""
"At the end of every outline step, the return value will be inspected by the "
"engine. If a non-zero integer value is detected, the engine will interpret "
"this as an exit code and will stop the execution of the work chain, while "
"setting its process state to ``Finished``. In addition, the integer return "
"value will be set as the ``exit_status`` of the work chain, which combined "
"with the ``Finished`` process state will denote that the worchain is "
"considered to be ``Failed``, as explained in the section on the "
":ref:`process state <concepts_process_state>`. This is useful because it "
"allows a workflow designer to easily exit from a work chain and use the "
"return value to communicate programmatically the reason for the work chain "
"stopping."
msgstr ""

#: ../../source/working/workflows.rst:451
msgid ""
"We assume that you have read the `section on how to define exit code "
"<exit_codes>`_ through the process specification of the work chain. Consider"
" the following example work chain that defines such an exit code:"
msgstr ""

#: ../../source/working/workflows.rst:458
msgid ""
"Now imagine that in the outline, we launch a calculation and in the next "
"step check whether it finished successfully. In the event that the "
"calculation did not finish successfully, the following snippet shows how you"
" can retrieve the corresponding exit code and abort the ``WorkChain`` by "
"returning it:"
msgstr ""

#: ../../source/working/workflows.rst:475
msgid ""
"In the ``inspect_calculation`` outline, we retrieve the calculation that was"
" submitted and added to the context in the previous step and check if it "
"finished successfully through the property ``is_finished_ok``. If this "
"returns ``False``, in this example we simply fire a report message and "
"return the exit code corresponding to the label "
"``ERROR_CALCULATION_FAILED``. Note that the specific exit code can be "
"retrieved through the ``WorkChain`` property ``exit_codes``. This will "
"return a collection of exit codes that have been defined for that "
"``WorkChain`` and any specific exit code can then be retrieved by accessing "
"it as an attribute. Returning this exit code, which will be an instance of "
"the :py:class:`~aiida.engine.processes.exit_code.ExitCode` named tuple, will"
" cause the work chain to be aborted and the ``exit_status`` and "
"``exit_message`` to be set on the node, which were defined in the spec."
msgstr ""

#: ../../source/working/workflows.rst:483
msgid ""
"The notation ``self.exit_codes.ERROR_CALCULATION_FAILED`` is just syntactic "
"sugar to retrieve the ``ExitCode`` tuple that was defined in the spec with "
"that error label. Constructing your own ``ExitCode`` directly and returning "
"that from the outline step will have exactly the same effect in terms of "
"aborting the work chain execution and setting the exit status and message. "
"However, it is strongly advised to define the exit code through the spec and"
" retrieve it through the ``self.exit_codes`` collection, as that makes it "
"easily retrievable through the spec by the caller of the work chain."
msgstr ""

#: ../../source/working/workflows.rst:487
msgid ""
"The best part about this method of aborting a work chains execution, is that"
" the exit status can now be used programmatically, by for example a parent "
"work chain. Imagine that a parent work chain submitted this work chain. "
"After it has terminated its execution, the parent work chain will want to "
"know what happened to the child work chain. As already noted in the "
":ref:`report<working_workchains_reporting>` section, the report messages of "
"the work chain should not be used. The exit status, however, is a perfect "
"way. The parent work chain can easily request the exit status of the child "
"work chain through the ``exit_status`` property, and based on its value "
"determine how to proceed."
msgstr ""

#: ../../source/working/workflows.rst:496
msgid "Modular workflow design"
msgstr ""

#: ../../source/working/workflows.rst:497
msgid ""
"When creating complex workflows, it is a good idea to split them up into "
"smaller, modular parts. At the lowest level, each workflow should perform "
"exactly one task. These workflows can then be wrapped together by a "
"\"parent\" workflow to create a larger logical unit."
msgstr ""

#: ../../source/working/workflows.rst:501
msgid ""
"In order to make this approach manageable, it needs to be as simple as "
"possible to glue together multiple workflows in a larger parent workflow. "
"One of the tools that AiiDA provides to simplify this is the ability to "
"*expose* the ports of another work chain."
msgstr ""

#: ../../source/working/workflows.rst:507
msgid "Exposing inputs and outputs"
msgstr ""

#: ../../source/working/workflows.rst:508
msgid ""
"Consider the following example work chain, which simply takes a few inputs "
"and returns them again as outputs:"
msgstr ""

#: ../../source/working/workflows.rst:513
msgid ""
"As a first example, we will implement a thin wrapper workflow, which simply "
"forwards its inputs to ``ChildWorkChain``, and forwards the outputs of the "
"child to its outputs:"
msgstr ""

#: ../../source/working/workflows.rst:518
msgid ""
"In the ``define`` method of this simple parent work chain, we use the "
":meth:`~plumpy.process_spec.ProcessSpec.expose_inputs` and "
":meth:`~plumpy.process_spec.ProcessSpec.expose_outputs`. This creates the "
"corresponding input and output ports in the parent work chain. Additionally,"
" AiiDA remembers which inputs and outputs were exposed from that particular "
"work chain class. This is used when calling the child in the ``run_child`` "
"method. The :meth:`~aiida.engine.processes.process.Process.exposed_inputs` "
"method returns a dictionary of inputs that the parent received which were "
"exposed from the child, and so it can be used to pass these on to the child."
" Finally, in the ``finalize`` method, we use "
":meth:`~aiida.engine.processes.process.Process.exposed_outputs` to retrieve "
"the outputs of the child which were exposed to the parent. Using "
":meth:`~aiida.engine.processes.process.Process.out_many`, these outputs are "
"added to the outputs of the parent work chain. This work chain can now be "
"run in exactly the same way as the child itself:"
msgstr ""

#: ../../source/working/workflows.rst:530
msgid ""
"Next, we will see how a more complex parent work chain can be created by "
"using the additional features of the expose functionality. The following "
"work chain launches two children. These children share the input ``a``, but "
"have different ``b`` and ``c``. The output ``e`` will be taken only from the"
" first child, whereas ``d`` and ``f`` are taken from both children. In order"
" to avoid name conflicts, we need to create a *namespace* for each of the "
"two children, where the inputs and outputs which are not shared are stored. "
"Our goal is that the workflow can be called as follows:"
msgstr ""

#: ../../source/working/workflows.rst:540
msgid ""
"This is achieved by the following workflow. In the next section, we will "
"explain each of the steps."
msgstr ""

#: ../../source/working/workflows.rst:546
msgid ""
"First of all, we want to expose the ``a`` input and the ``e`` output at the "
"top-level. For this, we again use "
":meth:`~plumpy.process_spec.ProcessSpec.expose_inputs` and "
":meth:`~plumpy.process_spec.ProcessSpec.expose_outputs`, but with the "
"optional keyword ``include``. This specifies a list of keys, and only inputs"
" or outputs which are in that list will be exposed. So by passing "
"``include=['a']`` to :meth:`~plumpy.process_spec.ProcessSpec.expose_inputs`,"
" only the input ``a`` is exposed."
msgstr ""

#: ../../source/working/workflows.rst:551
msgid ""
"Additionally, we want to expose the inputs ``b`` and ``c`` (outputs ``d`` "
"and ``f``), but in a namespace specific for each of the two children. For "
"this purpose, we pass the ``namespace`` parameter to the expose functions. "
"However, since we now shouldn't expose ``a`` (``e``) again, we use the "
"``exclude`` keyword, which specifies a list of keys that will not be "
"exposed."
msgstr ""

#: ../../source/working/workflows.rst:555
msgid ""
"When calling the children, we again use the "
":meth:`~aiida.engine.processes.process.Process.exposed_inputs` method to "
"forward the exposed inputs. Since the inputs ``b`` and ``c`` are now in a "
"specific namespace, we need to pass this namespace as an additional "
"parameter. By default, "
":meth:`~aiida.engine.processes.process.Process.exposed_inputs` will search "
"through all the parent namespaces of the given namespace to search for "
"input, as shown in the call for ``child_1``. If the same input key exists in"
" multiple namespaces, the input in the lowest namespace takes precedence. "
"It's also possible to disable this behavior, and instead search only in the "
"explicit namespace that was passed. This is done by setting "
"``agglomerate=False``, as shown in the call to ``child_2``. Of course, we "
"then need to explicitly pass the input ``a``."
msgstr ""

#: ../../source/working/workflows.rst:563
msgid ""
"Finally, we use "
":meth:`~aiida.engine.processes.process.Process.exposed_outputs` and "
":meth:`~aiida.engine.processes.process.Process.out_many` to forward the "
"outputs of the children to the outputs of the parent. Again, the "
"``namespace`` and ``agglomerate`` options can be used to select which "
"outputs are returned by the "
":meth:`~aiida.engine.processes.process.Process.exposed_outputs` method."
msgstr ""

#: ../../source/working/workflows.rst:570
msgid "https://docs.python.org/3.5/library/functions.html#classmethod"
msgstr ""

#: ../../source/working/workflows.rst:571
msgid "https://en.wikipedia.org/wiki/Fizz_buzz"
msgstr ""

# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2019, ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE (Theory and Simulation of Materials (THEOS) and National Centre for Computational Design and Discovery of Novel Materials (NCCR MARVEL)), Switzerland and ROBERT BOSCH LLC, USA. All rights reserved
# This file is distributed under the same license as the AiiDA package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
# 
# Translators:
# Jason.Eu <morty.yu@yahoo.com>, 2019
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: AiiDA 1.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2019-06-24 09:00+0000\n"
"PO-Revision-Date: 2019-05-17 20:01+0000\n"
"Last-Translator: Jason.Eu <morty.yu@yahoo.com>, 2019\n"
"Language-Team: Chinese (China) (https://www.transifex.com/aiidateam/teams/98967/zh_CN/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: zh_CN\n"
"Plural-Forms: nplurals=1; plural=0;\n"

#: ../docs/source/working/calculations.rst:5
msgid "Calculations"
msgstr "算例(Calculations)"

#: ../docs/source/working/calculations.rst:7
msgid ""
"A calculation is a process (see the :ref:`process "
"section<concepts_processes>` for details) that *creates* new data. "
"Currently, there are two ways of implementing a calculation process:"
msgstr ""
"算例是能够 *创建* 新的数据的一个例程(详情参看 :ref:`process section<concepts_processes>`  )。 "
"当前，有两种实现算例例程的方法 :"

#: ../docs/source/working/calculations.rst:10
msgid ":ref:`calculation function<working_calcfunctions>`"
msgstr ":ref:`算例函数<working_calcfunctions>`"

#: ../docs/source/working/calculations.rst:11
msgid ":ref:`calculation job<working_calcjobs>`"
msgstr ":ref:`算例任务<working_calcjobs>`"

#: ../docs/source/working/calculations.rst:13
msgid ""
"This section will provide detailed information and best practices on how to "
"implement these two calculation types."
msgstr "该章节关于如何实现这两种算例的详细信息和最佳案例。"

#: ../docs/source/working/calculations.rst:16
msgid ""
"This chapter assumes that the basic concept and difference between "
"calculation functions and calculation jobs is known and when one should use "
"on or the other. It is therefore crucial that, before you continue, you have"
" read and understood the basic concept of :ref:`calculation "
"processes<concepts_calculations>`."
msgstr ""
"该章认为读者已经对基础概念和算例函数与算例任务之间的区别和使用场景有所了解。因此在继续下面的阅读前，你需要阅读和理解 "
":ref:`算例例程<concepts_calculations>` 的基础概念."

#: ../docs/source/working/calculations.rst:22
msgid "Calculation functions"
msgstr "算例函数(Calculation functions)"

#: ../docs/source/working/calculations.rst:24
msgid ""
"The section on the :ref:`concept of calculation "
"functions<concepts_calcfunctions>` already addressed their aim: automatic "
"recording of their execution with their inputs and outputs in the provenance"
" graph. The :ref:`section on process functions<working_process_functions>` "
"subsequently detailed the rules that apply when implementing them, all of "
"which to calculation functions, which are a sub type, just like work "
"functions. However, there are some differences given that calculation "
"functions are 'calculation'-like processes and work function behave like "
"'workflow'-like processes. What this entails in terms of intended usage and "
"limitations for calculation functions is the scope of this section."
msgstr ""
"章节 :ref:`算例函数及其概念<concepts_calcfunctions>` 已经描述了其使用目的: "
"自动在可验证性图中记录算例的运行和运行所需的输入和产生的输出。之后的 The "
":ref:`例程函数章节<working_process_functions>` "
"详细描述了实现例程函数时候的规则和细节，如同工作函数，规则和实现同时适用于例程函数这一例程函数的子类。但是，算例函数这种 “算例型” "
"的例程和工作函数这种“工作型” 的例程之间还是有些区别的。 就算例函数的预期使用和限制，还在本节描述。"

#: ../docs/source/working/calculations.rst:30
msgid "Creating data"
msgstr "创建数据"

#: ../docs/source/working/calculations.rst:31
msgid ""
"It has been said many times before: calculation functions, like all "
"'calculation'-like processes, `create` data, but what does `create` mean "
"exactly? In this context, the term 'create' is not intended to refer to the "
"simple creation of a new data node in the graph, in an interactive shell or "
"a script for example. But rather it indicates the creation of a new piece of"
" data from some other data through a computation implemented by a process. "
"This is then exactly what the calculation function does. It takes one or "
"more data nodes as inputs and returns one or more data nodes as outputs, "
"whose content is based on those inputs. As explained in the :ref:`technical "
"section<working_process_functions>`, outputs are created simply by returning"
" the nodes from the function. The engine will inspect the return value from "
"the function and attach the output nodes to the calculation node that "
"represents the calculation function. To verify that the output nodes are in "
"fact 'created', the engine will check that the nodes are not stored. "
"Therefore, it is very important that you **do not store the nodes you create"
" yourself**, or the engine will raise an exception, as shown in the "
"following example:"
msgstr ""
"前面曾多次提到: 算例函数，如同所有的“算例性”例程一样，能够  “创建” 数据，但所谓的“创建”具体指什么？ "
"在此处的上下文中，术语“创建”并不简单的描述通过交互式shell或脚本在可验证性图中创建数据节点。 "
"而是指代了通过例程实现的计算中从一些数据产生新的数据的过程。这就是算例函数所实际产生的效果。它以一个或多个数据节点作为输入，并返回以这些输入作为操作对象的一个或多个数据节点作为输出。正如小节"
" :ref:`技术细节<working_process_functions>` "
"所解释的，输出是通过从函数中返回数据节点的方式简单创建的。后端引擎会从函数中检查返回值并将返回节点连接在表示算例函数的算例节点上。为验证输出节点确实是“创建”的，AiiDA引擎会检查这个节点是没有被储存过的。因此，**不要手动储存你所创建的节点**"
" 是很重要的，否则引擎会产生一个如下异常 :"

#: ../docs/source/working/calculations.rst:44
msgid ""
"Because the returned node is already stored, the engine will raise the "
"following exception:"
msgstr "因为返回的节点已经储存，AiiDA引擎会产生一个如下异常 :"

#: ../docs/source/working/calculations.rst:52
msgid ""
"The reason for this strictness is that a node that was stored after being "
"created in the function body, is indistinguishable from a node that was "
"already stored and had simply been loaded in the function body and returned,"
" e.g.:"
msgstr "该严格限制的原因是，节点需要在被创建后才会被储存，这有别与在函数体中或函数的返回中载入一个已经储存的节点，如 ::"

#: ../docs/source/working/calculations.rst:57
msgid ""
"The loaded node would also have gotten a `create` link from the calculation "
"function, even though it was not really created by it at all. It is exactly "
"to prevent this ambiguity that calculation functions require all returned "
"output nodes to be *unstored*."
msgstr ""
"载入的节点会从算例函数中产生一个 `create` 连接，即便该节点不是由该函数创建的。正是为了避免这种模糊性，要求算例函数返回的所有输出节点都是 "
"*unstored* 的。"

#: ../docs/source/working/calculations.rst:60
msgid ""
"Note that work functions have exactly the opposite required and all the "
"outputs that it returns **have to be stored**, because as a 'workflow'-like "
"process, it *cannot* create new data. For more details refer to the "
":ref:`work function section<working_workfunctions>`."
msgstr ""
"注意到工作流函数有完全相反的要求，即所有函数返回的输出必须 *已经被储存* ，因为如一个“工作流”型的例程，它是 *不能* 创建新的数据的。详情请参考 "
":ref:`工作流函数小节<working_workfunctions>` 。"

#: ../docs/source/working/calculations.rst:66
msgid "Calculation jobs"
msgstr "算例任务(Calculation jobs)"

#: ../docs/source/working/calculations.rst:68
msgid ""
"To explain how a calculation job can be implemented, we will continue with "
"the example presented in the section on the :ref:`concept of the calculation"
" job<concepts_calcjobs>`. There we described a code that adds two integers, "
"implemented as a simple bash script, and how the "
":py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` class can be "
"used to run this code through AiiDA. Since it is a sub class of the "
":py:class:`~aiida.engine.processes.process.Process` class, it shares all its"
" properties. It will be very valuable to have read the section on working "
"with :ref:`generic processes<working_processes>` before continuing, because "
"all the concepts explained there will apply also to calculation jobs."
msgstr ""
"为描述如何实现算例任务，我们继续章节 :ref:`算例任务的概念<concepts_calcjobs>` "
"中展示的例子。例子中我们描述了对两个整数求和并通过简单的bash脚本实现的代码，以及 "
":py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` "
"类如何被用于在AiiDA中运行这段代码。因为该类是 "
":py:class:`~aiida.engine.processes.process.Process` "
"类的子类，则拥有它的全部性质。因此在继续之前阅读章节 :ref:`泛型例程<working_processes>` "
"也是很有用的。因为那里所描述的所有特性在此处算例任务中同样适用。"

#: ../docs/source/working/calculations.rst:77
#: ../docs/source/working/workflows.rst:151
msgid "Define"
msgstr "定义"

#: ../docs/source/working/calculations.rst:78
msgid ""
"To implement a calculation job, one simply sub classes the "
":py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` process class "
"and implements the "
":py:meth:`~aiida.engine.processes.calcjobs.calcjob.CalcJob.define` method. "
"You can pick any name that is a valid python class name. The most important "
"method of the ``CalcJob`` class, is the ``define`` class method. Here you "
"define, what inputs it takes and what outputs it will generate."
msgstr ""
"要实现一个算例任务，使用者只需要继承 "
":py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` 例程类并实现 "
":py:meth:`~aiida.engine.processes.calcjobs.calcjob.CalcJob.define` "
"方法。你可以使用认可python许可的类名。``CalcJob`` 中最重要的方法是 ``define`` "
"类方法。在这个方法中，你定义了输入和算例运行产生的输出。"

#: ../docs/source/working/calculations.rst:86
msgid ""
"As the snippet above demonstrates, the class method takes two arguments:"
msgstr "如上面代码片段所展示的，该类方法接受两个参数 :"

#: ../docs/source/working/calculations.rst:88
msgid ""
"``cls`` this is the reference of the class itself and is mandatory for any "
"class method"
msgstr "``cls`` 是指向该类自身的可以访问类的所有类方法的变量"

#: ../docs/source/working/calculations.rst:89
msgid "``spec`` which is the 'specification'"
msgstr "``spec`` 是 “计算规格和详情” (specification)"

#: ../docs/source/working/calculations.rst:92
msgid ""
"Do not forget to add the line ``super(ArithmeticAddCalculation, "
"self).define(spec)`` as the first line of the ``define`` method, where you "
"replace the class name with the name of your calculation job. This will call"
" the ``define`` method of the parent class, which is necessary for the "
"calculation job to work properly"
msgstr ""
"请不要忘记在 ``define`` 方法的首行加入 ``super(ArithmeticAddCalculation, "
"self).define(spec)``  ，这里你需要用你自己的类名。这会调用 ``define`` 方法的父类，使得算例任务可以正确工作。"

#: ../docs/source/working/calculations.rst:95
msgid ""
"As the name suggests, the ``spec`` can be used to specify the properties of "
"the calculation job. For example, it can be used to define inputs that the "
"calculation job takes. In our example, we need to be able to pass two "
"integers as input, so we define those in the spec by calling "
"``spec.input()``. The first argument is the name of the input. This name "
"should be used later to specify the inputs when launching the calculation "
"job and it will also be used as the label for link to connect the data node "
"and the calculation node in the provenance graph. Additionally, as we have "
"done here, you can specify which types are valid for that particular input. "
"Since we expect integers, we specify that the valid type is the database "
"storable :py:class:`~aiida.orm.nodes.data.int.Int` class."
msgstr ""
"正如其名所示， ``spec`` "
"可以用于指定算例任务的性质。比如，它可以用于定义算例任务所需的输入。在我们的例子中，我们需要接受两个整数作为输入，所以我们通过调用 "
"``spec.input()`` 定义这些 “规格参数”。 "
"第一个参数是输入的名称。该名称之后会被用于在启动算例任务时输入的指定，还会被作为在可验证性图中连接算例节点的数据节点的标签。另外，正如我们在这里所用到的，你还可以指定特定输入允许的参数类型。因为我们在此处希望得到整形的变量，我们指定允许的类型是数据库可储存的"
" :py:class:`~aiida.orm.nodes.data.int.Int` 类。"

#: ../docs/source/working/calculations.rst:105
msgid ""
"Since we sub class from ``CalcJob`` and call its ``define`` method, it will "
"inherit the ports that it declares as well. If you look at the "
"implementation, you will find that the base class ``CalcJob`` already "
"defines an input ``code`` that takes a ``Code`` instance. This will "
"reference the code that the user wants to run when he launches the "
"``CalcJob``. For this reason, you **do not** again have to declare this "
"input."
msgstr ""
"因为我们继承了 ``CalcJob`` 类并调用了它的 ``define`` 方法，这会同时继承其声明的端口(port)。 "
"如果你查看类的实现，你会发现在基类 ``CalcJob`` 中已经定义了输入 ``code`` 以接受一个 ``Code`` 示例。这会指向用户在运行 "
"``CalcJob`` 时所要使用的计算代码。因此， **请不要** 重复声明该输入。"

#: ../docs/source/working/calculations.rst:110
msgid ""
"Next we should define what outputs we expect the calculation to produce:"
msgstr "之后我们需要定义我们期望得到的算例输出 :"

#: ../docs/source/working/calculations.rst:115
msgid ""
"Just as for the inputs, one can specify what node type each output should "
"have. By default a defined output will be 'required', which means that if "
"the calculation job terminates and the output has not been attached, the "
"process will be marked as failed. To indicate that an output is optional, "
"one can use ``required=False`` in the ``spec.output`` call. Note that the "
"process spec, and its "
":py:meth:`~aiida.engine.processes.process_spec.ProcessSpec.input` and "
":py:meth:`~aiida.engine.processes.process_spec.ProcessSpec.output` methods "
"provide a lot more functionality. Fore more details, please refer to the "
"section on :ref:`process specifications<working_processes_spec>`."
msgstr ""
"如同输入，用户需要指定每个输出因有的节点类型。默认的，一个定义了的输出将会是 '必给的' "
"(required)，意味着如果算例任务终止但没有得到输出，则例程(process)会被标记为失败。要指明一个输出不是必须的而是可选的，用户可以在 "
"``spec.output`` 调用中使用 ``required=False``  。可以注意到，例程的规格详情以及其 "
":py:meth:`~aiida.engine.processes.process_spec.ProcessSpec.input` 和 "
":py:meth:`~aiida.engine.processes.process_spec.ProcessSpec.output` "
"方法提供了许多功能。详情可以参考章节 :ref:`例程规格<working_processes_spec>` 。"

#: ../docs/source/working/calculations.rst:125
msgid "Prepare"
msgstr "准备"

#: ../docs/source/working/calculations.rst:126
msgid ""
"We have know defined through the process specification, what inputs the "
"calculation job expects and what outputs it will create. The final remaining"
" task is to instruct the engine how the calculation job should actually be "
"run. To understand what the engine would have to do to accomplish this, "
"let's consider what one typically does when manually preparing to run a "
"computing job through a scheduler:"
msgstr ""
"通过例程的规格定义，我们能够知晓算例任务所期望的输入和将会产生的输出。剩下的任务就是告知引擎算例任务事实上需要如何运行。为了理解AiiDA引擎为了完成算例任务将会执行的步骤，我们来看一下当用户手动通过任务调度工具执行一个计算任务时会采取的具体步骤"
" :"

#: ../docs/source/working/calculations.rst:130
msgid ""
"Prepare a working directory in some scratch space on the machine where the "
"job will run"
msgstr "在计算资源的可用空间上，准备一个任务运行的工作文件夹"

#: ../docs/source/working/calculations.rst:131
msgid "Create the raw input files required by the executable"
msgstr "创建可执行软件所需的的原始输入文件"

#: ../docs/source/working/calculations.rst:132
msgid ""
"Create a launch script containing scheduler directives, loading of "
"environment variables and finally calling the executable with certain "
"command line parameters."
msgstr "创建一个包含调度程序指令的启动脚本，加载环境变量，最后使用特定命令行参数调用可执行文件。"

#: ../docs/source/working/calculations.rst:134
msgid ""
"So all we need to do now is instruct the engine how to accomplish these "
"things for a specific calculation job. Since these instructions will be "
"calculation dependent, we will implement this with the "
":py:meth:`~aiida.engine.processes.calcjobs.calcjob.CalcJob.prepare_for_submission`"
" method. The implementation of the ``ArithmeticAddCalculation`` that we are "
"considering in the example looks like the following:"
msgstr ""
"所以我们要做的就是直到AiiDA引擎对指定算例任务完成这些步骤。由于。由于这些步骤对每个计算是不同的，我们需要通过 "
":py:meth:`~aiida.engine.processes.calcjobs.calcjob.CalcJob.prepare_for_submission`"
" 方法来实现这些步骤。在样例中展示的 ``ArithmeticAddCalculation`` 实现如下 :"

#: ../docs/source/working/calculations.rst:141
msgid ""
"Before we go into the code line-by-line, let's describe the big picture of "
"what is happening here. The goal of this method is to help the engine "
"accomplish the three steps required for preparing the submission a "
"calculation job, as described above. The raw input files that are required "
"can be written to a sandbox folder that is passed in as the ``folder`` "
"argument. All the other required information, such as the directives of "
"which files to copy and what command line options to use are defined through"
" the :py:class:`~aiida.common.datastructures.CalcInfo` datastructure, which "
"should be returned from the method as the only value. In principle, this is "
"what one **should do** in the ``prepare_for_submission`` method:"
msgstr ""
"在我们逐行研究代码之前，让我们先描述一下这里发生的事情的全貌。该类方法的目的是帮助AiiDA引擎完成如上所述的准备和提交计算任务所需的三个步骤。所需的原始输入文件可以写入沙箱文件夹，该文件夹之后会以"
" ``folder`` 参数传入。所需的其他所有信息，如拷贝文件的指令和指令参数均通过 "
":py:class:`~aiida.common.datastructures.CalcInfo` "
"数据结构定义，这个值应该作为方法返回的唯一值。理论上，这是用户在方法 ``prepare_for_submission`` 中 **应该做的** :"

#: ../docs/source/working/calculations.rst:147
msgid ""
"Writing raw inputs files required for the calculation to run to the "
"``folder`` sandbox folder."
msgstr ""

#: ../docs/source/working/calculations.rst:148
msgid ""
"Use a ``CalcInfo`` to instruct the engine which files to copy to the working"
" directory"
msgstr ""

#: ../docs/source/working/calculations.rst:149
msgid ""
"Use a ``CalcInfo`` to tell which codes should run, using which command line "
"parameters, such as standard input and output redirection."
msgstr ""

#: ../docs/source/working/calculations.rst:153
msgid ""
"The ``prepare_for_submission`` does not have to write the submission script "
"itself. The engine will know how to do this, because the codes that are to "
"be used have been configured on a specific computer, which defines what "
"scheduler is to be used. This gives the engine all the necessary information"
" on how to write the launch script such as what scheduler directives to "
"write."
msgstr ""

#: ../docs/source/working/calculations.rst:157
msgid ""
"Now that we know what the ``prepare_for_submission`` is expected to do, "
"let's see how the implementation of the ``ArithmeticAddCalculation`` "
"accomplishes it line-by-line. The input file required for this example "
"calculation will consist of the two integers that are passed as inputs. The "
"``self.inputs`` attribute returns an attribute dictionary with the parsed "
"and validated inputs, according to the process specification defined in the "
"``define`` method. This means that you do not have to validate the inputs "
"yourself. That is to say, if an input is marked as required and of a certain"
" type, by the time we get to the ``prepare_for_submission`` it is guaranteed"
" that the dictionary returned by ``self.inputs`` will contain that input and"
" of the correct type."
msgstr ""

#: ../docs/source/working/calculations.rst:163
msgid ""
"From the two inputs ``x`` and ``y`` that will have been passed when the "
"calculation job was launched, we should now generate the input file, that is"
" simply a text file with these two numbers on a single line, separated by a "
"space. We accomplish this by opening a filehandle to the input file in the "
"sandbox folder and write the values of the two ``Int`` nodes to the file."
msgstr ""

#: ../docs/source/working/calculations.rst:168
msgid ""
"The format of this input file just so happens to be the format that the "
":ref:`bash script<concepts_calcjobs>` expects that we are using in this "
"example. The exact number of input files and their content will of course "
"depend on the code for which the calculation job is being written."
msgstr ""

#: ../docs/source/working/calculations.rst:171
msgid ""
"With the input file written, we now have to create an instance of "
":py:class:`~aiida.common.datastructures.CalcInfo` that should be returned "
"from the method. This data structure will instruct the engine exactly what "
"needs to be done to execute the code, such as what files should be copied to"
" the remote computer where the code will be executed. In this simple "
"example, we define four simple attributes:"
msgstr ""

#: ../docs/source/working/calculations.rst:175
msgid ""
"``codes_info``: a list of :py:class:`~aiida.common.datastructures.CodeInfo` "
"datastructures, that tell which codes to run consecutively during the job"
msgstr ""

#: ../docs/source/working/calculations.rst:176
msgid ""
"``local_copy_list``: a list of tuples that instruct what files to copy to "
"the working directory from the local machine"
msgstr ""

#: ../docs/source/working/calculations.rst:177
msgid ""
"``remote_copy_list``: a list of tuples that instruct what files to copy to "
"the working directory from the machine on which the job will run"
msgstr ""

#: ../docs/source/working/calculations.rst:178
msgid ""
"``retrieve_list``: a list of tuples instructing which files should be "
"retrieved from the working directory and stored in the local repository "
"after the job has finished"
msgstr ""

#: ../docs/source/working/calculations.rst:180
msgid ""
"In this example we only need to run a single code, so the ``codes_info`` "
"list has a single ``CodeInfo`` datastructure. This datastructure needs to "
"define which code it needs to run, which is one of the inputs passed to the "
"``CalcJob``, and does so by means of its UUID. Through the ``stdout_name`` "
"attribute, we tell the engine where the output of the executable should be "
"redirected to. In this example this is set to the value of the  "
"``output_filename`` option. What options are available in calculation jobs, "
"what they do and how they can be set will be explained in the :ref:`section "
"on options<working_calcjobs_options>`. Finally, the ``cmdline_params`` "
"attribute takes a list with command line parameters that will be placed "
"*after* the executable in the launch script. Here we use it to explicitly "
"instruct the executable to read its input from the filename stored in the "
"option ``input_filename``."
msgstr ""

#: ../docs/source/working/calculations.rst:190
msgid ""
"Since we instruct the executable should read the input from "
"``self.options.input_filename``, this is also the filename we used when "
"writing that very input file in the sandbox folder."
msgstr ""

#: ../docs/source/working/calculations.rst:192
msgid ""
"Finally, we have to define the various \"file lists\" that tell what files "
"to copy from where to where and what files to retrieve. Here we will briefly"
" describe their intended goals. The implementation details will be described"
" in full in the :ref:`file lists section<working_calcjobs_file_lists>`."
msgstr ""

#: ../docs/source/working/calculations.rst:196
msgid ""
"The local copy list is useful to instruct the engine to copy over files that"
" you might already have stored in your database, such as instances of "
":py:class:`~aiida.orm.nodes.data.singlefile.SinglefileData` nodes, that you "
"can define and pass as inputs of the ``CalcJob``. You could have of course "
"many copied their content to the ``folder`` sandbox folder, which will also "
"have caused them to be written to the working directory. The disadvantage of"
" that method, however, is that all the contents written to the sandbox "
"folder will also be stored in the repository of the ``CalcJobNode`` that "
"will represent the execution of the ``CalcJob`` in the provenance graph. "
"This will cause duplication of the data contained within these data nodes. "
"By not writing them explicitly to the sandbox folder, you avoid this "
"duplication, without losing provenance, because the data node itself will of"
" course be recorded in the provenance graph."
msgstr ""

#: ../docs/source/working/calculations.rst:202
msgid ""
"The remote copy list is useful to avoid unnecessary file transfers between "
"the machine where the engine runs and where the calculation jobs are "
"executed. For example, imagine you have already completed a calculation job "
"on a remote cluster and now want to launch a second one, that requires some "
"of the output files of the first run as its inputs. The remote copy list "
"allows you to specify exactly what output files to copy to the remote "
"working directory, without them having to be retrieved to the engine's "
"machine in between."
msgstr ""

#: ../docs/source/working/calculations.rst:206
msgid ""
"The retrieve list, finally, allows you to instruct the engine what files "
"should be retrieved from the working directory after the job has terminated."
" These files will be downloaded to the local machine, stored in a "
":py:class:`~aiida.orm.nodes.data.folder.FolderData` data node and attached "
"as an output to the ``CalcJobNode`` with the link label ``retrieved``."
msgstr ""

#: ../docs/source/working/calculations.rst:211
msgid ""
"We didn't explicitly define the ``retrieved`` folder data node as an output "
"in the example ``ArithmeticAddCalculation`` implementation shown above. This"
" is because this is already defined by the ``CalcJob`` base class. Just as "
"the ``code`` input, the ``retrieved`` output is common for all calculation "
"job implementations."
msgstr ""

#: ../docs/source/working/calculations.rst:219
msgid "File lists"
msgstr ""

#: ../docs/source/working/calculations.rst:224
msgid "Local copy list"
msgstr ""

#: ../docs/source/working/calculations.rst:225
msgid ""
"The local copy list takes tuples of length three, each of which represents a"
" file to be copied, defined through the following items:"
msgstr ""

#: ../docs/source/working/calculations.rst:227
msgid ""
"`node uuid`: the node whose repository contains the file, typically a "
"``SinglefileData`` or ``FolderData`` node"
msgstr ""

#: ../docs/source/working/calculations.rst:228
msgid ""
"`source relative path`: the relative path of the file within the node "
"repository"
msgstr ""

#: ../docs/source/working/calculations.rst:229
#: ../docs/source/working/calculations.rst:255
msgid ""
"`target relative path`: the relative path within the working directory to "
"which to copy the file"
msgstr ""

#: ../docs/source/working/calculations.rst:231
msgid ""
"As an example, consider a ``CalcJob`` implementation that receives a "
"``SinglefileData`` node as input with the name ``pseudopotential``, to copy "
"its contents one can specify:"
msgstr ""

#: ../docs/source/working/calculations.rst:237
msgid ""
"The ``SinglefileData`` node only contains a single file by definition, the "
"relative path of which is returned by the ``filename`` attribute. If "
"instead, you need to transfer a specific file from a ``FolderData``, you can"
" specify the explicit key of the file, like so:"
msgstr ""

#: ../docs/source/working/calculations.rst:244
msgid ""
"Note that the filenames in the relative source and target path need not be "
"the same. This depends fully on how the files are stored in the node's "
"repository and what files need to be written to the working directory."
msgstr ""

#: ../docs/source/working/calculations.rst:250
msgid "Remote copy list"
msgstr ""

#: ../docs/source/working/calculations.rst:251
msgid ""
"The remote copy list takes tuples of length three, each of which represents "
"a file to be copied on the remote machine where the calculation will run, "
"defined through the following items:"
msgstr ""

#: ../docs/source/working/calculations.rst:253
msgid ""
"`computer uuid`: this is the UUID of the ``Computer`` on which the source "
"file resides. For now the remote copy list can only copy files on the same "
"machine where the job will run."
msgstr ""

#: ../docs/source/working/calculations.rst:254
msgid ""
"`source absolute path`: the absolute path of the source file on the remote "
"machine"
msgstr ""

#: ../docs/source/working/calculations.rst:261
msgid ""
"Note that the source path can point to a directory, in which case its "
"contents will be recursively copied in its entirety."
msgstr ""

#: ../docs/source/working/calculations.rst:266
msgid "Retrieve list"
msgstr ""

#: ../docs/source/working/calculations.rst:267
msgid ""
"The retrieve list supports various formats to define what files should be "
"retrieved. The simplest is retrieving a single file, whose filename you know"
" before hand and you simply want to copy with the same name in the retrieved"
" folder. Imagine you want to retrieve the files ``output.out`` and "
"``output_folder/output.out`` you would simply add them as strings to the "
"retrieve list:"
msgstr ""

#: ../docs/source/working/calculations.rst:275
msgid ""
"The retrieved files will be copied over keeping the exact names and "
"hierarchy. If you require more control over the hierarchy and nesting, you "
"can use tuples of length three instead, with the following items:"
msgstr ""

#: ../docs/source/working/calculations.rst:278
msgid ""
"`source relative path`: the relative path, with respect to the working "
"directory on the remote, of the file or directory to retrieve"
msgstr ""

#: ../docs/source/working/calculations.rst:279
msgid ""
"`target relative path`: the relative path where to copy the files locally in"
" the retrieved folder. The string `'.'` indicates the top level in the "
"retrieved folder."
msgstr ""

#: ../docs/source/working/calculations.rst:280
msgid ""
"`depth`: the number of levels of nesting in the folder hierarchy to maintain"
" when copying, starting from the deepest file"
msgstr ""

#: ../docs/source/working/calculations.rst:282
msgid ""
"For example, imagine the calculation will have written a file in the remote "
"working directory with the folder hierarchy "
"``some/remote/path/files/output.dat``. If you want to copy the file, with "
"the final resulting path ``path/files/output.dat``, you would specify:"
msgstr ""

#: ../docs/source/working/calculations.rst:289
msgid ""
"The depth of two, ensures that only two levels of nesting are copied. If the"
" output files have dynamic names that one cannot know beforehand, the "
"``'*'`` glob pattern can be used. For example, if the code will generate a "
"number of XML files in the folder ``relative/path/output`` with filenames "
"that follow the pattern ``file_*[0-9].xml``, you can instruct to retrieve "
"all of them as follows:"
msgstr ""

#: ../docs/source/working/calculations.rst:297
msgid ""
"The second item when using globbing *has* to be ``'.'`` and the depth works "
"just as before. In this example, all files matching the globbing pattern "
"will be copied in the directory ``output`` in the retrieved folder data "
"node."
msgstr ""

#: ../docs/source/working/calculations.rst:302
msgid "Retrieve temporary list"
msgstr ""

#: ../docs/source/working/calculations.rst:303
msgid ""
"Recall that, as explained in the :ref:`'prepare' "
"section<working_calcjobs_prepare>`, all the files that are retrieved by the "
"engine following the 'retrieve list', are stored in the ``retrieved`` folder"
" data node. This means that any file you retrieve for a completed "
"calculation job will be stored in your repository. If you are retrieving big"
" files, this can cause your repository to grow significantly. Often, "
"however, you might only need a part of the information contained in these "
"retrieved files. To solve this common issue, there is the concept of the "
"'retrieve temporary list'. The specification of the retrieve temporary list "
"is identical to that of the normal :ref:`retrieve "
"list<working_calcjobs_file_lists_retrieve>`. The only difference is that, "
"unlike the files of the retrieve list which will be permanently stored in "
"the retrieved :py:class:`~aiida.orm.nodes.data.folder.FolderData` node, the "
"files of the retrieve temporary list will be stored in a temporary sandbox "
"folder. This folder is then passed to the "
":ref:`parser<working_calcjobs_parsers>`, if one was specified for the "
"calculation job. The parser implementation can then parse these files and "
"store the relevant information as output nodes. After the parser terminates,"
" the engine will take care to automatically clean up the sandbox folder with"
" the temporarily retrieved files. The contract of the 'retrieve temporary "
"list' is essentially that the files will be available during parsing and "
"will be destroyed immediately afterwards."
msgstr ""

#: ../docs/source/working/calculations.rst:319
msgid "Options"
msgstr ""

#: ../docs/source/working/calculations.rst:320
msgid ""
"In addition to the common metadata inputs, such as ``label`` and "
"``description``, that all processes have, the "
":py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` has an "
"additonal input called ``options``. These options allow to subtly change the"
" behavior of the calculation job, for example which parser should be used "
"once it is finished and special scheduler directives. The full list of "
"available options are as follows:"
msgstr ""

#: ../docs/source/working/calculations.rst:324
msgid ":ref:`parser_name<working_calcjobs_options_parser_name>`"
msgstr ":ref:`parser_name<working_calcjobs_options_parser_name>`"

#: ../docs/source/working/calculations.rst:325
msgid ":ref:`input_filename<working_calcjobs_options_input_filename>`"
msgstr ":ref:`input_filename<working_calcjobs_options_input_filename>`"

#: ../docs/source/working/calculations.rst:326
msgid ":ref:`output_filename<working_calcjobs_options_output_filename>`"
msgstr ":ref:`output_filename<working_calcjobs_options_output_filename>`"

#: ../docs/source/working/calculations.rst:327
msgid ":ref:`scheduler_stdout<working_calcjobs_options_scheduler_stdout>`"
msgstr ":ref:`scheduler_stdout<working_calcjobs_options_scheduler_stdout>`"

#: ../docs/source/working/calculations.rst:328
msgid ":ref:`scheduler_stderr<working_calcjobs_options_scheduler_stderr>`"
msgstr ":ref:`scheduler_stderr<working_calcjobs_options_scheduler_stderr>`"

#: ../docs/source/working/calculations.rst:329
msgid ":ref:`resources<working_calcjobs_options_resources>`"
msgstr ":ref:`resources<working_calcjobs_options_resources>`"

#: ../docs/source/working/calculations.rst:330
msgid ""
":ref:`max_wallclock_seconds<working_calcjobs_options_max_wallclock_seconds>`"
msgstr ""
":ref:`max_wallclock_seconds<working_calcjobs_options_max_wallclock_seconds>`"

#: ../docs/source/working/calculations.rst:331
msgid ""
":ref:`custom_scheduler_commands<working_calcjobs_options_custom_scheduler_commands>`"
msgstr ""
":ref:`custom_scheduler_commands<working_calcjobs_options_custom_scheduler_commands>`"

#: ../docs/source/working/calculations.rst:332
msgid ":ref:`queue_name<working_calcjobs_options_queue_name>`"
msgstr ""

#: ../docs/source/working/calculations.rst:333
msgid ":ref:`account<working_calcjobs_options_account>`"
msgstr ""

#: ../docs/source/working/calculations.rst:334
msgid ":ref:`qos<working_calcjobs_options_qos>`"
msgstr ""

#: ../docs/source/working/calculations.rst:335
msgid ":ref:`computer<working_calcjobs_options_computer>`"
msgstr ""

#: ../docs/source/working/calculations.rst:336
msgid ":ref:`withmpi<working_calcjobs_options_withmpi>`"
msgstr ""

#: ../docs/source/working/calculations.rst:337
msgid ""
":ref:`mpirun_extra_params<working_calcjobs_options_mpirun_extra_params>`"
msgstr ""

#: ../docs/source/working/calculations.rst:338
msgid ""
":ref:`import_sys_environment<working_calcjobs_options_import_sys_environment>`"
msgstr ""

#: ../docs/source/working/calculations.rst:339
msgid ""
":ref:`environment_variables<working_calcjobs_options_environment_variables>`"
msgstr ""

#: ../docs/source/working/calculations.rst:340
msgid ":ref:`priority<working_calcjobs_options_priority>`"
msgstr ""

#: ../docs/source/working/calculations.rst:341
msgid ":ref:`max_memory_kb<working_calcjobs_options_max_memory_kb>`"
msgstr ""

#: ../docs/source/working/calculations.rst:342
msgid ":ref:`prepend_text<working_calcjobs_options_prepend_text>`"
msgstr ""

#: ../docs/source/working/calculations.rst:343
msgid ":ref:`append_text<working_calcjobs_options_append_text>`"
msgstr ""

#: ../docs/source/working/calculations.rst:345
msgid "More detailed information about their usage, follows below."
msgstr ""

#: ../docs/source/working/calculations.rst:350
msgid "``parser_name``"
msgstr ""

#: ../docs/source/working/calculations.rst:355
msgid "``input_filename``"
msgstr ""

#: ../docs/source/working/calculations.rst:360
msgid "``output_filename``"
msgstr ""

#: ../docs/source/working/calculations.rst:365
msgid "``scheduler_stdout``"
msgstr ""

#: ../docs/source/working/calculations.rst:370
msgid "``scheduler_stderr``"
msgstr ""

#: ../docs/source/working/calculations.rst:375
msgid "``resources``"
msgstr ""

#: ../docs/source/working/calculations.rst:380
msgid "``max_wallclock_seconds``"
msgstr ""

#: ../docs/source/working/calculations.rst:385
msgid "``custom_scheduler_commands``"
msgstr ""

#: ../docs/source/working/calculations.rst:390
msgid "``queue_name``"
msgstr ""

#: ../docs/source/working/calculations.rst:395
msgid "``account``"
msgstr ""

#: ../docs/source/working/calculations.rst:400
msgid "``qos``"
msgstr ""

#: ../docs/source/working/calculations.rst:405
msgid "``computer``"
msgstr ""

#: ../docs/source/working/calculations.rst:410
msgid "``withmpi``"
msgstr ""

#: ../docs/source/working/calculations.rst:415
msgid "``mpirun_extra_params``"
msgstr ""

#: ../docs/source/working/calculations.rst:420
msgid "``import_sys_environment``"
msgstr ""

#: ../docs/source/working/calculations.rst:425
msgid "``environment_variables``"
msgstr ""

#: ../docs/source/working/calculations.rst:430
msgid "``priority``"
msgstr ""

#: ../docs/source/working/calculations.rst:435
msgid "``max_memory_kb``"
msgstr ""

#: ../docs/source/working/calculations.rst:440
msgid "``prepend_text``"
msgstr ""

#: ../docs/source/working/calculations.rst:445
msgid "``append_text``"
msgstr ""

#: ../docs/source/working/calculations.rst:451
msgid "Launch"
msgstr ""

#: ../docs/source/working/calculations.rst:453
msgid ""
"Launching a calculation job is no different from launching any other process"
" class, so please refer to the section on :ref:`launching "
"processes<working_processes_launch>`. The only caveat that we should place "
"is that calculation jobs typically tend to take quite a bit of time. The "
"trivial example we used above of course will run very fast, but a typical "
"calculation job that will be submitted to a scheduler will most likely take "
"longer than just a few seconds. For that reason it is highly advisable to "
"**submit** calculation jobs instead of running them. By submitting them to "
"the daemon, you free up your interpreter straight away and the process will "
"be checkpointed between the various :ref:`transport "
"tasks<concepts_calcjobs_transport_tasks>` that will have to be performed. "
"The exception is of course when you want to run a calculation job locally "
"for testing or demonstration purposes."
msgstr ""

#: ../docs/source/working/calculations.rst:464
msgid "Dry run"
msgstr ""

#: ../docs/source/working/calculations.rst:465
msgid ""
"The calculation job has one additional feature over all other processes when"
" it comes to launching them. Since an incorrectly configured calculation job"
" can potentially waste computational resources, one might want to inspect "
"the input files that will be written by the plugin, before actually "
"submitting the job. A so-called dry-run is possible by simply specifying it "
"in the metadata of the inputs. If you are using the process builder, it is "
"as simple as:"
msgstr ""

#: ../docs/source/working/calculations.rst:474
msgid ""
"When you now launch the process builder, the engine will perform the entire "
"process of a normal calculation job run, except that it will not actually "
"upload and submit the job to the remote computer. However, the "
"``prepare_for_submission`` method will be called. The inputs that it writes "
"to the input folder will be stored in temporary folder called "
"``submit_test`` that will be created in the current working directory. Each "
"time you perform a dry-run, a new sub folder will be created in the "
"``submit_test`` folder, which you allows you to perform multiple dry-runs "
"without overwriting the previous results."
msgstr ""

#: ../docs/source/working/calculations.rst:481
msgid ""
"By default the storing of provenance is enabled and this goes also for a dry"
" run. If you do not want any nodes to be created during a dry run, simply "
"set the metadata input ``store_provenance`` to ``False``."
msgstr ""

#: ../docs/source/working/calculations.rst:488
msgid "Parsing"
msgstr ""

#: ../docs/source/working/calculations.rst:489
msgid ""
"The previous sections explained in detail how the execution of an external "
"executable is wrapped by the ``CalcJob`` class to make it runnable by "
"AiiDA's engine. From the first steps of preparing the input files on the "
"remote machine, to retrieving the relevant files and storing them in a "
":py:class:`~aiida.orm.nodes.data.folder.FolderData` node, that is attached "
"as the ``retrieved`` output. This is the last *required* step for a "
"``CalcJob`` to terminate, but often we would *like* to parse the raw output "
"and attach them as queryable output nodes to the calculation job node. To "
"automatically trigger the parsing of a calculation job after its output has "
"been retrieved, is to specify the :ref:`parser name "
"option<working_calcjobs_options_parser_name>`. If the engine find this "
"option specified, it will load the corresponding parser class, which should "
"be a sub class of :py:class:`~aiida.parsers.parser.Parser` and calls its "
":py:meth:`~aiida.parsers.parser.Parser.parse` method."
msgstr ""

#: ../docs/source/working/calculations.rst:495
msgid ""
"To explain the interface of the ``Parser`` class and the ``parse`` method, "
"let's take the "
":py:class:`~aiida.parsers.plugins.arithmetic.add.ArithmeticAddParser` as an "
"example. This parser is designed to parse the output produced by the simple "
"bash script that is wrapped by the ``ArithmeticAddCalculation`` discussed in"
" the previous sections."
msgstr ""

#: ../docs/source/working/calculations.rst:502
msgid ""
"To create a new parser implementation, simply create a new class that sub "
"classes the :py:class:`~aiida.parsers.parser.Parser` class. As usual, any "
"valid python class name will work, but the convention is to always use the "
"``Parser`` suffix and to use the same name as the calculation job for which "
"the parser is designed. For example, here we are implementing a parser for "
"the ``ArithmeticAddCalculation``, so therefore we name it "
"``ArithmeticAddParser``, just replacing the ``Calculation`` suffix for "
"``Parser``. The only method that needs to be implemented is the "
":py:meth:`~aiida.parsers.parser.Parser.parse` method. Its signature should "
"include ``**kwargs``, the reason for which will become clear later. The goal"
" of the ``parse`` method is very simple:"
msgstr ""

#: ../docs/source/working/calculations.rst:509
msgid ""
"Open and load the content of the output files generated by the calculation "
"job and have been retrieved by the engine"
msgstr ""

#: ../docs/source/working/calculations.rst:510
msgid ""
"Create data nodes out of this raw data that are attached as output nodes"
msgstr ""

#: ../docs/source/working/calculations.rst:511
msgid "Log human-readable warning messages in the case of worrying output"
msgstr ""

#: ../docs/source/working/calculations.rst:512
msgid ""
"Optionally return an :ref:`exit code<concepts_process_exit_codes>` to "
"indicate that the results of the calculation was not successful"
msgstr ""

#: ../docs/source/working/calculations.rst:514
msgid ""
"The advantage of adding the raw output data in different form as output "
"nodes, is that in that form the content becomes queryable. This allows one "
"to query for calculations that produced specific outputs with a certain "
"value, which becomes a very powerful approach for post-processing and "
"analyses of big databases."
msgstr ""

#: ../docs/source/working/calculations.rst:517
msgid ""
"The ``retrieved`` attribute of the parser will return the ``FolderData`` "
"node that should have been attached by the engine containing all the "
"retrieved files, as specified using the :ref:`retrieve "
"list<working_calcjobs_file_lists_retrieve>` in the :ref:`preparation step of"
" the calculation job<working_calcjobs_prepare>`. If this node has not been "
"attached for whatever reason, this call will throw an "
":py:class:`~aiida.common.exceptions.NotExistent` exception. This is why we "
"wrap the ``self.retrieved`` call in a try-catch block:"
msgstr ""

#: ../docs/source/working/calculations.rst:527
msgid ""
"If the exception is thrown, it means the retrieved files are not available "
"and something must have has gone terribly awry with the calculation. In this"
" case, there is nothing to do for the parser and so we return an exit code. "
"Specific exit codes can be referenced by their label, such as "
"``ERROR_NO_RETRIEVED_FOLDER`` in this example, through the "
"``self.exit_codes`` property. This call will retrieve the corresponding exit"
" code defined on the ``CalcJob`` that we are currently parsing. Returning "
"this exit code from the parser will stop the parsing immediately and will "
"instruct the engine to set its exit status and exit message on the node of "
"this calculation job. This should scenario should however never occur, but "
"it is just here as a safety. If the exception would not be caught, the "
"engine will catch the exception instead and set the process state of the "
"corresponding calculation to ``Excepted``. Note that this will happen for "
"any exception that occurs during parsing."
msgstr ""

#: ../docs/source/working/calculations.rst:536
msgid ""
"Assuming that everything went according to plan during the retrieval, we now"
" have access to those retrieved files and can start to parse them. In this "
"example, there should be a single output file that was written by "
"redirecting the standard output of the bash script that added the two "
"integers. The parser opens this file, reads its content and tries to parse "
"the sum from it:"
msgstr ""

#: ../docs/source/working/calculations.rst:546
msgid ""
"Note that again we wrap this parsing action in a try-except block. If the "
"file cannot be found or cannot be read, we return the appropriate exit code."
" The ``parse_stdout`` method is just a small utility function to separate "
"the actual parsing of the data from the main parser code. In this case, the "
"parsing is so simple that we might have as well kept it in the main method, "
"but this is just to illustrate that you are completely free to organize the "
"code within the ``parse`` method for clarity. If we manage to parse the sum,"
" produced by the calculation, we wrap it in the appropriate "
":py:class:`~aiida.orm.nodes.data.int.Int` data node class, and register it "
"as an output through the ``out`` method:"
msgstr ""

#: ../docs/source/working/calculations.rst:558
msgid ""
"Note that if we encountered no problems, we do not have to return anything. "
"The engine will interpret this as the calculation having finished "
"successfully. You might now pose the question: \"what part of the raw data "
"should I parse and in what types of data nodes should I store it?\". This "
"not an easy question to answer in the general, because it will heavily "
"depend on the type of raw output that is produced by the calculation and "
"what parts you would like to be queryable. However, we can give you some "
"guidelines:"
msgstr ""

#: ../docs/source/working/calculations.rst:564
msgid ""
"Store data that you might want to query for, in the lightweight data nodes, "
"such as :py:class:`~aiida.orm.nodes.data.dict.Dict`, "
":py:class:`~aiida.orm.nodes.data.list.List` and "
":py:class:`~aiida.orm.nodes.data.structure.StructureData`. The contents of "
"these nodes are stored as attributes in the database, which makes sure that "
"they can be queried for."
msgstr ""

#: ../docs/source/working/calculations.rst:566
msgid ""
"Bigger data sets, such as large (multi-dimnensional) arrays, are better "
"stored in an :py:class:`~aiida.orm.nodes.data.array.array.ArrayData` or one "
"of its sub classes. If you were to store all this data in the database, it "
"would become unnecessarily bloated, because the chances you would have to "
"query for this data are unlikely. Instead these array type data nodes store "
"the bulk of their content in the repository. This way you still keep the "
"data and therewith the provenance of your calculations, while keeping your "
"database lean and fast!"
msgstr ""

#: ../docs/source/working/functions.rst:5
msgid "Calculation and work functions"
msgstr ""

#: ../docs/source/working/functions.rst:7
msgid ""
"A process function is a process (see the :ref:`process "
"section<concepts_processes>` for details) that is implemented as a decorated"
" python function. Currently, there are two types of process functions:"
msgstr ""

#: ../docs/source/working/functions.rst:10
msgid ":ref:`calculation function<concepts_calcfunctions>`"
msgstr ""

#: ../docs/source/working/functions.rst:11
msgid ":ref:`work function<concepts_workfunctions>`"
msgstr ""

#: ../docs/source/working/functions.rst:13
msgid ""
"The former can *create* new data, whereas the latter can orchestrate other "
"processes and *return* their results. This section will provide detailed "
"information and best practices on how to implement these two process types. "
"Since the calculation function and work function are both process functions "
"and have the same implementation, all the rules explained below apply to "
"both process types."
msgstr ""

#: ../docs/source/working/functions.rst:18
msgid ""
"This chapter assumes that the basic concept and difference between "
"calculation functions and work functions is known and when one should use on"
" or the other. It is therefore crucial that, before you continue, you have "
"read and understood the basic concept of :ref:`calculation "
"functions<concepts_calcfunctions>` and :ref:`work "
"functions<concepts_workfunctions>`."
msgstr ""

#: ../docs/source/working/functions.rst:21
msgid ""
"The simple example in the :ref:`introductory section on calculation "
"functions<concepts_calcfunctions>` showed how a simple python function can "
"be turned into a calculation function simply by adorning it with the "
":py:func:`~aiida.engine.processes.functions.calcfunction` decorator. When "
"the function is run, AiiDA will dynamically generate a "
":py:class:`~aiida.engine.processes.functions.FunctionProcess` and build its "
":ref:`process specification<working_processes_spec>` based on the function "
"signature. Here we will explain how this is accomplished and what features "
"of the python function signature standard are supported."
msgstr ""

#: ../docs/source/working/functions.rst:26
msgid "Function signatures"
msgstr ""

#: ../docs/source/working/functions.rst:27
msgid ""
"To explain what features of python function definitions and calls are "
"supported we first need to be clear about some terminology. When dealing "
"with functions, there are two distinct parts:"
msgstr ""

#: ../docs/source/working/functions.rst:30
msgid ""
"`function definitions "
"<https://docs.python.org/3/reference/compound_stmts.html#function-"
"definitions>`_"
msgstr ""

#: ../docs/source/working/functions.rst:31
msgid ""
"`function calls "
"<https://docs.python.org/3/reference/expressions.html#calls>`_"
msgstr ""

#: ../docs/source/working/functions.rst:33
msgid ""
"Consider the following code snippet that defines a simple python function:"
msgstr ""

#: ../docs/source/working/functions.rst:38
msgid ""
"The function takes three 'parameters', named ``x``, ``y`` and ``z``. In "
"addition, the function ``plain_function`` is said to have default values, "
"because one or more parameters (``z`` in this case) have the form `parameter"
" = expression`. When *calling* a function, the terminology changes slightly "
"and values for parameters can be passed as either 'positional' or 'keyword'."
" In the example below, the function is called with 'positional' arguments:"
msgstr ""

#: ../docs/source/working/functions.rst:46
msgid ""
"They are called positional, because the arguments are not explicitly named "
"and so will be matched to the corresponding parameter solely based on their "
"position in the function call. In this example, ``x``, ``y`` and ``z`` will "
"have the values ``1``, ``2`` and ``3``, respectively. Since we specified "
"three values, the default for the third parameter ``z`` was not actually "
"used. However, we are allowed to only specify two arguments, in which case "
"the default *will* be used as can be seen below:"
msgstr ""

#: ../docs/source/working/functions.rst:54
msgid ""
"By not specifying the third argument, the default will be used, so in this "
"case ``z`` will equal ``1``. Additionally, one can employ 'named' arguments "
"to specifically target a parameter based on its name, instead of having to "
"rely on its position:"
msgstr ""

#: ../docs/source/working/functions.rst:60
msgid ""
"Notice how the order in which we pass the arguments is irrelevant because we"
" specify the name of each argument explicitly when assigning the value. Now "
"that we know the difference between positional and named arguments, it is "
"important to realize a python requirement that **positional arguments have "
"to come before named arguments**. What this means is that *both* the "
"function definition and function call below are illegal, because there are "
"named arguments before positional ones:"
msgstr ""

#: ../docs/source/working/functions.rst:67
msgid ""
"Finally, python knows the concept of ``*args`` and ``**kwargs``, also "
"referred to as variable arguments and keyword arguments, which allow one to "
"define a function which accepts an undetermined number of positional and "
"keyword arguments."
msgstr ""

#: ../docs/source/working/functions.rst:72
msgid ""
"The variable arguments ``*args`` will receive the positionally passed "
"arguments as a tuple and the keyword arguments ``**kwargs`` will receive the"
" named arguments as a dictionary. With the formal definitions out of the "
"way, let's now see which of these concepts are supported by process "
"functions."
msgstr ""

#: ../docs/source/working/functions.rst:76
msgid "Default arguments"
msgstr ""

#: ../docs/source/working/functions.rst:77
msgid ""
"Default arguments are supported by calculation functions just as normal "
"python functions as long as it is a :py:class:`~aiida.orm.nodes.node.Node` "
"instance, just like the inputs or ``None``. However, just as with python "
"functions, one should only use immutable objects as function defaults "
"because mutable objects can give unexpected results as they will be kept "
"between function calls. Therefore, in order to use a default value for "
"process functions, simply use ``None`` as the default value and check for "
"its presence in the function body settings the default value if it is "
"``None``. This pattern looks like the following:"
msgstr ""

#: ../docs/source/working/functions.rst:85
msgid ""
"Both function calls in the example above will have the exact same result."
msgstr ""

#: ../docs/source/working/functions.rst:88
msgid "Variable and keyword arguments"
msgstr ""

#: ../docs/source/working/functions.rst:89
msgid ""
"Variable arguments are *not* supported by process functions. The reasoning "
"behind this is that the process specification for the "
":py:class:`~aiida.engine.processes.functions.FunctionProcess` is built "
"dynamically based on the function signature and so the names of the inputs "
"are based on the parameter name from the function definition, or the named "
"argument when the function is called. Since for variable arguments, neither "
"at function definition nor at function call, explicit parameter names are "
"used, the engine can impossibly determine what names, and by extensions link"
" label, to use for the inputs."
msgstr ""

#: ../docs/source/working/functions.rst:93
msgid ""
"In contrast, keyword arguments for that reason *are* supported and it is the"
" keyword used when the function is called that determines the names of the "
"parameters and the labels of the input links. The following snippet is "
"therefore perfectly legal and will return the sum of all the nodes that are "
"passed:"
msgstr ""

#: ../docs/source/working/functions.rst:99
msgid "The provenance generated by this example looks like the following:"
msgstr ""

#: ../docs/source/working/functions.rst:104
msgid ""
"The link labels of the inputs are determined based on the naming of the "
"parameters when the function is called."
msgstr ""

#: ../docs/source/working/functions.rst:106
msgid ""
"Note that the inputs **have to be passed as keyword arguments** because they"
" are used for the link labels. If the inputs would simply have been passed "
"as positional arguments, the engine could have impossibly determined what "
"label to use for the links that connect the input nodes with the calculation"
" function node. For this reason, invoking a 'dynamic' function, i.e. one "
"that supports ``**kwargs`` in its signature, with more positional arguments "
"that explicitly named in the signature, will raise a ``TypeError``."
msgstr ""

#: ../docs/source/working/functions.rst:111
msgid "Return values"
msgstr ""

#: ../docs/source/working/functions.rst:112
msgid ""
"In :numref:`fig_calculation_functions_kwargs` you can see that the engine "
"used the label ``result`` for the link connecting the calculation function "
"node with its output node. This is the default link label if only a single "
"result is returned from the calculation function. If you want to specify a "
"label yourself, you can return the result in the form of a dictionary, where"
" the key will be used as the link label. By using a dictionary you can also "
"record multiple nodes as output. Consider the following snippet:"
msgstr ""

#: ../docs/source/working/functions.rst:121
msgid ""
"The provenance generated by running this calculation function will look "
"like:"
msgstr ""

#: ../docs/source/working/functions.rst:126
msgid ""
"If a dictionary is returned, the keys will be used as the labels for the "
"links that connect the output nodes with the calculation node."
msgstr ""

#: ../docs/source/working/functions.rst:128
msgid ""
"As always, all the values returned by a calculation function have to be "
"storable, which means they have to be instances of the "
":py:class:`~aiida.orm.nodes.node.Node` class."
msgstr ""

#: ../docs/source/working/functions.rst:131
msgid ""
"It is very important that you **do not call** "
":py:meth:`~aiida.orm.nodes.node.Node.store` **yourself** on the nodes before"
" returning them from a ``calcfunction``. Because of the calculation/workflow"
" duality in AiiDA, a ``calcfunction``, which is a calculation-like process, "
"can only *create* and not *return* data nodes. This means that if a node is "
"returned from a ``calcfunction`` that *is already stored*, the engine will "
"throw an exception."
msgstr ""

#: ../docs/source/working/functions.rst:137
#: ../docs/source/working/processes.rst:211
#: ../docs/source/working/workflows.rst:109
#: ../docs/source/working/workflows.rst:274
msgid "Exit codes"
msgstr ""

#: ../docs/source/working/functions.rst:138
msgid ""
"So far we have only seen examples of calculation functions where everything "
"works out just fine. However, the real world is different, and often we will"
" encounter situations where problems arise. A calculation function may "
"receive incorrect or incoherent inputs, or the code it executes may throw an"
" exception. Of course we could throw an input validation exception or not "
"even catch the exceptions that the code we call throws, but that will lead "
"the function process to be put in the ``Excepted`` terminal state. As "
"explained in the :ref:`process state<concepts_process_state>` section, this "
"state is indeed reserved for processes that incurred an exception during "
"execution. Consider the following calculation function definition and call:"
msgstr ""

#: ../docs/source/working/functions.rst:148
msgid ""
"Because the value for ``y`` that is being passed is zero, the engine will "
"encounter a ``ZeroDivisionError`` exception when the calculation function is"
" run. The output of ``verdi process list`` will confirm that the process has"
" excepted:"
msgstr ""

#: ../docs/source/working/functions.rst:159
msgid ""
"Exceptions that occur during the execution of a process are recorded as a "
"log message on the corresponding process node. To show these log messages, "
"one can use ``verdi process report``. In the case of the example above, it "
"would look something like the following:"
msgstr ""

#: ../docs/source/working/functions.rst:178
msgid ""
"However, in this particular example the exception is not so much an "
"unexpected error, but one we could have considered and have seen coming, so "
"it might be more applicable to simply mark the process as failed. To "
"accomplish this, there is the concept of an :ref:`exit "
"status<concepts_process_exit_codes>` that can be set on the process, which "
"is an integer that, when non-zero, marks a process in the ``Finished`` state"
" as 'failed'. Since the exit status is set as an attribute on the process "
"node, it also makes it very easy to query for failed processes. To set a "
"non-zero exit status on a calculation function to indicate it as failed, "
"simply return an instance of the "
":py:class:`~aiida.engine.processes.exit_code.ExitCode` named tuple. Time for"
" a demonstration:"
msgstr ""

#: ../docs/source/working/functions.rst:187
msgid ""
"When we run the calculation function now, with the same inputs, instead of "
"excepting, the process will successfully terminate and its exit status will "
"be set to the value stored in the ``ExitCode``. The exit status is also "
"displayed by ``verdi process list``:"
msgstr ""

#: ../docs/source/working/functions.rst:199
msgid ""
"Both approaches are valid and which one to use depends on your use case. The"
" question you should ask yourself is whether a potential problem merits "
"throwing the process on the pile of 'excepted' processes. Or maybe, as in "
"the example above, the problem is easily foreseeable and classifiable with a"
" well defined exit status, in which case it might make more sense to return "
"the exit code. At the end one should think which solution makes it easier "
"for a workflow calling the function to respond based on the result and what "
"makes it easier to query for these specific failure modes."
msgstr ""

#: ../docs/source/working/functions.rst:206
msgid "Provenance"
msgstr ""

#: ../docs/source/working/functions.rst:207
msgid ""
"In addition to the basic attributes that are stored for all processes such "
"as the process state and label, the process functions automatically store "
"additional information that relates to the source code of the function they "
"represent:"
msgstr ""

#: ../docs/source/working/functions.rst:209
msgid "Function name"
msgstr ""

#: ../docs/source/working/functions.rst:210
msgid "Function namespace"
msgstr ""

#: ../docs/source/working/functions.rst:211
msgid "Function starting line number"
msgstr ""

#: ../docs/source/working/functions.rst:212
msgid "Function source file"
msgstr ""

#: ../docs/source/working/functions.rst:214
msgid ""
"The first three are retrieved by inspecting the python source code as soon "
"as the process function is executed and are stored as attributes on the "
"process node. They can be accessed through the corresponding properties on "
"the process node as follows:"
msgstr ""

#: ../docs/source/working/functions.rst:220
msgid ""
"The source code of the file in which the function is defined is also stored,"
" but since it can be quite big, it is stored as a raw file in the repository"
" of the process node. It can be retrieved through the "
":py:meth:`~aiida.orm.utils.mixins.FunctionCalculationMixin.get_function_source_code`"
" method."
msgstr ""

#: ../docs/source/working/functions.rst:223
msgid ""
"The attributes give some querability to the process functions stored in the "
"provenance graph and by storing the source code of the function that was "
"executed, there will be some reference in the future to track how the "
"function created its output nodes. Note, however, that just storing the "
"source file of the function does not guarantee that one can reproduce the "
"exact result. For example, one can 'leak' data into the function by reading "
"a file or loading an existing node from the database that was not explicitly"
" passed as an input. Alternatively, external code can be imported and "
"called, the source code of which will not be recorded."
msgstr ""

#: ../docs/source/working/functions.rst:229
msgid "Reproducibility guidelines"
msgstr ""

#: ../docs/source/working/functions.rst:230
msgid ""
"Due to the nature of the way process functions are implemented, it is "
"impossible to guarantee 100% reproducibility, but by following the following"
" guidelines, one can come as close as possible."
msgstr ""

#: ../docs/source/working/functions.rst:232
msgid "Do not leak data into functions"
msgstr ""

#: ../docs/source/working/functions.rst:233
msgid "Limit importing of external code"
msgstr ""

#: ../docs/source/working/functions.rst:234
msgid "Keep functions self-consistent and in separate files"
msgstr ""

#: ../docs/source/working/functions.rst:236
msgid ""
"Leaking data into functions is accomplished for example by reading a file on"
" the local file system in the function body and using its contents for the "
"creation of the outputs. Even if you store the source code, if you don't "
"possess the file that was read, it is impossible to reproduce the results. "
"Likewise, you should not load any existing data from the database through "
"the API, but rather they should be direct inputs of the process function."
msgstr ""

#: ../docs/source/working/functions.rst:240
msgid ""
"A similar problem occurs when importing other python code. Practically, it "
"is almost impossible to never import code into process functions, as this "
"would force massive code duplication. However, there is still a difference "
"between importing code from the ``aiida-core`` library or the repository in "
"which the process function is hosted, and the importing of a local python "
"file. Even though for both cases there can no be guarantee of "
"reproducibility, the former stands a better chance by far, as the version "
"number of the plugin should be recorded. The rule of thumb then is to keep "
"the importing of code to a minimum, but if you have to, make sure to make it"
" part of a plugin package with a well-defined version number."
msgstr ""

#: ../docs/source/working/functions.rst:246
msgid ""
"Finally, as mentioned in the introduction, the source file of a process "
"function is stored as a file in the repository for *each execution*. "
"Currently there is no automatic deduplication for identical files by the "
"engine, so these files may occupy quite a bit of space. For this reason it "
"is advisable to keep each process function in its own separate file. This "
"not only improves readability, but it also minimizes the impact on the size "
"of the file repository."
msgstr ""

#: ../docs/source/working/processes.rst:5
msgid "Processes"
msgstr ""

#: ../docs/source/working/processes.rst:7
msgid ""
"Before you start working with processes, make sure you have read and "
"understood the :ref:`basic concept<concepts_processes>`. This section will "
"explain the aspects of working with processes that apply to all the various "
"types of processes. Details that only pertain to a specific sub type of "
"process, will be documented in their respective sections:"
msgstr ""

#: ../docs/source/working/processes.rst:11
msgid ":ref:`calculation functions<working_calcfunctions>`"
msgstr ""

#: ../docs/source/working/processes.rst:12
msgid ":ref:`calculation jobs<working_calcjobs>`"
msgstr ""

#: ../docs/source/working/processes.rst:13
msgid ":ref:`work functions<working_workfunctions>`"
msgstr ""

#: ../docs/source/working/processes.rst:14
msgid ":ref:`work chains<working_workchains>`"
msgstr ""

#: ../docs/source/working/processes.rst:16
msgid ""
"Since all of these are types of processes, everything that will be explained"
" in this section, will apply to each and everyone of them. That makes it "
"very useful to read and understand this section well, as the concepts apply "
"so broadly. However, for the same reason, at times this section may feel a "
"bit abstract. It may therefore be advisable to start reading a section on "
"one of the more specific processes listed above first, to get a more "
"concrete example, and then simply refer back here for a more extensive "
"explanation of the details."
msgstr ""

#: ../docs/source/working/processes.rst:25
msgid "Defining processes"
msgstr ""

#: ../docs/source/working/processes.rst:30
msgid "Process specification"
msgstr ""

#: ../docs/source/working/processes.rst:31
msgid ""
"How a process defines the inputs that it requires or can optionally take, "
"depends on the process type. The inputs of "
":py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` and "
":py:class:`~aiida.engine.processes.workchains.workchain.WorkChain` are given"
" by the :py:class:`~aiida.engine.processes.process_spec.ProcessSpec` class, "
"which is defined though  the "
":py:meth:`~aiida.engine.processes.process.Process.define` method. For "
"process functions, the "
":py:class:`~aiida.engine.processes.process_spec.ProcessSpec` is dynamically "
"generated by the engine from the signature of the decorated function. "
"Therefore, to determine what inputs a process takes, one simply has to look "
"at the process specification in the ``define`` method or the function "
"signature. For the "
":py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` and "
":py:class:`~aiida.engine.processes.workchains.workchain.WorkChain` there is "
"also the concept of the :ref:`process builder<working_processes_builder>`, "
"which will allow one to inspect the inputs with tab-completion and help "
"strings in the shell."
msgstr ""

#: ../docs/source/working/processes.rst:37
msgid ""
"The three most important attributes of the "
":py:class:`~aiida.engine.processes.process_spec.ProcessSpec` are:"
msgstr ""

#: ../docs/source/working/processes.rst:39
msgid "``inputs``"
msgstr ""

#: ../docs/source/working/processes.rst:40
msgid "``outputs``"
msgstr ""

#: ../docs/source/working/processes.rst:41
msgid "``exit_codes``"
msgstr ""

#: ../docs/source/working/processes.rst:43
msgid ""
"Through these attributes, one can define what inputs a process takes, what "
"outputs it will produce and what potential exit codes it can return in case "
"of errors. Just by looking at a process specification then, one will know "
"exactly *what* will happen, just not *how* it will happen. The ``inputs`` "
"and ``outputs`` attributes are *namespaces* that contain so called *ports*, "
"each one of which represents a specific input or output. The namespaces can "
"be arbitrarily nested with ports and so are called *port namespaces*. The "
"port and port namespace are implemented by the :py:class:`~plumpy.Port` and "
":py:class:`~aiida.engine.processes.ports.PortNamespace` class, respectively."
msgstr ""

#: ../docs/source/working/processes.rst:53
msgid "Ports and Port namespaces"
msgstr ""

#: ../docs/source/working/processes.rst:54
msgid ""
"To define an input for a process specification, we only need to add a port "
"to the ``inputs`` port namespace, as follows:"
msgstr ""

#: ../docs/source/working/processes.rst:61
msgid ""
"The ``input`` method, will create an instance of "
":py:class:`~aiida.engine.processes.ports.InputPort`, a sub class of the base"
" :py:class:`~plumpy.Port`, and will add it to the ``inputs`` port namespace "
"of the spec. Creating an output is just as easy, but one should use the "
":py:meth:`~plumpy.ProcessSpec.output` method instead:"
msgstr ""

#: ../docs/source/working/processes.rst:69
msgid ""
"This will cause an instance of "
":py:class:`~aiida.engine.processes.ports.OutputPort`, also a sub class of "
"the base :py:class:`~plumpy.Port`, to be created and to be added to the "
"``outputs`` specifcation attribute. Recall, that the ``inputs`` and "
"``output`` are instances of a "
":py:class:`~aiida.engine.processes.ports.PortNamespace`, which means that "
"they can contain any port. But the "
":py:class:`~aiida.engine.processes.ports.PortNamespace` itself is also a "
"port itself, so it can be added to another port namespace, allowing one to "
"create nested port namespaces. Creating a new namespace in for example the "
"inputs namespace is as simple as:"
msgstr ""

#: ../docs/source/working/processes.rst:79
msgid ""
"This will create a new ``PortNamespace`` named ``namespace`` in the "
"``inputs`` namespace of the spec. You can create arbitrarily nested "
"namespaces in one statement, by separating them with a ``.`` as shown here:"
msgstr ""

#: ../docs/source/working/processes.rst:87
msgid ""
"This command will result in the ``PortNamespace`` name ``namespace`` to be "
"nested inside another ``PortNamespace`` called ``nested``."
msgstr ""

#: ../docs/source/working/processes.rst:91
msgid ""
"Because the period is reserved to denote different nested namespaces, it "
"cannot be used in the name of terminal input and output ports as that could "
"be misinterpreted later as a port nested in a namespace."
msgstr ""

#: ../docs/source/working/processes.rst:93
msgid ""
"Graphically, this can be visualized as a nested dictionary and will look "
"like the following:"
msgstr ""

#: ../docs/source/working/processes.rst:103
msgid ""
"The ``outputs`` attribute of the ``ProcessSpec`` is also a ``PortNamespace``"
" just as the ``inputs``, with the only different that it will create "
"``OutputPort`` instead of ``InputPort`` instances. Therefore the same "
"concept of nesting through ``PortNamespaces`` applies to the outputs of a "
"``ProcessSpec``."
msgstr ""

#: ../docs/source/working/processes.rst:110
msgid "Validation and defaults"
msgstr ""

#: ../docs/source/working/processes.rst:111
msgid ""
"In the previous section, we saw that the ``ProcessSpec`` uses the "
"``PortNamespace``, ``InputPort`` and ``OutputPort`` to define the inputs and"
" outputs structure of the ``Process``. The underlying concept that allows "
"this nesting of ports is that the ``PortNamespace``, ``InputPort`` and "
"``OutputPort``, are all a subclass of :py:class:`~plumpy.ports.Port`. And as"
" different subclasses of the same class, they have more properties and "
"attributes in common, for example related to the concept of validation and "
"default values. All three have the following attributes (with the exception "
"of the ``OutputPort`` not having a ``default`` attribute):"
msgstr ""

#: ../docs/source/working/processes.rst:116
msgid "``default``"
msgstr ""

#: ../docs/source/working/processes.rst:117
msgid "``required``"
msgstr ""

#: ../docs/source/working/processes.rst:118
msgid "``valid_type``"
msgstr ""

#: ../docs/source/working/processes.rst:119
msgid "``validator``"
msgstr ""

#: ../docs/source/working/processes.rst:121
msgid ""
"These attributes can all be set upon construction of the port or after the "
"fact, as long as the spec has not been sealed, which means that they can be "
"altered without limit as long as it is within the ``define`` method of the "
"corresponding ``Process``. An example input port that explicitly sets all "
"these attributes is the following:"
msgstr ""

#: ../docs/source/working/processes.rst:128
msgid ""
"Here we define an input named ``positive_number`` that is not required, if a"
" value is not explicitly passed, the default ``Int(1)`` will be used and if "
"a value *is* passed, it should be of type ``Int`` or ``Float`` and it should"
" be valid according to the ``is_number_positive`` validator. Note that the "
"validator is nothing more than a free function which takes a single "
"argument, being the value that is to be validated and should return ``True``"
" if that value is valid or ``False`` otherwise, for example:"
msgstr ""

#: ../docs/source/working/processes.rst:136
msgid ""
"The ``valid_type`` can define a single type, or a tuple of valid types."
msgstr ""

#: ../docs/source/working/processes.rst:140
msgid ""
"Note that by default all ports are required, but specifying a default value "
"implies that the input is not required and as such specifying "
"``required=False`` is not necessary in that case. It was added to the "
"example above simply for clarity."
msgstr ""

#: ../docs/source/working/processes.rst:143
msgid ""
"The validation of input or output values with respect to the specification "
"of the corresponding port, happens at the instantiation of the process and "
"when it is finalized, respectively. If the inputs are invalid, a "
"corresponding exception will be thrown and the process instantiation will "
"fail. When the outputs fail to be validated, likewise an exception will be "
"thrown and the process state will be set to ``Excepted``."
msgstr ""

#: ../docs/source/working/processes.rst:151
msgid "Dynamic namespaces"
msgstr ""

#: ../docs/source/working/processes.rst:152
msgid ""
"In the previous section we described the various attributes related to "
"validation and claimed that all the port variants share those attributes, "
"yet we only discussed the ``InputPort`` and ``OutputPort`` explicitly. The "
"statement, however, is still correct and the ``PortNamespace`` has the same "
"attributes. You might then wonder what the meaning is of a ``valid_type`` or"
" ``default`` for a ``PortNamespace`` if all it does is contain "
"``InputPorts``, ``OutputPorts`` or other ``PortNamespaces``. The answer to "
"this question lies in the ``PortNamespace`` attribute ``dynamic``."
msgstr ""

#: ../docs/source/working/processes.rst:157
msgid ""
"Often when designing the specification of a ``Process``, we cannot know "
"exactly which inputs we want to be able to pass to the process. However, "
"with the concept of the ``InputPort`` and ``OutputPort`` one *does* need to "
"know exactly, how many value one expects at least, as they do have to be "
"defined. This is where the ``dynamic`` attribute of the ``PortNamespace`` "
"comes in. By default this is set to ``False``, but by setting it to "
"``True``, one indicates that that namespace can take a number of values that"
" is unknown at the time of definition of the specification. This now "
"explains the meaning of the ``valid_type``, ``validator`` and ``default`` "
"attributes in the context of the ``PortNamespace``. If you do mark a "
"namespace as dynamic, you may still want to limit the set of values that are"
" acceptable, which you can do by specifying the valid type and or validator."
" The values that will eventually be passed to the port namespace will then "
"be validated according to these rules exactly as a value for a regular input"
" port would be."
msgstr ""

#: ../docs/source/working/processes.rst:169
msgid "Non storable inputs"
msgstr ""

#: ../docs/source/working/processes.rst:170
msgid ""
"In principle, the only valid types for inputs and outputs should be "
"instances of a :py:class:`~aiida.orm.nodes.data.data.Data` node, or one of "
"its sub classes, as that is the only data type that can be recorded in the "
"provenance graph as an input or output of a process. However, there are "
"cases where you might want to pass an input to a process, whose provenance "
"you do not care about and therefore would want to pass a non-database "
"storable type anyway."
msgstr ""

#: ../docs/source/working/processes.rst:175
msgid ""
"AiiDA allows you to break the provenance as to be not too restrictive, but "
"always tries to urge you and guide you in a direction to keep the "
"provenance. There are legitimate reasons to break it regardless, but make "
"sure you think about the implications and whether you are really willing to "
"lose the information."
msgstr ""

#: ../docs/source/working/processes.rst:178
msgid ""
"For this situation, the ``InputPort`` has the attribute ``non_db``. By "
"default this is set to ``False``, but by setting it to ``True`` the port is "
"marked that the values that are passed to it should not be stored as a node "
"in the provenance graph and linked to the process node. This allows one to "
"pass any normal value that one would also be able to pass to a normal "
"function."
msgstr ""

#: ../docs/source/working/processes.rst:186
msgid "Automatic input serialization"
msgstr ""

#: ../docs/source/working/processes.rst:188
msgid ""
"Quite often, inputs which are given as python data types need to be cast to "
"the corresponding AiiDA type before passing them to a process. Doing this "
"manually can be cumbersome, so you can define a function when defining the "
"process specification, which does the conversion automatically. This "
"function, passed as ``serializer`` parameter to ``spec.input``, is invoked "
"if the given input is *not* already an AiiDA type."
msgstr ""

#: ../docs/source/working/processes.rst:192
msgid ""
"For inputs which are stored in the database (``non_db=False``), the "
"serialization function should return an AiiDA data type. For ``non_db`` "
"inputs, the function must be idempotent because it might be applied more "
"than once."
msgstr ""

#: ../docs/source/working/processes.rst:195
msgid ""
"The following example work chain takes three inputs ``a``, ``b``, ``c``, and"
" simply returns the given inputs. The "
":func:`aiida.orm.nodes.data.base.to_aiida_type` function is used as "
"serialization function."
msgstr ""

#: ../docs/source/working/processes.rst:200
msgid ""
"This work chain can now be called with native Python types, which will "
"automatically converted to AiiDA types by the "
":func:`aiida.orm.nodes.data.base.to_aiida_type` function. Note that the "
"module which defines the corresponding AiiDA type must be loaded for it to "
"be recognized by :func:`aiida.orm.nodes.data.base.to_aiida_type`."
msgstr ""

#: ../docs/source/working/processes.rst:205
msgid ""
"Of course, you can also use the serialization feature to perform a more "
"complex serialization of the inputs."
msgstr ""

#: ../docs/source/working/processes.rst:212
msgid ""
"Any ``Process`` most likely will have one or multiple expected failure "
"modes. To clearly communicate to the caller what went wrong, the ``Process``"
" supports setting its ``exit_status``. This ``exit_status``, a positive "
"integer, is an attribute of the process node and by convention, when it is "
"zero means the process was successful, whereas any other value indicates "
"failure. This concept of an exit code, with a positive integer as the exit "
"status, `is a common concept in programming <https://shapeshed.com/unix-"
"exit-codes/>`_ and a standard way for programs to communicate the result of "
"their execution."
msgstr ""

#: ../docs/source/working/processes.rst:217
msgid ""
"Potential exit codes for the ``Process`` can be defined through the "
"``ProcessSpec``, just like inputs and ouputs. Any exit code consists of a "
"positive non-zero integer, a string label to reference it and a more "
"detailed description of the problem that triggers the exit code. Consider "
"the following example:"
msgstr ""

#: ../docs/source/working/processes.rst:226
msgid ""
"This defines an exit code for the ``Process`` with exit status ``418`` and "
"exit message ``the work chain had an identity crisis``. The string "
"``ERROR_I_AM_A_TEAPOT`` is a label that the developer can use to reference "
"this particular exit code somewhere in the ``Process`` code itself."
msgstr ""

#: ../docs/source/working/processes.rst:229
msgid ""
"Whenever a ``Process`` exits through a particular error code, the caller "
"will be able to introspect it through the ``exit_status`` and "
"``exit_message`` attributes of the node. Assume for example that we ran a "
"``Process`` that threw the exit code described above, the caller would be "
"able to do the following:"
msgstr ""

#: ../docs/source/working/processes.rst:240
msgid ""
"This is useful, because the caller can now programmatically, based on the "
"``exit_status``, decide how to proceed. This is an infinitely more robust "
"way of communcating specific errors to a non-human then parsing text based "
"logs or reports. Additionally, The exit codes make it also very easy to "
"query for failed processes with specific error codes."
msgstr ""

#: ../docs/source/working/processes.rst:248
msgid "Process metadata"
msgstr ""

#: ../docs/source/working/processes.rst:250
msgid ""
"Each process, in addition to the normal inputs defined through its process "
"specifcation, can take optional 'metadata'. These metadata differ from "
"inputs in the sense that they are not nodes that will show up as inputs in "
"the provenance graph of the executed process. Rather, these are inputs that "
"slightly modify the behavior of the process or allow to set attributes on "
"the process node that represents its execution. The following metadata "
"inputs are available for *all* process classes:"
msgstr ""

#: ../docs/source/working/processes.rst:255
msgid "``label``: will set the label on the ``ProcessNode``"
msgstr ""

#: ../docs/source/working/processes.rst:256
msgid "``description``: will set the description on the ``ProcessNode``"
msgstr ""

#: ../docs/source/working/processes.rst:257
msgid ""
"``store_provenance``: boolean flag, by default ``True``, that when set to "
"``False``, will ensure that the execution of the process **is not** stored "
"in the provenance graph"
msgstr ""

#: ../docs/source/working/processes.rst:259
msgid ""
"Sub classes of the :py:class:`~aiida.engine.processes.process.Process` class"
" can specify further metadata inputs, refer to their specific documentation "
"for details. To pass any of these metadata options to a process, simply pass"
" them in a dictionary under the key ``metadata`` in the inputs when "
"launching the process. How a process can be launched is explained the "
"following section."
msgstr ""

#: ../docs/source/working/processes.rst:267
msgid "Launching processes"
msgstr ""

#: ../docs/source/working/processes.rst:268
msgid ""
"Any process can be launched by 'running' or 'submitting' it. Running means "
"to run the process in the current python interpreter in a blocking way, "
"whereas submitting means to send it to a daemon worker over RabbitMQ. For "
"long running processes, such as calculation jobs or complex workflows, it is"
" best advised to submit to the daemon. This has the added benefit that it "
"will directly return control to your interpreter and allow the daemon to "
"save intermediate progress during checkpoints and reload the process from "
"those if it has to restart. Running processes can be useful for trivial "
"computational tasks, such as simple calcfunctions or workfunctions, or for "
"debugging and testing purposes."
msgstr ""

#: ../docs/source/working/processes.rst:278
msgid "Process launch"
msgstr ""

#: ../docs/source/working/processes.rst:280
msgid ""
"To launch a process, one can use the free functions that can be imported "
"from the :py:mod:`aiida.engine` module. There are four different functions:"
msgstr ""

#: ../docs/source/working/processes.rst:283
msgid ":py:func:`~aiida.engine.launch.run`"
msgstr ""

#: ../docs/source/working/processes.rst:284
msgid ":py:func:`~aiida.engine.launch.run_get_node`"
msgstr ""

#: ../docs/source/working/processes.rst:285
msgid ":py:func:`~aiida.engine.launch.run_get_pk`"
msgstr ""

#: ../docs/source/working/processes.rst:286
msgid ":py:func:`~aiida.engine.launch.submit`"
msgstr ""

#: ../docs/source/working/processes.rst:288
msgid ""
"As the name suggest, the first three will 'run' the process and the latter "
"will 'submit' it to the daemon. Running means that the process will be "
"executed in the same interpreter in which it is launched, blocking the "
"interpreter, until the process is terminated. Submitting to the daemon, in "
"contrast, means that the process will be sent to the daemon for execution, "
"and the interpreter is released straight away."
msgstr ""

#: ../docs/source/working/processes.rst:292
msgid ""
"All functions have the exact same interface ``launch(process, **inputs)`` "
"where:"
msgstr ""

#: ../docs/source/working/processes.rst:294
msgid "``process`` is the process class or process function to launch"
msgstr ""

#: ../docs/source/working/processes.rst:295
msgid "``inputs`` are the inputs as keyword arguments to pass to the process."
msgstr ""

#: ../docs/source/working/processes.rst:297
msgid ""
"What inputs can be passed depends on the exact process class that is to be "
"launched. For example, when we want to run an instance of the "
":py:class:`~aiida.calculations.plugins.arithmetic.add.ArithmeticAddCalculation`"
" process, which takes two :py:class:`~aiida.orm.nodes.data.int.Int` nodes as"
" inputs under the name ``x`` and ``y`` [#f1]_, we would do the following:"
msgstr ""

#: ../docs/source/working/processes.rst:303
msgid ""
"The function will submit the calculation to the daemon and immediately "
"return control to the interpreter, returning the node that is used to "
"represent the process in the provenance graph."
msgstr ""

#: ../docs/source/working/processes.rst:306
msgid ""
"Process functions, i.e. python functions decorated with the ``calcfunction``"
" or ``workfunction`` decorators, **cannot be submitted** but can only be "
"run."
msgstr ""

#: ../docs/source/working/processes.rst:308
msgid "The ``run`` function is called identically:"
msgstr ""

#: ../docs/source/working/processes.rst:313
msgid ""
"except that it does not submit the process to the daemon, but executes it in"
" the current interpreter, blocking it until the process is terminated. The "
"return value of the ``run`` function is also **not** the node that "
"represents the executed process, but the results returned by the process, "
"which is a dictionary of the nodes that were produced as outputs. If you "
"would still like to have the process node or the pk of the process node you "
"can use one of the following variants:"
msgstr ""

#: ../docs/source/working/processes.rst:320
msgid ""
"Finally, the :py:func:`~aiida.engine.launch.run` launcher has two attributes"
" ``get_node`` and ``get_pk`` that are simple proxies to the "
":py:func:`~aiida.engine.launch.run_get_node` and "
":py:func:`~aiida.engine.launch.run_get_pk` methods. This is a handy "
"shortcut, as now you can choose to use any of the three variants with just a"
" single import:"
msgstr ""

#: ../docs/source/working/processes.rst:326
msgid ""
"If you want to launch a process class that takes a lot more inputs, often it"
" is useful to define them in a dictionary and use the python syntax ``**`` "
"that automatically expands it into keyword argument and value pairs. The "
"examples used above would look like the following:"
msgstr ""

#: ../docs/source/working/processes.rst:332
msgid ""
"Process functions, i.e. :ref:`calculation functions<concepts_calcfunctions>`"
" and :ref:`work functions<concepts_workfunctions>`, can be launched like any"
" other process as explained above, with the only exception that they "
"**cannot be submitted**. In addition to this limitation, process functions "
"have two additional methods of being launched:"
msgstr ""

#: ../docs/source/working/processes.rst:335
msgid "Simply *calling* the function"
msgstr ""

#: ../docs/source/working/processes.rst:336
msgid "Using the internal run method attributes"
msgstr ""

#: ../docs/source/working/processes.rst:338
msgid ""
"Using a calculation function to add two numbers as an example, these two "
"methods look like the following:"
msgstr ""

#: ../docs/source/working/processes.rst:347
msgid "Process builder"
msgstr ""

#: ../docs/source/working/processes.rst:348
msgid ""
"As explained in a :ref:`previous section<working_processes_spec>`, the "
"inputs for a :py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` "
"and :py:class:`~aiida.engine.processes.workchains.workchain.WorkChain` are "
"defined in the :py:meth:`~aiida.engine.processes.process.Process.define` "
"method. To know then what inputs they take, one would have to read the "
"implementation, which can be annoying if you are not a developer. To "
"simplify this process, these two process classes provide a utility called "
"the 'process builder'. The process builder is essentially a tool that helps "
"you build the inputs for the specific process class that you want to run. To"
" get a *builder* for a particular ``CalcJob`` or a ``WorkChain`` "
"implementation, all you need is the class itself, which can be loaded "
"through the :py:class:`~aiida.plugins.factories.CalculationFactory` and "
":py:class:`~aiida.plugins.factories.WorkflowFactory`, respectively. Let's "
"take the "
":py:class:`~aiida.calculations.plugins.arithmetic.add.ArithmeticAddCalculation`"
" as an example::"
msgstr ""

#: ../docs/source/working/processes.rst:358
msgid ""
"The string ``arithmetic.add`` is the entry point of the "
"``ArithmeticAddCalculation`` and passing it to the ``CalculationFactory`` "
"will return the corresponding class. Calling the ``get_builder`` method on "
"that class will return an instance of the "
":py:class:`~aiida.engine.processes.builder.ProcessBuilder` class that is "
"tailored for the ``ArithmeticAddCalculation``. The builder will help you in "
"defining the inputs that the ``ArithmeticAddCalculation`` requires and has a"
" few handy tools to simplify this process."
msgstr ""

#: ../docs/source/working/processes.rst:362
msgid ""
"To find out which inputs the builder exposes, you can simply use tab "
"completion. In an interactive python shell, by simply typing ``builder.`` "
"and hitting the tab key, a complete list of all the available inputs will be"
" shown. Each input of the builder can also show additional information about"
" what sort of input it expects. In an interactive shell, you can get this "
"information to display as follows::"
msgstr ""

#: ../docs/source/working/processes.rst:377
msgid ""
"In the ``Docstring`` you will see a ``help`` string that contains more "
"detailed information about the input port. Additionally, it will display a "
"``valid_type``, which when defined shows which data types are expected. If a"
" default value has been defined, that will also be displayed. The ``non_db``"
" attribute defines whether that particular input will be stored as a proper "
"input node in the database, if the process is submitted."
msgstr ""

#: ../docs/source/working/processes.rst:382
msgid ""
"Defining an input through the builder is as simple as assigning a value to "
"the attribute. The following example shows how to set the ``parameters`` "
"input, as well as the ``description`` and ``label`` metadata inputs::"
msgstr ""

#: ../docs/source/working/processes.rst:390
msgid ""
"If you evaluate the ``builder`` instance, simply by typing the variable name"
" and hitting enter, the current values of the builder's inputs will be "
"displayed::"
msgstr ""

#: ../docs/source/working/processes.rst:403
msgid ""
"In this example, you can see the value that we just set for the "
"``description`` and the ``label``. In addition, it will also show any "
"namespaces, as the inputs of processes support nested namespaces, such as "
"the ``metadata.options`` namespace in this example. Note that nested "
"namespaces are also all autocompleted, and you can traverse them recursively"
" with tab-completion."
msgstr ""

#: ../docs/source/working/processes.rst:407
msgid ""
"All that remains is to fill in all the required inputs and we are ready to "
"launch the process builder. When all the inputs have been defined for the "
"builder, it can be used to actually launch the ``Process``. The process can "
"be launched by passing the builder to any of the free functions "
":py:mod:`~aiida.engine.launch` module, just as you would do a normal process"
" as :ref:`described above<working_processes_launching>`, i.e.:"
msgstr ""

#: ../docs/source/working/processes.rst:414
msgid ""
"Note that the process builder is in principle designed to be used in an "
"interactive shell, as there is where the tab-completion and automatic input "
"documentation really shines. However, it is perfectly possible to use the "
"same builder in scripts where you simply use it as an input container, "
"instead of a plain python dictionary."
msgstr ""

#: ../docs/source/working/processes.rst:421
msgid "Monitoring processes"
msgstr ""

#: ../docs/source/working/processes.rst:422
msgid ""
"When you have launched a process, you may want to investigate its status, "
"progression and the results. The :ref:`verdi<verdi_overview>` command line "
"tool provides various commands to do just this."
msgstr ""

#: ../docs/source/working/processes.rst:429
msgid "verdi process list"
msgstr ""

#: ../docs/source/working/processes.rst:430
msgid ""
"Your first point of entry will be the ``verdi`` command ``verdi process "
"list``. This command will print a list of all active processes through the "
"``ProcessNode`` stored in the database that it uses to represent its "
"execution. A typical example may look something like the following:"
msgstr ""

#: ../docs/source/working/processes.rst:444
msgid ""
"The 'State' column is a concatenation of the ``process_state`` and the "
"``exit_status`` of the ``ProcessNode``. By default, the command will only "
"show active items, i.e. ``ProcessNodes`` that have not yet reached a "
"terminal state. If you want to also show the nodes in a terminal states, you"
" can use the ``-a`` flag and call ``verdi process list -a``:"
msgstr ""

#: ../docs/source/working/processes.rst:460
msgid ""
"For more information on the meaning of the 'state' column, please refer to "
"the documentation of the :ref:`process state <concepts_process_state>`. The "
"``-S`` flag let's you query for specific process states, i.e. issuing "
"``verdi process list -S created`` will return:"
msgstr ""

#: ../docs/source/working/processes.rst:472
msgid ""
"To query for a specific exit status, one can use ``verdi process list -E "
"0``:"
msgstr ""

#: ../docs/source/working/processes.rst:484
msgid ""
"This simple tool should give you a good idea of the current status of "
"running processes and the status of terminated ones. For a complete list of "
"all the available options, please refer to the documentation of :ref:`verdi "
"process<verdi_process>`."
msgstr ""

#: ../docs/source/working/processes.rst:487
msgid ""
"If you are looking for information about a specific process node, the "
"following three commands are at your disposal:"
msgstr ""

#: ../docs/source/working/processes.rst:489
msgid ""
"``verdi process report`` gives a list of the log messages attached to the "
"process"
msgstr ""

#: ../docs/source/working/processes.rst:490
msgid ""
"``verdi process status`` print the call hierarchy of the process and status "
"of all its nodes"
msgstr ""

#: ../docs/source/working/processes.rst:491
msgid ""
"``verdi process show`` print details about the status, inputs, outputs, "
"callers and callees of the process"
msgstr ""

#: ../docs/source/working/processes.rst:493
msgid ""
"In the following sections, we will explain briefly how the commands work. "
"For the purpose of example, we will show the output of the commands for a "
"completed ``PwBaseWorkChain`` from the ``aiida-quantumespresso`` plugin, "
"which simply calls a ``PwCalculation``."
msgstr ""

#: ../docs/source/working/processes.rst:500
msgid "verdi process report"
msgstr ""

#: ../docs/source/working/processes.rst:501
msgid ""
"The developer of a process can attach log messages to the node of a process "
"through the :py:meth:`~aiida.engine.processes.process.Process.report` "
"method. The ``verdi process report`` command will display all the log "
"messages in chronological order:"
msgstr ""

#: ../docs/source/working/processes.rst:511
msgid ""
"The log message will include a timestamp followed by the level of the log, "
"which is always ``REPORT``. The second block has the format ``pk|class "
"name|function name`` detailing information about, in this case, the work "
"chain itself and the step in which the message was fired. Finally, the "
"message itself is displayed. Of course how many messages are logged and how "
"useful they are is up to the process developer. In general they can be very "
"useful for a user to understand what has happened during the execution of "
"the process, however, one has to realize that each entry is stored in the "
"database, so overuse can unnecessarily bloat the database."
msgstr ""

#: ../docs/source/working/processes.rst:521
msgid "verdi process status"
msgstr ""

#: ../docs/source/working/processes.rst:522
msgid ""
"This command is most useful for ``WorkChain`` instances, but also works for "
"``CalcJobs``. One of the more powerful aspect of work chains, is that they "
"can call ``CalcJobs`` and other ``WorkChains`` to create a nested call "
"hierarchy. If you want to inspect the status of a work chain and all the "
"children that it called, ``verdi process status`` is the go-to tool. An "
"example output is the following:"
msgstr ""

#: ../docs/source/working/processes.rst:532
msgid ""
"The command prints a tree representation of the hierarchical call structure,"
" that recurses all the way down. In this example, there is just a single "
"``PwBaseWorkChain`` which called a ``PwCalculation``, which is indicated by "
"it being indented one level. In addition to the call tree, each node also "
"shows its current process state and for work chains at which step in the "
"outline it is. This tool can be very useful to inspect while a work chain is"
" running at which step in the outline it currently is, as well as the status"
" of all the children calculations it called."
msgstr ""

#: ../docs/source/working/processes.rst:541
msgid "verdi process show"
msgstr ""

#: ../docs/source/working/processes.rst:542
msgid ""
"Finally, there is a command that displays detailed information about the "
"``ProcessNode``, such as its inputs, outputs and the optional other "
"processes it called and or was called by. An example output for a "
"``PwBaseWorkChain`` would look like the following:"
msgstr ""

#: ../docs/source/working/processes.rst:586
msgid ""
"This overview should give you all the information if you want to inspect a "
"process' inputs and outputs in closer detail as it provides you their pk's."
msgstr ""

#: ../docs/source/working/processes.rst:592
msgid "Manipulating processes"
msgstr ""

#: ../docs/source/working/processes.rst:593
msgid ""
"To understand how one can manipulate running processes, one has to "
"understand the principles of the :ref:`process/node "
"distinction<concepts_process_node_distinction>` and a :ref:`process' "
"lifetime<concepts_process_lifetime>` first, so be sure to have read those "
"sections first."
msgstr ""

#: ../docs/source/working/processes.rst:599
msgid "verdi process pause/play/kill"
msgstr ""

#: ../docs/source/working/processes.rst:600
msgid ""
"The ``verdi`` command line interface provides three commands to interact "
"with 'live' processes."
msgstr ""

#: ../docs/source/working/processes.rst:602
msgid "``verdi process pause``"
msgstr ""

#: ../docs/source/working/processes.rst:603
msgid "``verdi process play``"
msgstr ""

#: ../docs/source/working/processes.rst:604
msgid "``verdi process kill``"
msgstr ""

#: ../docs/source/working/processes.rst:606
msgid ""
"The first pauses a process temporarily, the second resumes any paused "
"processes and the third one permanently kills them. The sub command names "
"might seem to tell you this already and it might look like that is all there"
" is to know, but the functionality underneath is quite complicated and "
"deserves additional explanation nonetheless."
msgstr ""

#: ../docs/source/working/processes.rst:609
msgid ""
"As the section on :ref:`the distinction between the process and the "
"node<concepts_process_node_distinction>` explained, manipulating a process "
"means interacting with the live process instance that lives in the memory of"
" the runner that is running it. By definition, these runners will always run"
" in a different system process then the one from which you want to interact,"
" because otherwise, you would *be* the runner, given that there can only be "
"a single runner in an interpreter and if it is running, the interpreter "
"would be blocked from performing any other operations. This means that in "
"order to interact with the live process, one has to interact with another "
"interpreter running in a different system process. This is once again "
"facilitated by the RabbitMQ message broker. When a runner starts to run a "
"process, it will also add listeners for incoming messages that are being "
"sent for that specific process over RabbitMQ."
msgstr ""

#: ../docs/source/working/processes.rst:617
msgid ""
"This does not just apply to daemon runners, but also normal runners. That is"
" to say that if you were to launch a process in a local runner, that "
"interpreter will be blocked, but it will still setup the listeners for that "
"process on RabbitMQ. This means that you can manipulate the process from "
"another terminal, just as if you would do with a process that is being run "
"by a daemon runner."
msgstr ""

#: ../docs/source/working/processes.rst:621
msgid ""
"In the case of 'pause', 'play' and 'kill', one is sending what is called a "
"Remote Procedure Call (RPC) over RabbitMQ. The RPC will include the process "
"identifier for which the action is intended and RabbitMQ will send it to "
"whoever registered itself to be listening for that specific process, in this"
" case the runner that is running the process. This immediately reveals a "
"potential problem: the RPC will fall on deaf ears if there is no one "
"listening, which can have multiple causes. For example, as explained in the "
"section on a :ref:`process' lifetime<concepts_process_lifetime>`, this can "
"be the case for a submitted process, where the corresponding task is still "
"queued, as all available process slots are occupied. But even if the task "
"*were* to be with a runner, it might be too busy to respond to the RPC and "
"the process appears to be unreachable. Whenever a process is unreachable for"
" an RPC, the command will return an error:"
msgstr ""

#: ../docs/source/working/processes.rst:632
msgid ""
"Depending on the cause of the process being unreachable, the problem may "
"resolve itself automatically over time and one can try again at a later "
"time, as for example in the case of the runner being too busy to respond. "
"However, to prevent this from happening, the runner has been designed to "
"have the communication happen over a separate thread and to schedule "
"callbacks for any necessary actions on the main thread, which performs all "
"the heavy lifting. This should make occurrences of the runner being too busy"
" to respond very rare. If you think the The problem is, however, there is "
"unfortunately no way of telling what the actual problem is for the process "
"not being reachable. The problem will manifest itself identically if the "
"runner just could not respond in time or if the task has accidentally been "
"lost forever due to a bug, even though these are two completely separate "
"situations."
msgstr ""

#: ../docs/source/working/processes.rst:639
msgid ""
"This brings us to another potential unintuitive aspect of interacting with "
"processes. The previous paragraph already mentioned it in passing, but when "
"a remote procedure call is sent, it first needs to be answered by the "
"responsible runner, if applicable, but it will not *directly execute* the "
"call. This is because the call will be incoming on the communcation thread "
"who is not allowed to have direct access to the process instance, but "
"instead it will schedule a callback on the main thread who can perform the "
"action. The callback will however not necessarily be executed directly, as "
"there may be other actions waiting to be performed. So when you pause, play "
"or kill a process, you are not doing so directly, but rather you are "
"*scheduling* a request to do so. If the runner has successfully received the"
" request and scheduled the callback, the command will therefore show "
"something like the following:"
msgstr ""

#: ../docs/source/working/processes.rst:650
msgid ""
"The 'scheduled' indicates that the actual killing might not necessarily have"
" happened just yet. This means that even after having called ``verdi process"
" kill`` and getting the success message, the corresponding process may still"
" be listed as active in the output of ``verdi process list``."
msgstr ""

#: ../docs/source/working/processes.rst:653
msgid ""
"By default, the ``pause``, ``play`` and ``kill`` commands will only ask for "
"the confirmation of the runner that the request has been scheduled and not "
"actually wait for the command to have been executed. This is because, as "
"explained, the actual action being performed might not be instantaneous as "
"the runner may be busy working with other processes, which would mean that "
"the command would block for a long time. If you want to send multiple "
"requests to a lot of processes in one go, this would be ineffective, as each"
" one would have to wait for the previous one to be completed. To change the "
"default and actually wait for the action to be completed and await its "
"response, you can use the ``--wait`` flag. If you know that your daemon "
"runners may be experiencing a heavy load, you can also increase the time "
"that the command waits before timing out, with the ``-t/--timeout`` flag."
msgstr ""

#: ../docs/source/working/processes.rst:661
#: ../docs/source/working/workflows.rst:569
msgid "Footnotes"
msgstr ""

#: ../docs/source/working/processes.rst:662
msgid ""
"Note that the "
":py:class:`~aiida.calculations.plugins.arithmetic.add.ArithmeticAddCalculation`"
" process class also takes a ``code`` as input, but that has been omitted for"
" the purposes of the example."
msgstr ""

#: ../docs/source/working/workflows.rst:5
msgid "Workflows"
msgstr ""

#: ../docs/source/working/workflows.rst:7
msgid ""
"A workflow in AiiDA is a process (see the :ref:`process "
"section<concepts_processes>` for details) that calls other workflows and "
"calculations and optionally *returns* data and as such can encode the logic "
"of a typical scientific workflow. Currently, there are two ways of "
"implementing a workflow process:"
msgstr ""

#: ../docs/source/working/workflows.rst:10
msgid ":ref:`work function<working_workfunctions>`"
msgstr ""

#: ../docs/source/working/workflows.rst:11
msgid ":ref:`work chain<working_workchains>`"
msgstr ""

#: ../docs/source/working/workflows.rst:13
msgid ""
"This section will provide detailed information and best practices on how to "
"implement these two workflow types."
msgstr ""

#: ../docs/source/working/workflows.rst:16
msgid ""
"This chapter assumes that the basic concept and difference between work "
"functions and work chains is known and when one should use on or the other. "
"It is therefore crucial that, before you continue, you have read and "
"understood the basic concept of :ref:`workflow "
"processes<concepts_workflows>`."
msgstr ""

#: ../docs/source/working/workflows.rst:22
msgid "Work functions"
msgstr ""

#: ../docs/source/working/workflows.rst:24
msgid ""
"The concept of work functions and the basic rules of implementation are "
"documented in detail elsewhere:"
msgstr ""

#: ../docs/source/working/workflows.rst:26
msgid ":ref:`concept of work functions<concepts_workfunctions>`"
msgstr ""

#: ../docs/source/working/workflows.rst:27
msgid ":ref:`implementation of process functions<working_process_functions>`"
msgstr ""

#: ../docs/source/working/workflows.rst:29
msgid ""
"Since work functions are a sub type of process functions, just like "
"calculation functions, their implementation rules are as good as identical. "
"However, their intended aim and heuristics are very different. Where "
":ref:`calculation functions<working_calcfunctions>` are 'calculation'-like "
"processes that *create* new data, work functions behave like 'workflow'-like"
" processes and can only *return* data. What this entails in terms of "
"intended usage and limitations for work functions is the scope of this "
"section."
msgstr ""

#: ../docs/source/working/workflows.rst:37
msgid "Returning data"
msgstr ""

#: ../docs/source/working/workflows.rst:38
msgid ""
"It has been said many times before: work functions, like all 'workflow'-like"
" processes, `return` data, but what does `return` mean exactly? In this "
"context, the term 'return' is not intended to refer to a piece of python "
"code returning a value. Instead it refers to a workflow process recording a "
"data node as one of its outputs, that *it itself did not create*, but which "
"rather was created by some other process, that was called by the workflow. "
"The calculation process was responsable for *creating* the data node and the"
" workflow is merely *returning* it as one of its outputs."
msgstr ""

#: ../docs/source/working/workflows.rst:43
msgid ""
"This is then exactly what the workfunction function does. It takes one or "
"more data nodes as inputs, calls other processes to which it passes those "
"inputs and optionally returns some or all of the outputs created by the "
"calculation processes it called. As explained in the :ref:`technical "
"section<working_process_functions>`, outputs are recorded as 'returned' "
"nodes simply by returning the nodes from the function. The engine will "
"inspect the return value from the function and attach the output nodes to "
"the node that represents the work function. To verify that the output nodes "
"are in fact not 'created', the engine will check that the nodes are stored. "
"Therefore, it is very important that you **do not store the nodes you create"
" yourself**, or the engine will raise an exception, as shown in the "
"following example:"
msgstr ""

#: ../docs/source/working/workflows.rst:53
msgid ""
"Because the returned node is a newly created node and not stored, the engine"
" will raise the following exception:"
msgstr ""

#: ../docs/source/working/workflows.rst:61
msgid ""
"Note that you could of course circumvent this check by calling ``store`` "
"yourself on the node, but that misses the point. The problem with using a "
"``workfunction`` to 'create' new data, is that the provenance is lost. To "
"illustrate this problem, let's go back to the simple problem of implementing"
" a workflow to add two integer and multiply the result with a third. The "
":ref:`correct implementation<concepts_workfunctions>` has a resulting "
"provenance graph that clearly captures the addition and the multiplication "
"as separate calculation nodes, as shown in "
":numref:`fig_work_functions_provenance_add_multiply_full`. To illustrate "
"what would happen if one does does not call calculation functions to perform"
" the computations, but instead directly perform them in the work function "
"itself and return the result, consider the following example:"
msgstr ""

#: ../docs/source/working/workflows.rst:70
#: ../docs/source/working/workflows.rst:89
msgid ""
"For the documentation skimmers: this is an explicit example on **how not to "
"use** work functions. The :ref:`correct "
"implementation<concepts_workfunctions>` calls calculation functions to "
"perform the computation"
msgstr ""

#: ../docs/source/working/workflows.rst:72
msgid ""
"Note that in this example implementation we explicitly had to call ``store``"
" on the result before returning it to avoid the exception thrown by the "
"engine. The resulting provenance would look like the following:"
msgstr ""

#: ../docs/source/working/workflows.rst:78
msgid ""
"The provenance generated by the incorrect work function implementation. Note"
" how the addition and multiplication are not explicitly represented, but are"
" implicitly hidden inside the workflow node. Moreover, the result node does "
"not have a 'create' link, because a work function cannot create new data."
msgstr ""

#: ../docs/source/working/workflows.rst:80
msgid ""
"However, looking at the generated provenance shows exactly why we shouldn't."
" This faulty implementation loses provenance as it has no explicit "
"representations of the addition and the multiplication and the `result` node"
" does not have a `create` link, which means that if only the data provenance"
" is followed, it is as if it appears out of thin air! Compare this to the "
"provenance graph of "
":numref:`fig_work_functions_provenance_add_multiply_full`, which was "
"generated by a solution that correctly uses calculation functions to perform"
" the computations. In this trivial example, one may think that this loss of "
"information is not so important, because it is implicitly captured by the "
"workflow node. But a halfway solution may make the problem more apparent, as"
" demonstrated by the following snippet where the addition is properly done "
"by calling a calculation function, but the final product is still performed "
"by the work function itself:"
msgstr ""

#: ../docs/source/working/workflows.rst:91
msgid ""
"This time around the addition is correctly performed by a calculation "
"function as it should, however, its result is multiplied by the work "
"function itself and returned. Note that once again ``store`` had to be "
"called explicitly on ``product`` to avoid the engine throwing a "
"``ValueError``, which is only for the purpose of this example **and should "
"not be done in practice**. The resulting provenance would look like the "
"following:"
msgstr ""

#: ../docs/source/working/workflows.rst:98
msgid ""
"The provenance generated by the incorrect work function implementation that "
"uses only a calculation function for the addition but performs the "
"multiplication itself. The red cross is there to indicate that there is no "
"actual connection between the intermediate sum `D4` and the final result "
"`D5`, even though the latter in reality derives from the former."
msgstr ""

#: ../docs/source/working/workflows.rst:101
msgid ""
"The generated provenance shows, that although the addition is explicitly "
"represented because the work function called the calculation function, there"
" is no connection between the sum and the final result. That is to say, "
"there is no direct link between the sum `D4` and the final result `D5`, as "
"indicated by the red cross, even though we know that the final answer was "
"based on the intermediate sum. This is a direct cause of the work function "
"'creating' new data and illustrates how, in doing so, the provenance of data"
" creation is lost."
msgstr ""

#: ../docs/source/working/workflows.rst:111
msgid ""
"To terminate the execution of a work function and mark it as failed, one "
"simply has to return an :ref:`exit code<working_processes_exit_codes>`. The "
":py:class:`~aiida.engine.processes.exit_code.ExitCode` named tuple is "
"constructed with an integer, to denote the desired exit status and an "
"optional message When such as exit code is returned, the engine will mark "
"the node of the work function as ``Finished`` and set the exit status and "
"message to the value of the tuple. Consider the following example:"
msgstr ""

#: ../docs/source/working/workflows.rst:123
msgid ""
"The execution of the work function will be immediately terminated as soon as"
" the tuple is returned, and the exit status and message will be set to "
"``418`` and ``I am a teapot``, respectively. Since no output nodes are "
"returned, the ``WorkFunctionNode`` node will have no outputs and the value "
"returned from the function call will be an empty dictionary."
msgstr ""

#: ../docs/source/working/workflows.rst:130
msgid "Work chains"
msgstr ""

#: ../docs/source/working/workflows.rst:132
msgid ""
"The :ref:`basic concept of the work chain<concepts_workchains>` has been "
"explained elsewhere. This section will provide details on how a work chain "
"can and should be implemented. A work chain is implemented by the "
":py:class:`~aiida.engine.processes.workchains.workchain.WorkChain` class. "
"Since it is a sub class of the "
":py:class:`~aiida.engine.processes.process.Process` class, it shares all its"
" properties. It will be very valuable to have read the section on working "
"with :ref:`generic processes<working_processes>` before continuing, because "
"all the concepts explained there will apply also to work chains."
msgstr ""

#: ../docs/source/working/workflows.rst:138
msgid ""
"Let's continue with the example presented in the section on the "
":ref:`concept of workchains<concepts_workchains>`, where we sum two integers"
" and multiply the result with a third. We provided a very simple "
"implementation in a code snippet, whose generated provenance graph, when "
"executed, is shown in "
":numref:`fig_work_chains_provenance_add_multiply_workchain_full`. For "
"convenience we copy the snippet here once more:"
msgstr ""

#: ../docs/source/working/workflows.rst:145
msgid ""
"We will now got through the implementation step-by-step and go into more "
"detail on the interface and best practices."
msgstr ""

#: ../docs/source/working/workflows.rst:152
msgid ""
"To implement a new work chain, simply create a new class that sub classes "
":py:class:`~aiida.engine.processes.workchains.workchain.WorkChain`. You can "
"give the new class any valid python class name, but the convention is to "
"have it end in ``WorkChain`` so that it is always immediately clear what it "
"references. After having created a new work chain class, the first and most "
"important method to implement is the "
":py:meth:`~aiida.engine.processes.process.Process.define` method. This is a "
"class method that allows the developer to define the characteristics of the "
"work chain, such as what inputs it takes, what outputs it can generate, what"
" potential exit codes it can return and the logical outline through which it"
" will accomplish all this."
msgstr ""

#: ../docs/source/working/workflows.rst:157
msgid ""
"To implement the ``define`` method, you have to start with the following "
"three lines:"
msgstr ""

#: ../docs/source/working/workflows.rst:165
msgid ""
"where you replace ``AddAndMultiplyWorkChain`` with the actual name of your "
"work chain. The ``@classmethod`` decorator indicates that this method is a "
"class method  [#f1]_ and not an instance method. The second line is the "
"method signature and specified that it will receive the class itself ``cls``"
" and ``spec`` which will be an instance of the "
":py:class:`~aiida.engine.processes.process_spec.ProcessSpec`. This is the "
"object that we will use to define our inputs, outputs and other relevant "
"properties of the work chain. The third and final line is extremely "
"important, as it will call the ``define`` method of the parent class, in "
"this case the "
":py:class:`~aiida.engine.processes.workchains.workchain.WorkChain` class."
msgstr ""

#: ../docs/source/working/workflows.rst:173
msgid ""
"If you forget to call ``super`` in the ``define`` method, your work chain "
"will fail miserably!"
msgstr ""

#: ../docs/source/working/workflows.rst:179
msgid "Inputs and outputs"
msgstr ""

#: ../docs/source/working/workflows.rst:180
msgid ""
"With those formalities out of the way, you can start defining the "
"interesting properties of the work chain through the ``spec``. In the "
"example you can see how the method "
":py:meth:`~aiida.engine.processes.process_spec.ProcessSpec.input` is used to"
" define multiple input ports, which document exactly which inputs the work "
"chain expects. Similarly, "
":py:meth:`~aiida.engine.processes.process_spec.ProcessSpec.output` is called"
" to instruct that the work chain will produce an output with the label "
"``result``. These two port creation methods support a lot more "
"functionality, such as adding help string, validation and more, all of which"
" is documented in detail in the section on :ref:`ports and port "
"namespace<working_processes_ports_portnamespaces>`."
msgstr ""

#: ../docs/source/working/workflows.rst:189
msgid "Outline"
msgstr ""

#: ../docs/source/working/workflows.rst:190
msgid ""
"The outline is what sets the work chain apart from other processes. It is a "
"way of defining the higher-level logic that encodes the workflow that the "
"work chain takes. The outline is defined in the ``define`` method through "
"the :py:meth:`~aiida.engine.processes.process_spec.ProcessSpec.outline`. It "
"takes a sequence of instructions that the work chain will execute, each of "
"which is implemented as a method of the work chain class. In the simple "
"example above, the outline consists of three simple instructions: ``add``, "
"``multiply``, ``results``. Since these are implemented as instance methods, "
"they are prefixed with ``cls.`` to indicate that they are in fact methods of"
" the work chain class. For that same reason, their implementation should "
"take ``self`` as its one and only argument, as demonstrated in the example "
"snippet."
msgstr ""

#: ../docs/source/working/workflows.rst:198
msgid ""
"The outline in this simple example is not particular interesting as it "
"consists of three simple instructions that will be executed sequentially. "
"However, the outline also supports various logical constructs, such as "
"while-loops, conditionals and return statements. As usual, the best way to "
"illustrate these constructs is by example. The currently available logical "
"constructs for the work chain outline are:"
msgstr ""

#: ../docs/source/working/workflows.rst:203
msgid "``if``, ``elif``, ``else``"
msgstr ""

#: ../docs/source/working/workflows.rst:204
msgid "``while``"
msgstr ""

#: ../docs/source/working/workflows.rst:205
msgid "``return``"
msgstr ""

#: ../docs/source/working/workflows.rst:207
msgid ""
"To distinguish these constructs from the python builtins, they are suffixed "
"with an underscore, like so ``while_``. To use these in your work chain "
"design, you will have to import them:"
msgstr ""

#: ../docs/source/working/workflows.rst:214
msgid ""
"The following example shows how to use these logical constructs to define "
"the outline of a work chain:"
msgstr ""

#: ../docs/source/working/workflows.rst:234
msgid ""
"This is an implementation (and an extremely contrived one at that) of the "
"well known FizzBuzz [#f2]_ problem. The idea is that the program is supposed"
" to print in sequence the numbers from zero to some limit, except when the "
"number is a multiple of three ``Fizz`` is printed, for a multiple of five "
"``Buzz`` and when it is a multiple of both, the program should print "
"``FizzBuzz``. Note how the syntax looks very much like that of normal python"
" syntax. The methods that are used in the conditionals (between the "
"parentheses of the ``while_`` and ``if_`` constructs) for example should "
"return a boolean; ``True`` when the condition holds and ``False`` otherwise."
" The actual implementation of the outline steps themselves is now trivial:"
msgstr ""

#: ../docs/source/working/workflows.rst:260
msgid ""
"The intention of this example is to show that with a well designed outline, "
"a user only has to look at the outline to have a good idea *what* the work "
"chain does and *how* it does it. One should not have to look at the "
"implementation of the outline steps as all the important information is "
"captured by the outline itself. Since the goal of a work chain should be to "
"execute a very well defined task, it is the goal of the outline to capture "
"the required logic to achieve that goal, in a clear and short yet not overly"
" succint manner. The outline supports various logical flow constructs, such "
"as conditionals and while loops, so where possible this logic should be "
"expressed in the outline and not in the body of the outline functions. "
"However, one can also go overboard and put too finely grained logical blocks"
" into the outline, causing it to become bulky and difficult to understand."
msgstr ""

#: ../docs/source/working/workflows.rst:266
msgid ""
"A good rule of thumb in designing the outline is the following: before you "
"start designing a work chain, define very clearly the task that it should "
"carry out. Once the goal is clear, draw a schematic block diagram of the "
"necessary steps and logical decisions that connect them, in order to "
"accomplish that goal. Converting the resulting flow diagram in a one-to-one "
"fashion into an outline, often results in very reasonable outline designs."
msgstr ""

#: ../docs/source/working/workflows.rst:275
msgid ""
"There is one more property of a work chain that is specified through its "
"process specification, in addition to its inputs, outputs and outline. Any "
"work chain may have one to multiple failure modes, which are modeled by "
":ref:`exit codes<working_processes_exit_codes>`. A work chain can be stopped"
" at any time, simply by returning an exit code from an outline method. To "
"retrieve an exit code that is defined on the spec, one can use the "
":py:meth:`~aiida.engine.processes.process.Process.exit_codes` property. This"
" returns an attribute dictionary where the exit code labels map to their "
"corresponding exit code. For example, with the following process spec:"
msgstr ""

#: ../docs/source/working/workflows.rst:287
msgid ""
"To see how exit codes can be used to terminate the execution of work chains "
"gracefully, refer to the section "
":ref:`working_workchains_aborting_and_exit_codes`."
msgstr ""

#: ../docs/source/working/workflows.rst:293
msgid "Launching work chains"
msgstr ""

#: ../docs/source/working/workflows.rst:295
msgid ""
"The rules for launching work chains are the same as those for any other "
"process, which are detailed in :ref:`this "
"section<working_processes_launching>`. On top of those basic rules, there is"
" one peculiarity in the case of work chains when submitting to the daemon. "
"When you submit a ``WorkChain`` over the daemon, or any other process for "
"that matter, you need to make sure that the daemon can find the class when "
"it needs to load it. Registering your class through the plugin system with a"
" designated entry point is one way to make sure that the daemon will be able"
" to find it. If, however, you simply have a test class and do not want to go"
" through the effort of creating an entry point for it, you should make sure "
"that the module where you define the class is in the python path. "
"Additionally, make sure that the definition of the work chain **is not in "
"the same file from which you submit it**, or the engine won't be able to "
"load it."
msgstr ""

#: ../docs/source/working/workflows.rst:306
msgid "Context"
msgstr ""

#: ../docs/source/working/workflows.rst:307
msgid ""
"In the simplest work chain example presented in the introductory section, we"
" already saw how the context can be used to persist information during the "
"execution of a work chain and pass it between outline steps. The context is "
"essentially a data container, very similar to a dictionary that can hold all"
" sorts of data. The engine will ensure that its contents are saved and "
"persisted in between steps and when the daemon shuts down or restarts. A "
"trivial example of this would be the following:"
msgstr ""

#: ../docs/source/working/workflows.rst:320
msgid ""
"In the ``step_one`` outline step we store the string ``'store me in the "
"context'`` in the context, which can be addressed as ``self.ctx``, under the"
" key ``some_variable``. Note that for the key you can use anything that "
"would be a valid key for a normal python dictionary. In the second outline "
"step ``step_two``, we can verify that the string was successfully persisted,"
" by checking the value stored in the context ``self.ctx.some_variable``."
msgstr ""

#: ../docs/source/working/workflows.rst:326
msgid "Any data that is stored in the context **has** to be serializable."
msgstr ""

#: ../docs/source/working/workflows.rst:328
msgid ""
"This was just a simple example to introduce the concept of the context, "
"however, it really is one of the more important parts of the work chain. The"
" context really becomes crucial when you want to submit a calculation or "
"another work chain from within the work chain. How this is accomplished, we "
"will show in the next section."
msgstr ""

#: ../docs/source/working/workflows.rst:335
msgid "Submitting sub processes"
msgstr ""

#: ../docs/source/working/workflows.rst:336
msgid ""
"One of the main tasks of a ``WorkChain`` will be to launch other processes, "
"such as a ``CalcJob`` or another ``WorkChain``. How to submit processes was "
"explained in :ref:`another section<working_processes_launch>` and is "
"accomplished by using the :py:func:`~aiida.engine.launch.submit` launch "
"function. However, when submitting a sub process from within a work chain, "
"**this should not be used**. Instead, the "
":py:class:`~aiida.engine.processes.process.Process` class provides its own "
":py:meth:`~aiida.engine.processes.process.Process.submit` method. If you do,"
" you will be greeted with the exception:"
msgstr ""

#: ../docs/source/working/workflows.rst:346
msgid ""
"The only change you have to make is to replace the top-level ``submit`` "
"method with the built-in method of the process class:"
msgstr ""

#: ../docs/source/working/workflows.rst:354
msgid ""
"The ``self.submit`` method has the exact same interface as the global "
"``aiida.engine.launch.submit`` launcher. When the ``submit`` method is "
"called, the process is created and submitted to the daemon, but at that "
"point it is not yet done. So the value that is returned by the ``submit`` "
"call is not the result of the submitted process, but rather it is the "
"process node that represents the execution of the process in the provenance "
"graph and acts as a *future*. We somehow need to tell the work chain that it"
" should wait for the sub process to be finished, and the future to resolve, "
"before it continues. To do so, however, control has to be returned to the "
"engine, which can then, when the process is completed, call the next step in"
" the outline, where we can analyse the results. The snippet above already "
"revealed that this is accomplished by returning an instance of the "
"``ToContext`` class."
msgstr ""

#: ../docs/source/working/workflows.rst:362
msgid "To context"
msgstr ""

#: ../docs/source/working/workflows.rst:363
msgid ""
"In order to store the future of the submitted process, we can store it in "
"the context with a special construct that will tell the engine that it "
"should wait for that process to finish before continuing the work chain. To "
"illustrate how this works, consider the following minimal example:"
msgstr ""

#: ../docs/source/working/workflows.rst:369
msgid ""
"As explained in the previous section, calling ``self.submit`` for a given "
"process that you want to submit, will return a future. To add this future to"
" the context, we can not access the context directly as explained in the "
":ref:`context section<working_workchains_context>`, but rather we need to "
"use the class "
":py:class:`~aiida.engine.processes.workchains.context.ToContext`. This class"
" has to be imported from the ``aiida.engine`` module. To add the future to "
"the context, simply construct an instance of ``ToContext``, passing the "
"future as a keyword argument, and returning it from the outline step. The "
"keyword used, ``workchain`` in this example, will be the key used under "
"which to store the node in the context once its execution has terminated. "
"Returning an instance of ``ToContext`` signals to the engine that it has to "
"wait for the futures contained within it to finish execution, store their "
"nodes in the context under the specified keys and then continue to the next "
"step in the outline. In this example, that is the ``inspect_workchain`` "
"method. At this point we are sure that the process, a work chain in this "
"case, has terminated its execution, although not necessarily successful, and"
" we can continue the logic of the work chain."
msgstr ""

#: ../docs/source/working/workflows.rst:378
msgid ""
"Sometimes one wants to launch not just one, but multiple processes at the "
"same time that can run in parallel. With the mechanism described above, this"
" will not be possible since after submitting a single process and returning "
"the ``ToContext`` instance, the work chain has to wait for the process to be"
" finished before it can continue. To solve this problem, there is another "
"way to add futures to the context:"
msgstr ""

#: ../docs/source/working/workflows.rst:385
msgid ""
"Here we submit three work chains in a for loop in a single outline step, but"
" instead of returning an instance of ``ToContext``, we call the "
":meth:`~aiida.engine.processes.workchains.workchain.WorkChain.to_context` "
"method. This method has exactly the same syntax as the ``ToContext`` class, "
"except it is not necessary to return its value, so we can call it multiple "
"times in one outline step. Under the hood the functionality is also the same"
" as the ``ToContext`` class. At the end of the ``submit_workchains`` outline"
" step, the engine will find the futures that were added by calling "
"``to_context`` and will wait for all of them to be finished. The good thing "
"here is that these three sub work chains can be run in parallel and once all"
" of them are done, the parent work chain will go to the next step, which is "
"``inspect_workchains``. There we can find the nodes of the work chains in "
"the context under the key that was used as the keyword argument in the "
"``to_context`` call in the previous step."
msgstr ""

#: ../docs/source/working/workflows.rst:392
msgid ""
"Since we do not want the subsequent calls of ``to_context`` to override the "
"previous future, we had to create unique keys to store them under. In this "
"example, we chose to use the index of the for-loop. The name carries no "
"meaning and is just required to guarantee unique key names. This pattern "
"will occur often where you will want to launch multiple work chains or "
"calculations in parallel and will have to come up with unique names. In "
"essence, however, you are really just creating a list and it would be better"
" to be able to create a list in the context and simply append the future to "
"that list as you submit them. How this can be achieved is explained in the "
"next section."
msgstr ""

#: ../docs/source/working/workflows.rst:400
msgid "Appending"
msgstr ""

#: ../docs/source/working/workflows.rst:401
msgid ""
"When you want to add a future of a submitted sub process to the context, but"
" append it to a list rather than assign it to a key, you can use the "
":func:`~aiida.engine.processes.workchains.context.append_` function. "
"Consider the example from the previous section, but now we will use the "
"``append_`` function instead:"
msgstr ""

#: ../docs/source/working/workflows.rst:407
msgid ""
"Notice that in the ``submit_workchains`` step we no longer have to generate "
"a unique key based on the index but we simply wrap the future in the "
"``append_`` function and assign it to the generic key ``workchains``. The "
"engine will see the ``append_`` function and instead of assigning the node "
"corresponding to the future to the key ``workchains``, it will append it to "
"the list stored under that key. If the list did not yet exist, it will "
"automatically be created. The ``self.ctx.workchains`` now contains a list "
"with the nodes of the completed work chains and so in the "
"``inspect_workchains`` step we can simply iterate over it to access all of "
"them."
msgstr ""

#: ../docs/source/working/workflows.rst:414
msgid ""
"The process nodes of the completed processes will **not necessarily** be "
"added to the list in the context in the same order as the ``to_context`` "
"calls. This is because the futures may not necessarily be resolved in the "
"same order as they were submitted. Therefore it is dangerous to depend on "
"the order when using the append method."
msgstr ""

#: ../docs/source/working/workflows.rst:418
msgid ""
"Note that the use of ``append_`` is not just limited to the ``to_context`` "
"method. You can also use it in exactly the same way with ``ToContext`` to "
"append a process to a list in the context in multiple outline steps."
msgstr ""

#: ../docs/source/working/workflows.rst:424
msgid "Reporting"
msgstr ""

#: ../docs/source/working/workflows.rst:425
msgid ""
"During the execution of a ``WorkChain``, we may want to keep the user "
"abreast of its progress and what is happening. For this purpose, the "
"``WorkChain`` implements the "
":py:meth:`~aiida.engine.processes.process.Process.report` method, which "
"functions as a logger of sorts. It takes a single argument, a string, that "
"is the message that needs to be reported:"
msgstr ""

#: ../docs/source/working/workflows.rst:434
msgid ""
"This will send that message to the internal logger of python, which will "
"cause it to be picked up by the default AiiDA logger, but it will also "
"trigger the database log handler, which will store the message in the "
"database and link it to the node of the work chain. This allows the ``verdi "
"process report`` command to retrieve all those messages that were fired "
"using the ``report`` method for a specific process. Note that the report "
"method, in addition to the pk of the work chain, will also automatically "
"record the name of the work chain and the name of the outline step in which "
"the report message was fired. This information will show up in the output of"
" ``verdi process report``, so you never have to explicitly reference the "
"work chain name, outline step name or date and time in the message itself."
msgstr ""

#: ../docs/source/working/workflows.rst:439
msgid ""
"It is important to note that the report system is a form of logging and as "
"such has been designed to be read by humans only. That is to say, the report"
" system is not designed to pass information programmatically by parsing the "
"log messages."
msgstr ""

#: ../docs/source/working/workflows.rst:445
msgid "Aborting and exit codes"
msgstr ""

#: ../docs/source/working/workflows.rst:446
msgid ""
"At the end of every outline step, the return value will be inspected by the "
"engine. If a non-zero integer value is detected, the engine will interpret "
"this as an exit code and will stop the execution of the work chain, while "
"setting its process state to ``Finished``. In addition, the integer return "
"value will be set as the ``exit_status`` of the work chain, which combined "
"with the ``Finished`` process state will denote that the worchain is "
"considered to be ``Failed``, as explained in the section on the "
":ref:`process state <concepts_process_state>`. This is useful because it "
"allows a workflow designer to easily exit from a work chain and use the "
"return value to communicate programmatically the reason for the work chain "
"stopping."
msgstr ""

#: ../docs/source/working/workflows.rst:451
msgid ""
"We assume that you have read the `section on how to define exit code "
"<exit_codes>`_ through the process specification of the work chain. Consider"
" the following example work chain that defines such an exit code:"
msgstr ""

#: ../docs/source/working/workflows.rst:458
msgid ""
"Now imagine that in the outline, we launch a calculation and in the next "
"step check whether it finished successfully. In the event that the "
"calculation did not finish successfully, the following snippet shows how you"
" can retrieve the corresponding exit code and abort the ``WorkChain`` by "
"returning it:"
msgstr ""

#: ../docs/source/working/workflows.rst:475
msgid ""
"In the ``inspect_calculation`` outline, we retrieve the calculation that was"
" submitted and added to the context in the previous step and check if it "
"finished successfully through the property ``is_finished_ok``. If this "
"returns ``False``, in this example we simply fire a report message and "
"return the exit code corresponding to the label "
"``ERROR_CALCULATION_FAILED``. Note that the specific exit code can be "
"retrieved through the ``WorkChain`` property ``exit_codes``. This will "
"return a collection of exit codes that have been defined for that "
"``WorkChain`` and any specific exit code can then be retrieved by accessing "
"it as an attribute. Returning this exit code, which will be an instance of "
"the :py:class:`~aiida.engine.processes.exit_code.ExitCode` named tuple, will"
" cause the work chain to be aborted and the ``exit_status`` and "
"``exit_message`` to be set on the node, which were defined in the spec."
msgstr ""

#: ../docs/source/working/workflows.rst:483
msgid ""
"The notation ``self.exit_codes.ERROR_CALCULATION_FAILED`` is just syntactic "
"sugar to retrieve the ``ExitCode`` tuple that was defined in the spec with "
"that error label. Constructing your own ``ExitCode`` directly and returning "
"that from the outline step will have exactly the same effect in terms of "
"aborting the work chain execution and setting the exit status and message. "
"However, it is strongly advised to define the exit code through the spec and"
" retrieve it through the ``self.exit_codes`` collection, as that makes it "
"easily retrievable through the spec by the caller of the work chain."
msgstr ""

#: ../docs/source/working/workflows.rst:487
msgid ""
"The best part about this method of aborting a work chains execution, is that"
" the exit status can now be used programmatically, by for example a parent "
"work chain. Imagine that a parent work chain submitted this work chain. "
"After it has terminated its execution, the parent work chain will want to "
"know what happened to the child work chain. As already noted in the "
":ref:`report<working_workchains_reporting>` section, the report messages of "
"the work chain should not be used. The exit status, however, is a perfect "
"way. The parent work chain can easily request the exit status of the child "
"work chain through the ``exit_status`` property, and based on its value "
"determine how to proceed."
msgstr ""

#: ../docs/source/working/workflows.rst:496
msgid "Modular workflow design"
msgstr ""

#: ../docs/source/working/workflows.rst:497
msgid ""
"When creating complex workflows, it is a good idea to split them up into "
"smaller, modular parts. At the lowest level, each workflow should perform "
"exactly one task. These workflows can then be wrapped together by a "
"\"parent\" workflow to create a larger logical unit."
msgstr ""

#: ../docs/source/working/workflows.rst:501
msgid ""
"In order to make this approach manageable, it needs to be as simple as "
"possible to glue together multiple workflows in a larger parent workflow. "
"One of the tools that AiiDA provides to simplify this is the ability to "
"*expose* the ports of another work chain."
msgstr ""

#: ../docs/source/working/workflows.rst:507
msgid "Exposing inputs and outputs"
msgstr ""

#: ../docs/source/working/workflows.rst:508
msgid ""
"Consider the following example work chain, which simply takes a few inputs "
"and returns them again as outputs:"
msgstr ""

#: ../docs/source/working/workflows.rst:513
msgid ""
"As a first example, we will implement a thin wrapper workflow, which simply "
"forwards its inputs to ``ChildWorkChain``, and forwards the outputs of the "
"child to its outputs:"
msgstr ""

#: ../docs/source/working/workflows.rst:518
msgid ""
"In the ``define`` method of this simple parent work chain, we use the "
":meth:`~plumpy.process_spec.ProcessSpec.expose_inputs` and "
":meth:`~plumpy.process_spec.ProcessSpec.expose_outputs`. This creates the "
"corresponding input and output ports in the parent work chain. Additionally,"
" AiiDA remembers which inputs and outputs were exposed from that particular "
"work chain class. This is used when calling the child in the ``run_child`` "
"method. The :meth:`~aiida.engine.processes.process.Process.exposed_inputs` "
"method returns a dictionary of inputs that the parent received which were "
"exposed from the child, and so it can be used to pass these on to the child."
" Finally, in the ``finalize`` method, we use "
":meth:`~aiida.engine.processes.process.Process.exposed_outputs` to retrieve "
"the outputs of the child which were exposed to the parent. Using "
":meth:`~aiida.engine.processes.process.Process.out_many`, these outputs are "
"added to the outputs of the parent work chain. This work chain can now be "
"run in exactly the same way as the child itself:"
msgstr ""

#: ../docs/source/working/workflows.rst:530
msgid ""
"Next, we will see how a more complex parent work chain can be created by "
"using the additional features of the expose functionality. The following "
"work chain launches two children. These children share the input ``a``, but "
"have different ``b`` and ``c``. The output ``e`` will be taken only from the"
" first child, whereas ``d`` and ``f`` are taken from both children. In order"
" to avoid name conflicts, we need to create a *namespace* for each of the "
"two children, where the inputs and outputs which are not shared are stored. "
"Our goal is that the workflow can be called as follows:"
msgstr ""

#: ../docs/source/working/workflows.rst:540
msgid ""
"This is achieved by the following workflow. In the next section, we will "
"explain each of the steps."
msgstr ""

#: ../docs/source/working/workflows.rst:546
msgid ""
"First of all, we want to expose the ``a`` input and the ``e`` output at the "
"top-level. For this, we again use "
":meth:`~plumpy.process_spec.ProcessSpec.expose_inputs` and "
":meth:`~plumpy.process_spec.ProcessSpec.expose_outputs`, but with the "
"optional keyword ``include``. This specifies a list of keys, and only inputs"
" or outputs which are in that list will be exposed. So by passing "
"``include=['a']`` to :meth:`~plumpy.process_spec.ProcessSpec.expose_inputs`,"
" only the input ``a`` is exposed."
msgstr ""

#: ../docs/source/working/workflows.rst:551
msgid ""
"Additionally, we want to expose the inputs ``b`` and ``c`` (outputs ``d`` "
"and ``f``), but in a namespace specific for each of the two children. For "
"this purpose, we pass the ``namespace`` parameter to the expose functions. "
"However, since we now shouldn't expose ``a`` (``e``) again, we use the "
"``exclude`` keyword, which specifies a list of keys that will not be "
"exposed."
msgstr ""

#: ../docs/source/working/workflows.rst:555
msgid ""
"When calling the children, we again use the "
":meth:`~aiida.engine.processes.process.Process.exposed_inputs` method to "
"forward the exposed inputs. Since the inputs ``b`` and ``c`` are now in a "
"specific namespace, we need to pass this namespace as an additional "
"parameter. By default, "
":meth:`~aiida.engine.processes.process.Process.exposed_inputs` will search "
"through all the parent namespaces of the given namespace to search for "
"input, as shown in the call for ``child_1``. If the same input key exists in"
" multiple namespaces, the input in the lowest namespace takes precedence. "
"It's also possible to disable this behavior, and instead search only in the "
"explicit namespace that was passed. This is done by setting "
"``agglomerate=False``, as shown in the call to ``child_2``. Of course, we "
"then need to explicitly pass the input ``a``."
msgstr ""

#: ../docs/source/working/workflows.rst:563
msgid ""
"Finally, we use "
":meth:`~aiida.engine.processes.process.Process.exposed_outputs` and "
":meth:`~aiida.engine.processes.process.Process.out_many` to forward the "
"outputs of the children to the outputs of the parent. Again, the "
"``namespace`` and ``agglomerate`` options can be used to select which "
"outputs are returned by the "
":meth:`~aiida.engine.processes.process.Process.exposed_outputs` method."
msgstr ""

#: ../docs/source/working/workflows.rst:570
msgid "https://docs.python.org/3.5/library/functions.html#classmethod"
msgstr "https://docs.python.org/3.5/library/functions.html#classmethod"

#: ../docs/source/working/workflows.rst:571
msgid "https://en.wikipedia.org/wiki/Fizz_buzz"
msgstr "https://en.wikipedia.org/wiki/Fizz_buzz"

# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2019, ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE (Theory and Simulation of Materials (THEOS) and National Centre for Computational Design and Discovery of Novel Materials (NCCR MARVEL)), Switzerland and ROBERT BOSCH LLC, USA. All rights reserved
# This file is distributed under the same license as the AiiDA package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
# 
# Translators:
# Jason.Eu <morty.yu@yahoo.com>, 2019
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: AiiDA 1.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2019-10-31 22:43+0000\n"
"PO-Revision-Date: 2019-05-17 20:01+0000\n"
"Last-Translator: Jason.Eu <morty.yu@yahoo.com>, 2019\n"
"Language-Team: Chinese (China) (https://www.transifex.com/aiidateam/teams/98967/zh_CN/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: zh_CN\n"
"Plural-Forms: nplurals=1; plural=0;\n"

#: ../docs/source/working/calculations.rst:5
#: ../docs/source/working/processes.rst:5
#: ../docs/source/working/workflows.rst:5
msgid "Application"
msgstr ""

#: ../docs/source/working/calculations.rst:7
msgid ""
"A calculation is a process (see the :ref:`process "
"section<concepts_processes>` for details) that *creates* new data. "
"Currently, there are two ways of implementing a calculation process:"
msgstr ""
"算例是能够 *创建* 新的数据的一个例程(详情参看 :ref:`process section<concepts_processes>`  )。 "
"当前，有两种实现算例例程的方法 :"

#: ../docs/source/working/calculations.rst:10
msgid ":ref:`calculation function<working_calcfunctions>`"
msgstr ":ref:`算例函数<working_calcfunctions>`"

#: ../docs/source/working/calculations.rst:11
msgid ":ref:`calculation job<working_calcjobs>`"
msgstr ":ref:`算例任务<working_calcjobs>`"

#: ../docs/source/working/calculations.rst:13
msgid ""
"This section will provide detailed information and best practices on how to "
"implement these two calculation types."
msgstr "该章节关于如何实现这两种算例的详细信息和最佳案例。"

#: ../docs/source/working/calculations.rst:16
msgid ""
"This chapter assumes that the basic concept and difference between "
"calculation functions and calculation jobs is known and when one should use "
"on or the other. It is therefore crucial that, before you continue, you have"
" read and understood the basic concept of :ref:`calculation "
"processes<concepts_calculations>`."
msgstr ""
"该章认为读者已经对基础概念和算例函数与算例任务之间的区别和使用场景有所了解。因此在继续下面的阅读前，你需要阅读和理解 "
":ref:`算例例程<concepts_calculations>` 的基础概念."

#: ../docs/source/working/calculations.rst:22
msgid "Calculation functions"
msgstr "算例函数(Calculation functions)"

#: ../docs/source/working/calculations.rst:24
msgid ""
"The section on the :ref:`concept of calculation "
"functions<concepts_calcfunctions>` already addressed their aim: automatic "
"recording of their execution with their inputs and outputs in the provenance"
" graph. The :ref:`section on process functions<working_process_functions>` "
"subsequently detailed the rules that apply when implementing them, all of "
"which to calculation functions, which are a sub type, just like work "
"functions. However, there are some differences given that calculation "
"functions are 'calculation'-like processes and work function behave like "
"'workflow'-like processes. What this entails in terms of intended usage and "
"limitations for calculation functions is the scope of this section."
msgstr ""
"章节 :ref:`算例函数及其概念<concepts_calcfunctions>` 已经描述了其使用目的: "
"自动在可验证性图中记录算例的运行和运行所需的输入和产生的输出。之后的 The "
":ref:`例程函数章节<working_process_functions>` "
"详细描述了实现例程函数时候的规则和细节，如同工作函数，规则和实现同时适用于例程函数这一例程函数的子类。但是，算例函数这种 “算例型” "
"的例程和工作函数这种“工作型” 的例程之间还是有些区别的。 就算例函数的预期使用和限制，还在本节描述。"

#: ../docs/source/working/calculations.rst:30
msgid "Creating data"
msgstr "创建数据"

#: ../docs/source/working/calculations.rst:31
msgid ""
"It has been said many times before: calculation functions, like all "
"'calculation'-like processes, `create` data, but what does `create` mean "
"exactly? In this context, the term 'create' is not intended to refer to the "
"simple creation of a new data node in the graph, in an interactive shell or "
"a script for example. But rather it indicates the creation of a new piece of"
" data from some other data through a computation implemented by a process. "
"This is then exactly what the calculation function does. It takes one or "
"more data nodes as inputs and returns one or more data nodes as outputs, "
"whose content is based on those inputs. As explained in the :ref:`technical "
"section<working_process_functions>`, outputs are created simply by returning"
" the nodes from the function. The engine will inspect the return value from "
"the function and attach the output nodes to the calculation node that "
"represents the calculation function. To verify that the output nodes are in "
"fact 'created', the engine will check that the nodes are not stored. "
"Therefore, it is very important that you **do not store the nodes you create"
" yourself**, or the engine will raise an exception, as shown in the "
"following example:"
msgstr ""
"前面曾多次提到: 算例函数，如同所有的“算例性”例程一样，能够  “创建” 数据，但所谓的“创建”具体指什么？ "
"在此处的上下文中，术语“创建”并不简单的描述通过交互式shell或脚本在可验证性图中创建数据节点。 "
"而是指代了通过例程实现的计算中从一些数据产生新的数据的过程。这就是算例函数所实际产生的效果。它以一个或多个数据节点作为输入，并返回以这些输入作为操作对象的一个或多个数据节点作为输出。正如小节"
" :ref:`技术细节<working_process_functions>` "
"所解释的，输出是通过从函数中返回数据节点的方式简单创建的。后端引擎会从函数中检查返回值并将返回节点连接在表示算例函数的算例节点上。为验证输出节点确实是“创建”的，AiiDA引擎会检查这个节点是没有被储存过的。因此，**不要手动储存你所创建的节点**"
" 是很重要的，否则引擎会产生一个如下异常 :"

#: ../docs/source/working/calculations.rst:44
msgid ""
"Because the returned node is already stored, the engine will raise the "
"following exception:"
msgstr "因为返回的节点已经储存，AiiDA引擎会产生一个如下异常 :"

#: ../docs/source/working/calculations.rst:52
msgid ""
"The reason for this strictness is that a node that was stored after being "
"created in the function body, is indistinguishable from a node that was "
"already stored and had simply been loaded in the function body and returned,"
" e.g.:"
msgstr "该严格限制的原因是，节点需要在被创建后才会被储存，这有别与在函数体中或函数的返回中载入一个已经储存的节点，如 ::"

#: ../docs/source/working/calculations.rst:57
msgid ""
"The loaded node would also have gotten a `create` link from the calculation "
"function, even though it was not really created by it at all. It is exactly "
"to prevent this ambiguity that calculation functions require all returned "
"output nodes to be *unstored*."
msgstr ""
"载入的节点会从算例函数中产生一个 `create` 连接，即便该节点不是由该函数创建的。正是为了避免这种模糊性，要求算例函数返回的所有输出节点都是 "
"*unstored* 的。"

#: ../docs/source/working/calculations.rst:60
msgid ""
"Note that work functions have exactly the opposite required and all the "
"outputs that it returns **have to be stored**, because as a 'workflow'-like "
"process, it *cannot* create new data. For more details refer to the "
":ref:`work function section<working_workfunctions>`."
msgstr ""
"注意到工作流函数有完全相反的要求，即所有函数返回的输出必须 *已经被储存* ，因为如一个“工作流”型的例程，它是 *不能* 创建新的数据的。详情请参考 "
":ref:`工作流函数小节<working_workfunctions>` 。"

#: ../docs/source/working/calculations.rst:66
msgid "Calculation jobs"
msgstr "算例任务(Calculation jobs)"

#: ../docs/source/working/calculations.rst:68
msgid ""
"To explain how a calculation job can be implemented, we will continue with "
"the example presented in the section on the :ref:`concept of the calculation"
" job<concepts_calcjobs>`. There we described a code that adds two integers, "
"implemented as a simple bash script, and how the "
":py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` class can be "
"used to run this code through AiiDA. Since it is a sub class of the "
":py:class:`~aiida.engine.processes.process.Process` class, it shares all its"
" properties. It will be very valuable to have read the section on working "
"with :ref:`generic processes<working_processes>` before continuing, because "
"all the concepts explained there will apply also to calculation jobs."
msgstr ""
"为描述如何实现算例任务，我们继续章节 :ref:`算例任务的概念<concepts_calcjobs>` "
"中展示的例子。例子中我们描述了对两个整数求和并通过简单的bash脚本实现的代码，以及 "
":py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` "
"类如何被用于在AiiDA中运行这段代码。因为该类是 "
":py:class:`~aiida.engine.processes.process.Process` "
"类的子类，则拥有它的全部性质。因此在继续之前阅读章节 :ref:`泛型例程<working_processes>` "
"也是很有用的。因为那里所描述的所有特性在此处算例任务中同样适用。"

#: ../docs/source/working/calculations.rst:77
#: ../docs/source/working/workflows.rst:151
msgid "Define"
msgstr "定义"

#: ../docs/source/working/calculations.rst:78
msgid ""
"To implement a calculation job, one simply sub classes the "
":py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` process class "
"and implements the "
":py:meth:`~aiida.engine.processes.calcjobs.calcjob.CalcJob.define` method. "
"You can pick any name that is a valid python class name. The most important "
"method of the ``CalcJob`` class, is the ``define`` class method. Here you "
"define, what inputs it takes and what outputs it will generate."
msgstr ""
"要实现一个算例任务，使用者只需要继承 "
":py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` 例程类并实现 "
":py:meth:`~aiida.engine.processes.calcjobs.calcjob.CalcJob.define` "
"方法。你可以使用认可python许可的类名。``CalcJob`` 中最重要的方法是 ``define`` "
"类方法。在这个方法中，你定义了输入和算例运行产生的输出。"

#: ../docs/source/working/calculations.rst:86
msgid ""
"As the snippet above demonstrates, the class method takes two arguments:"
msgstr "如上面代码片段所展示的，该类方法接受两个参数 :"

#: ../docs/source/working/calculations.rst:88
msgid ""
"``cls`` this is the reference of the class itself and is mandatory for any "
"class method"
msgstr "``cls`` 是指向该类自身的可以访问类的所有类方法的变量"

#: ../docs/source/working/calculations.rst:89
msgid "``spec`` which is the 'specification'"
msgstr "``spec`` 是 “计算规格和详情” (specification)"

#: ../docs/source/working/calculations.rst:92
msgid ""
"Do not forget to add the line ``super(ArithmeticAddCalculation, "
"self).define(spec)`` as the first line of the ``define`` method, where you "
"replace the class name with the name of your calculation job. This will call"
" the ``define`` method of the parent class, which is necessary for the "
"calculation job to work properly"
msgstr ""
"请不要忘记在 ``define`` 方法的首行加入 ``super(ArithmeticAddCalculation, "
"self).define(spec)``  ，这里你需要用你自己的类名。这会调用 ``define`` 方法的父类，使得算例任务可以正确工作。"

#: ../docs/source/working/calculations.rst:95
msgid ""
"As the name suggests, the ``spec`` can be used to specify the properties of "
"the calculation job. For example, it can be used to define inputs that the "
"calculation job takes. In our example, we need to be able to pass two "
"integers as input, so we define those in the spec by calling "
"``spec.input()``. The first argument is the name of the input. This name "
"should be used later to specify the inputs when launching the calculation "
"job and it will also be used as the label for link to connect the data node "
"and the calculation node in the provenance graph. Additionally, as we have "
"done here, you can specify which types are valid for that particular input. "
"Since we expect integers, we specify that the valid type is the database "
"storable :py:class:`~aiida.orm.nodes.data.int.Int` class."
msgstr ""
"正如其名所示， ``spec`` "
"可以用于指定算例任务的性质。比如，它可以用于定义算例任务所需的输入。在我们的例子中，我们需要接受两个整数作为输入，所以我们通过调用 "
"``spec.input()`` 定义这些 “规格参数”。 "
"第一个参数是输入的名称。该名称之后会被用于在启动算例任务时输入的指定，还会被作为在可验证性图中连接算例节点的数据节点的标签。另外，正如我们在这里所用到的，你还可以指定特定输入允许的参数类型。因为我们在此处希望得到整形的变量，我们指定允许的类型是数据库可储存的"
" :py:class:`~aiida.orm.nodes.data.int.Int` 类。"

#: ../docs/source/working/calculations.rst:105
msgid ""
"Since we sub class from ``CalcJob`` and call its ``define`` method, it will "
"inherit the ports that it declares as well. If you look at the "
"implementation, you will find that the base class ``CalcJob`` already "
"defines an input ``code`` that takes a ``Code`` instance. This will "
"reference the code that the user wants to run when he launches the "
"``CalcJob``. For this reason, you **do not** again have to declare this "
"input."
msgstr ""
"因为我们继承了 ``CalcJob`` 类并调用了它的 ``define`` 方法，这会同时继承其声明的端口(port)。 "
"如果你查看类的实现，你会发现在基类 ``CalcJob`` 中已经定义了输入 ``code`` 以接受一个 ``Code`` 示例。这会指向用户在运行 "
"``CalcJob`` 时所要使用的计算代码。因此， **请不要** 重复声明该输入。"

#: ../docs/source/working/calculations.rst:110
msgid ""
"Next we should define what outputs we expect the calculation to produce:"
msgstr "之后我们需要定义我们期望得到的算例输出 :"

#: ../docs/source/working/calculations.rst:115
msgid ""
"Just as for the inputs, one can specify what node type each output should "
"have. By default a defined output will be 'required', which means that if "
"the calculation job terminates and the output has not been attached, the "
"process will be marked as failed. To indicate that an output is optional, "
"one can use ``required=False`` in the ``spec.output`` call. Note that the "
"process spec, and its "
":py:meth:`~aiida.engine.processes.process_spec.ProcessSpec.input` and "
":py:meth:`~aiida.engine.processes.process_spec.ProcessSpec.output` methods "
"provide a lot more functionality. Fore more details, please refer to the "
"section on :ref:`process specifications<working_processes_spec>`."
msgstr ""
"如同输入，用户需要指定每个输出因有的节点类型。默认的，一个定义了的输出将会是 '必给的' "
"(required)，意味着如果算例任务终止但没有得到输出，则例程(process)会被标记为失败。要指明一个输出不是必须的而是可选的，用户可以在 "
"``spec.output`` 调用中使用 ``required=False``  。可以注意到，例程的规格详情以及其 "
":py:meth:`~aiida.engine.processes.process_spec.ProcessSpec.input` 和 "
":py:meth:`~aiida.engine.processes.process_spec.ProcessSpec.output` "
"方法提供了许多功能。详情可以参考章节 :ref:`例程规格<working_processes_spec>` 。"

#: ../docs/source/working/calculations.rst:125
msgid "Prepare"
msgstr "准备"

#: ../docs/source/working/calculations.rst:126
msgid ""
"We have know defined through the process specification, what inputs the "
"calculation job expects and what outputs it will create. The final remaining"
" task is to instruct the engine how the calculation job should actually be "
"run. To understand what the engine would have to do to accomplish this, "
"let's consider what one typically does when manually preparing to run a "
"computing job through a scheduler:"
msgstr ""
"通过例程的规格定义，我们能够知晓算例任务所期望的输入和将会产生的输出。剩下的任务就是告知引擎算例任务事实上需要如何运行。为了理解AiiDA引擎为了完成算例任务将会执行的步骤，我们来看一下当用户手动通过任务调度工具执行一个计算任务时会采取的具体步骤"
" :"

#: ../docs/source/working/calculations.rst:130
msgid ""
"Prepare a working directory in some scratch space on the machine where the "
"job will run"
msgstr "在计算资源的可用空间上，准备一个任务运行的工作文件夹"

#: ../docs/source/working/calculations.rst:131
msgid "Create the raw input files required by the executable"
msgstr "创建可执行软件所需的的原始输入文件"

#: ../docs/source/working/calculations.rst:132
msgid ""
"Create a launch script containing scheduler directives, loading of "
"environment variables and finally calling the executable with certain "
"command line parameters."
msgstr "创建一个包含调度程序指令的启动脚本，加载环境变量，最后使用特定命令行参数调用可执行文件。"

#: ../docs/source/working/calculations.rst:134
msgid ""
"So all we need to do now is instruct the engine how to accomplish these "
"things for a specific calculation job. Since these instructions will be "
"calculation dependent, we will implement this with the "
":py:meth:`~aiida.engine.processes.calcjobs.calcjob.CalcJob.prepare_for_submission`"
" method. The implementation of the ``ArithmeticAddCalculation`` that we are "
"considering in the example looks like the following:"
msgstr ""
"所以我们要做的就是直到AiiDA引擎对指定算例任务完成这些步骤。由于。由于这些步骤对每个计算是不同的，我们需要通过 "
":py:meth:`~aiida.engine.processes.calcjobs.calcjob.CalcJob.prepare_for_submission`"
" 方法来实现这些步骤。在样例中展示的 ``ArithmeticAddCalculation`` 实现如下 :"

#: ../docs/source/working/calculations.rst:141
msgid ""
"Before we go into the code line-by-line, let's describe the big picture of "
"what is happening here. The goal of this method is to help the engine "
"accomplish the three steps required for preparing the submission a "
"calculation job, as described above. The raw input files that are required "
"can be written to a sandbox folder that is passed in as the ``folder`` "
"argument. All the other required information, such as the directives of "
"which files to copy and what command line options to use are defined through"
" the :py:class:`~aiida.common.datastructures.CalcInfo` datastructure, which "
"should be returned from the method as the only value. In principle, this is "
"what one **should do** in the ``prepare_for_submission`` method:"
msgstr ""
"在我们逐行研究代码之前，让我们先描述一下这里发生的事情的全貌。该类方法的目的是帮助AiiDA引擎完成如上所述的准备和提交计算任务所需的三个步骤。所需的原始输入文件可以写入沙箱文件夹，该文件夹之后会以"
" ``folder`` 参数传入。所需的其他所有信息，如拷贝文件的指令和指令参数均通过 "
":py:class:`~aiida.common.datastructures.CalcInfo` "
"数据结构定义，这个值应该作为方法返回的唯一值。理论上，这是用户在方法 ``prepare_for_submission`` 中 **应该做的** :"

#: ../docs/source/working/calculations.rst:147
msgid ""
"Writing raw inputs files required for the calculation to run to the "
"``folder`` sandbox folder."
msgstr "编写运行计算所需的原始输入文件到 ``folder`` 沙箱文件夹。"

#: ../docs/source/working/calculations.rst:148
msgid ""
"Use a ``CalcInfo`` to instruct the engine which files to copy to the working"
" directory"
msgstr "使用 ``CalcInfo`` 告诉引擎将被复制到工作目录的文件"

#: ../docs/source/working/calculations.rst:149
msgid ""
"Use a ``CalcInfo`` to tell which codes should run, using which command line "
"parameters, such as standard input and output redirection."
msgstr "使用 ``CalcInfo`` 来决定应运行的计算代码，以及使用哪些命令行参数，例如标准输入和输出重定向。"

#: ../docs/source/working/calculations.rst:153
msgid ""
"The ``prepare_for_submission`` does not have to write the submission script "
"itself. The engine will know how to do this, because the codes that are to "
"be used have been configured on a specific computer, which defines what "
"scheduler is to be used. This gives the engine all the necessary information"
" on how to write the launch script such as what scheduler directives to "
"write."
msgstr ""
"函数 ``prepare_for_submission`` "
"中不需要自己编写任务提交脚本。引擎知道如何编写任务脚本，因为使用的计算代码在配置时已经关联到特定计算资源上，因此其上的任务调度工具也就被记录在计算代码中。这也就告知了AiiDA引擎有关如何编写任务提交脚本比如任务调度指令等的全部信息。"

#: ../docs/source/working/calculations.rst:157
msgid ""
"Now that we know what the ``prepare_for_submission`` is expected to do, "
"let's see how the implementation of the ``ArithmeticAddCalculation`` "
"accomplishes it line-by-line. The input file required for this example "
"calculation will consist of the two integers that are passed as inputs. The "
"``self.inputs`` attribute returns an attribute dictionary with the parsed "
"and validated inputs, according to the process specification defined in the "
"``define`` method. This means that you do not have to validate the inputs "
"yourself. That is to say, if an input is marked as required and of a certain"
" type, by the time we get to the ``prepare_for_submission`` it is guaranteed"
" that the dictionary returned by ``self.inputs`` will contain that input and"
" of the correct type."
msgstr ""
"现在我们知道 ``prepare_for_submission`` 的预期功能，让我们逐行看看 ``ArithmeticAddCalculation``"
" 的实现。此示例所需的输入文件包含作为输入传递的两个整数。 ``self.inputs`` 属性根据 ``define`` "
"方法中定义的过程规范返回解析和验证好的输入的属性字典。这意味着用户不必自己验证输入。也就是说，如果输入被标记为必须的，以及某种指定类型，那么当我们运行 "
"``prepare_for_submission`` 时，``self.inputs`` 返回的字典将确保包含正确类型的输入。"

#: ../docs/source/working/calculations.rst:163
msgid ""
"From the two inputs ``x`` and ``y`` that will have been passed when the "
"calculation job was launched, we should now generate the input file, that is"
" simply a text file with these two numbers on a single line, separated by a "
"space. We accomplish this by opening a filehandle to the input file in the "
"sandbox folder and write the values of the two ``Int`` nodes to the file."
msgstr ""
"计算作业启动，两个输入 ``x`` 和 ``y`` "
"会被传入，我们应确保输入文件只是包含一行两个数组的文本文件，这两个数字在一行上，被空间隔开。我们通过在沙箱文件夹中打开到输入文件的文件句柄并将两个 "
"``Int`` 节点的值写入文件来实现此目的。"

#: ../docs/source/working/calculations.rst:168
msgid ""
"The format of this input file just so happens to be the format that the "
":ref:`bash script<concepts_calcjobs>` expects that we are using in this "
"example. The exact number of input files and their content will of course "
"depend on the code for which the calculation job is being written."
msgstr ""
"这个输入文件的格式恰好是 :ref:`bash script<concepts_calcjobs>` "
"期望我们在本例中使用的格式。输入文件的确切数量及其内容当然将取决于为其编写算例任务的代码。"

#: ../docs/source/working/calculations.rst:171
msgid ""
"With the input file written, we now have to create an instance of "
":py:class:`~aiida.common.datastructures.CalcInfo` that should be returned "
"from the method. This data structure will instruct the engine exactly what "
"needs to be done to execute the code, such as what files should be copied to"
" the remote computer where the code will be executed. In this simple "
"example, we define four simple attributes:"
msgstr ""
"写好输入文件后，我们现在必须创建一个 :py:class:`~aiida.common.datastructures.CalcInfo` "
"的实例，该实例应该从方法返回。这个数据结构将精确地指示引擎如何执行计算代码，比如应该将哪些文件复制到将要执行代码的远程计算机。在这个简单的例子中，我们定义了四个简单的属性:"

#: ../docs/source/working/calculations.rst:175
msgid ""
"``codes_info``: a list of :py:class:`~aiida.common.datastructures.CodeInfo` "
"datastructures, that tell which codes to run consecutively during the job"
msgstr ""
"``codes_info``: 一个由数据结构 :py:class:`~aiida.common.datastructures.CodeInfo` "
"构成的列表，用以告知任务运行期间要顺序执行的计算代码"

#: ../docs/source/working/calculations.rst:176
msgid ""
"``local_copy_list``: a list of tuples that instruct what files to copy to "
"the working directory from the local machine"
msgstr "``local_copy_list``: 元组列表，指示要从本地计算机复制哪些文件到工作目录"

#: ../docs/source/working/calculations.rst:177
msgid ""
"``remote_copy_list``: a list of tuples that instruct what files to copy to "
"the working directory from the machine on which the job will run"
msgstr "``remote_copy_list``: 一个元组列表，它指示要将哪些文件从运行任务的机器复制到工作目录"

#: ../docs/source/working/calculations.rst:178
msgid ""
"``retrieve_list``: a list of tuples instructing which files should be "
"retrieved from the working directory and stored in the local repository "
"after the job has finished"
msgstr "``retrieve_list``: 一个元组列表，指示应从工作目录检索哪些文件，并在作业完成后存储在本地存储库中"

#: ../docs/source/working/calculations.rst:180
msgid ""
"In this example we only need to run a single code, so the ``codes_info`` "
"list has a single ``CodeInfo`` datastructure. This datastructure needs to "
"define which code it needs to run, which is one of the inputs passed to the "
"``CalcJob``, and does so by means of its UUID. Through the ``stdout_name`` "
"attribute, we tell the engine where the output of the executable should be "
"redirected to. In this example this is set to the value of the  "
"``output_filename`` option. What options are available in calculation jobs, "
"what they do and how they can be set will be explained in the :ref:`section "
"on options<working_calcjobs_options>`. Finally, the ``cmdline_params`` "
"attribute takes a list with command line parameters that will be placed "
"*after* the executable in the launch script. Here we use it to explicitly "
"instruct the executable to read its input from the filename stored in the "
"option ``input_filename``."
msgstr ""
"在本例中，我们只需要运行一个计算代码，因此 ``codes_info`` 列表有一个 ``CodeInfo`` "
"数据结构。这个数据结构需要定义它需要运行哪些代码，这是传递给 ``CalcJob`` 的输入之一，并通过它的UUID来实现。通过 "
"``stdout_name`` 属性，我们告诉引擎可执行文件的输出应该重定向到哪里。在本例中，它被设置为 ``output_filename`` "
"选项的值。计算作业中有哪些选项可用，它们做什么以及如何设置这些选项，将在 :ref:`选项章节<working_calcjobs_options>` "
"中进行说明。最后，``cmdline_params`` 属性接受一个带有命令行参数的列表，这些命令行参数将放在启动脚本中可执行文件的 *后面* "
"。在这里，我们使用它显式地指示可执行文件从存储在选项 ``input_filename`` 中的文件名中读取其输入。"

#: ../docs/source/working/calculations.rst:190
msgid ""
"Since we instruct the executable should read the input from "
"``self.options.input_filename``, this is also the filename we used when "
"writing that very input file in the sandbox folder."
msgstr ""
"因为我们指示可执行文件应该从 ``self.options.input_filename`` "
"读取输入，这也是我们在数据临时储存文件夹中编写输入文件时使用的文件名。"

#: ../docs/source/working/calculations.rst:192
msgid ""
"Finally, we have to define the various \"file lists\" that tell what files "
"to copy from where to where and what files to retrieve. Here we will briefly"
" describe their intended goals. The implementation details will be described"
" in full in the :ref:`file lists section<working_calcjobs_file_lists>`."
msgstr ""
"最后，我们必须定义各种“文件列表”，这些“文件列表”告诉我们要将哪些文件从何处复制到何处，以及要检索哪些文件。在这里，我们将简要描述他们的预期目标。实现细节将在"
" :ref:`文件列表章节<working_calcjobs_file_lists>` 中详细描述。"

#: ../docs/source/working/calculations.rst:196
msgid ""
"The local copy list is useful to instruct the engine to copy over files that"
" you might already have stored in your database, such as instances of "
":py:class:`~aiida.orm.nodes.data.singlefile.SinglefileData` nodes, that you "
"can define and pass as inputs of the ``CalcJob``. You could have of course "
"many copied their content to the ``folder`` sandbox folder, which will also "
"have caused them to be written to the working directory. The disadvantage of"
" that method, however, is that all the contents written to the sandbox "
"folder will also be stored in the repository of the ``CalcJobNode`` that "
"will represent the execution of the ``CalcJob`` in the provenance graph. "
"This will cause duplication of the data contained within these data nodes. "
"By not writing them explicitly to the sandbox folder, you avoid this "
"duplication, without losing provenance, because the data node itself will of"
" course be recorded in the provenance graph."
msgstr ""

#: ../docs/source/working/calculations.rst:202
msgid ""
"The remote copy list is useful to avoid unnecessary file transfers between "
"the machine where the engine runs and where the calculation jobs are "
"executed. For example, imagine you have already completed a calculation job "
"on a remote cluster and now want to launch a second one, that requires some "
"of the output files of the first run as its inputs. The remote copy list "
"allows you to specify exactly what output files to copy to the remote "
"working directory, without them having to be retrieved to the engine's "
"machine in between."
msgstr ""
"远程复制列表有助于避免在运行引擎的计算机与执行计算作业的位置之间进行不必要的文件传输。例如，假设您已经在远程集群上完成了计算作业，现在想要启动第二个计算作业，这需要第一次运行的某些输出文件作为其输入。远程复制列表允许您准确指定要复制到远程工作目录的输出文件，而不必将它们检索到引擎的机器之间。"

#: ../docs/source/working/calculations.rst:206
msgid ""
"The retrieve list, finally, allows you to instruct the engine what files "
"should be retrieved from the working directory after the job has terminated."
" These files will be downloaded to the local machine, stored in a "
":py:class:`~aiida.orm.nodes.data.folder.FolderData` data node and attached "
"as an output to the ``CalcJobNode`` with the link label ``retrieved``."
msgstr ""
"最后，检索列表允许您指示引擎在作业终止后应从工作目录中检索哪些文件。这些文件将被下载到本地机器，存储在 "
":py:class:`~aiiida.orm.nodes.data.folder.FolderData`数据节点中，并作为输出附加到带有链接标签的 "
"``CalcJobNode``  ``retrieved`` 。"

#: ../docs/source/working/calculations.rst:211
msgid ""
"We didn't explicitly define the ``retrieved`` folder data node as an output "
"in the example ``ArithmeticAddCalculation`` implementation shown above. This"
" is because this is already defined by the ``CalcJob`` base class. Just as "
"the ``code`` input, the ``retrieved`` output is common for all calculation "
"job implementations."
msgstr ""
"我们没有明确地将 ``retrieve`` 文件夹数据节点定义为上面显示的示例 ``ArithmeticAddCalculation`` "
"实现中的输出。这是因为它已经由 ``CalcJob`` 基类定义。正如 ``code`` 输入一样， ``retrieve`` "
"输出对于所有计算作业实现都是通用的。"

#: ../docs/source/working/calculations.rst:219
msgid "File lists"
msgstr "文件列表"

#: ../docs/source/working/calculations.rst:224
msgid "Local copy list"
msgstr "本地复制列表"

#: ../docs/source/working/calculations.rst:225
msgid ""
"The local copy list takes tuples of length three, each of which represents a"
" file to be copied, defined through the following items:"
msgstr "本地副本列表采用长度为3的元组，每个元组表示要复制的文件，通过以下项定义:"

#: ../docs/source/working/calculations.rst:227
msgid ""
"`node uuid`: the node whose repository contains the file, typically a "
"``SinglefileData`` or ``FolderData`` node"
msgstr "`node uuid`: 其存储库包含文件的节点，通常是 ``SinglefileData`` 或 ``FolderData`` 节点"

#: ../docs/source/working/calculations.rst:228
msgid ""
"`source relative path`: the relative path of the file within the node "
"repository"
msgstr "`source relative path`: 节点存储库中文件的相对路径"

#: ../docs/source/working/calculations.rst:229
#: ../docs/source/working/calculations.rst:255
msgid ""
"`target relative path`: the relative path within the working directory to "
"which to copy the file"
msgstr "`target relative path`: 要复制文件的工作目录中的相对路径"

#: ../docs/source/working/calculations.rst:231
msgid ""
"As an example, consider a ``CalcJob`` implementation that receives a "
"``SinglefileData`` node as input with the name ``pseudopotential``, to copy "
"its contents one can specify:"
msgstr ""
"作为一个例子，考虑一个 ``CalcJob`` 实现，它接收一个名为 ``pseudopotential`` 的 ``SinglefileData`` "
"节点作为输入，以复制其可以指定的内容:"

#: ../docs/source/working/calculations.rst:237
msgid ""
"The ``SinglefileData`` node only contains a single file by definition, the "
"relative path of which is returned by the ``filename`` attribute. If "
"instead, you need to transfer a specific file from a ``FolderData``, you can"
" specify the explicit key of the file, like so:"
msgstr ""
"根据定义， ``SinglefileData`` 节点只包含一个文件，其相对路径由 ``filename`` 属性返回。相反，如果需要从 "
"``FolderData`` 传输特定文件，则可以指定文件的显式键，如下所示:"

#: ../docs/source/working/calculations.rst:244
msgid ""
"Note that the filenames in the relative source and target path need not be "
"the same. This depends fully on how the files are stored in the node's "
"repository and what files need to be written to the working directory."
msgstr "请注意，相对源和目标路径中的文件名不必相同。这完全取决于文件如何存储在节点的存储库中以及需要将哪些文件写入工作目录。"

#: ../docs/source/working/calculations.rst:250
msgid "Remote copy list"
msgstr "远程复制列表"

#: ../docs/source/working/calculations.rst:251
msgid ""
"The remote copy list takes tuples of length three, each of which represents "
"a file to be copied on the remote machine where the calculation will run, "
"defined through the following items:"
msgstr "远程复制列表采用长度为3的元组，每个元组表示要在运行计算的远程计算机上复制的文件，通过以下各项定义:"

#: ../docs/source/working/calculations.rst:253
msgid ""
"`computer uuid`: this is the UUID of the ``Computer`` on which the source "
"file resides. For now the remote copy list can only copy files on the same "
"machine where the job will run."
msgstr ""
"`computer uuid`: 这是源文件所在的 ``Computer`` 的UUID。目前，远程复制列表只能复制运行作业的同一台计算机上的文件。"

#: ../docs/source/working/calculations.rst:254
msgid ""
"`source absolute path`: the absolute path of the source file on the remote "
"machine"
msgstr "`source absolute path`: 远程机器上源文件的绝对路径"

#: ../docs/source/working/calculations.rst:261
msgid ""
"Note that the source path can point to a directory, in which case its "
"contents will be recursively copied in its entirety."
msgstr "请注意，源路径可以指向目录，在这种情况下，其内容将以整体递归方式复制。"

#: ../docs/source/working/calculations.rst:266
msgid "Retrieve list"
msgstr "检索列表"

#: ../docs/source/working/calculations.rst:267
msgid ""
"The retrieve list supports various formats to define what files should be "
"retrieved. The simplest is retrieving a single file, whose filename you know"
" before hand and you simply want to copy with the same name in the retrieved"
" folder. Imagine you want to retrieve the files ``output1.out`` and "
"``output_folder/output2.out`` you would simply add them as strings to the "
"retrieve list:"
msgstr ""

#: ../docs/source/working/calculations.rst:275
msgid ""
"The retrieved files will be copied over keeping the exact names and "
"hierarchy. If you require more control over the hierarchy and nesting, you "
"can use tuples of length three instead, with the following items:"
msgstr "将检索检索到的文件，保留确切的名称和层次结构。如果您需要对层次结构和嵌套进行更多控制，则可以使用长度为3的元组，使用以下项："

#: ../docs/source/working/calculations.rst:278
msgid ""
"`source relative path`: the relative path, with respect to the working "
"directory on the remote, of the file or directory to retrieve"
msgstr "`source relative path`: 相对于要检索的文件或目录的远程工作目录的相对路径"

#: ../docs/source/working/calculations.rst:279
msgid ""
"`target relative path`: the relative path where to copy the files locally in"
" the retrieved folder. The string `'.'` indicates the top level in the "
"retrieved folder."
msgstr "`target relative path`: 在检索到的文件夹中本地复制文件的相对路径。字符串 `'.'` 表示检索到的文件夹中的顶级。"

#: ../docs/source/working/calculations.rst:280
msgid ""
"`depth`: the number of levels of nesting in the folder hierarchy to maintain"
" when copying, starting from the deepest file"
msgstr "`depth`: 复制时要保留的文件夹层次结构中的嵌套级别数，从最深的文件开始"

#: ../docs/source/working/calculations.rst:282
msgid ""
"For example, imagine the calculation will have written a file in the remote "
"working directory with the folder hierarchy "
"``some/remote/path/files/output.dat``. If you want to copy the file, with "
"the final resulting path ``path/files/output.dat``, you would specify:"
msgstr ""
"例如，假设计算将在远程工作目录中编写一个文件，文件夹层次结构为 ``some/remote/path/files/output.dat`` "
"。如果要复制文件，并使用最终生成的路径 ``path/files/output.dat`` ，则应指定:"

#: ../docs/source/working/calculations.rst:289
msgid ""
"The depth of two, ensures that only two levels of nesting are copied. If the"
" output files have dynamic names that one cannot know beforehand, the "
"``'*'`` glob pattern can be used. For example, if the code will generate a "
"number of XML files in the folder ``relative/path/output`` with filenames "
"that follow the pattern ``file_*[0-9].xml``, you can instruct to retrieve "
"all of them as follows:"
msgstr ""
"深度为2，确保只复制两层嵌套。如果输出文件具有事先无法知道的动态名称，则可以使用 ``'*'`` glob模式。例如，如果代码将在文件夹 "
"``relative/path/output`` 中生成许多XML文件，文件名遵循模式 ``file_*[0-9].xml`` "
"，则可以指示检索所有这些都如下:"

#: ../docs/source/working/calculations.rst:297
msgid ""
"The second item when using globbing *has* to be ``'.'`` and the depth works "
"just as before. In this example, all files matching the globbing pattern "
"will be copied in the directory ``output`` in the retrieved folder data "
"node."
msgstr ""

#: ../docs/source/working/calculations.rst:302
msgid "Retrieve temporary list"
msgstr "检索临时列表"

#: ../docs/source/working/calculations.rst:303
msgid ""
"Recall that, as explained in the :ref:`'prepare' "
"section<working_calcjobs_prepare>`, all the files that are retrieved by the "
"engine following the 'retrieve list', are stored in the ``retrieved`` folder"
" data node. This means that any file you retrieve for a completed "
"calculation job will be stored in your repository. If you are retrieving big"
" files, this can cause your repository to grow significantly. Often, "
"however, you might only need a part of the information contained in these "
"retrieved files. To solve this common issue, there is the concept of the "
"'retrieve temporary list'. The specification of the retrieve temporary list "
"is identical to that of the normal :ref:`retrieve "
"list<working_calcjobs_file_lists_retrieve>`. The only difference is that, "
"unlike the files of the retrieve list which will be permanently stored in "
"the retrieved :py:class:`~aiida.orm.nodes.data.folder.FolderData` node, the "
"files of the retrieve temporary list will be stored in a temporary sandbox "
"folder. This folder is then passed to the "
":ref:`parser<working_calcjobs_parsers>`, if one was specified for the "
"calculation job. The parser implementation can then parse these files and "
"store the relevant information as output nodes. After the parser terminates,"
" the engine will take care to automatically clean up the sandbox folder with"
" the temporarily retrieved files. The contract of the 'retrieve temporary "
"list' is essentially that the files will be available during parsing and "
"will be destroyed immediately afterwards."
msgstr ""
"回想一下，如 :ref:`准备部分<working_calcjobs_prepare>` 中所述，引擎在'检索列表'之后检索的所有文件都存储在 "
"``retrieve`` "
"文件夹数据节点中。这意味着您为完成的计算作业检索的任何文件都将存储在您的存储库中。如果要检索大文件，这可能会导致存储库显着增长。但是，通常，您可能只需要这些检索到的文件中包含的部分信息。为了解决这个常见问题，有“检索临时列表”的概念。检索临时列表的规范与普通列表的规范相同"
" :ref:`retrieve list <working_calcjobs_file_lists_retrieve>` "
"。唯一的区别是，与检索列表的文件不同，它将永久存储在检索到的 "
":py:class:`~aiida.orm.nodes.data.folder.FolderData` "
"节点中，检索临时列表的文件将存储在临时沙箱文件夹中。然后将此文件夹传递给 :ref:`parser "
"<working_calcjobs_parsers>` "
"，如果为计算作业指定了一个。然后，解析器实现可以解析这些文件并将相关信息存储为输出节点。解析器终止后，引擎将注意使用临时检索的文件自动清理沙箱文件夹。 "
"“检索临时列表”的合同本质上是文件在解析期间可用，并且将在之后立即销毁。"

#: ../docs/source/working/calculations.rst:319
msgid "Options"
msgstr "选项"

#: ../docs/source/working/calculations.rst:320
msgid ""
"In addition to the common metadata inputs, such as ``label`` and "
"``description``, that all processes have, the "
":py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` has an "
"additonal input called ``options``. These options allow to subtly change the"
" behavior of the calculation job, for example which parser should be used "
"once it is finished and special scheduler directives. The full list of "
"available options are documented below as part of the ``CalcJob`` interface:"
msgstr ""

#: ../docs/source/working/calculations.rst:331
msgid "Launch"
msgstr "发动"

#: ../docs/source/working/calculations.rst:333
msgid ""
"Launching a calculation job is no different from launching any other process"
" class, so please refer to the section on :ref:`launching "
"processes<working_processes_launch>`. The only caveat that we should place "
"is that calculation jobs typically tend to take quite a bit of time. The "
"trivial example we used above of course will run very fast, but a typical "
"calculation job that will be submitted to a scheduler will most likely take "
"longer than just a few seconds. For that reason it is highly advisable to "
"**submit** calculation jobs instead of running them. By submitting them to "
"the daemon, you free up your interpreter straight away and the process will "
"be checkpointed between the various :ref:`transport "
"tasks<concepts_calcjobs_transport_tasks>` that will have to be performed. "
"The exception is of course when you want to run a calculation job locally "
"for testing or demonstration purposes."
msgstr ""

#: ../docs/source/working/calculations.rst:344
msgid "Dry run"
msgstr ""

#: ../docs/source/working/calculations.rst:345
msgid ""
"The calculation job has one additional feature over all other processes when"
" it comes to launching them. Since an incorrectly configured calculation job"
" can potentially waste computational resources, one might want to inspect "
"the input files that will be written by the plugin, before actually "
"submitting the job. A so-called dry-run is possible by simply specifying it "
"in the metadata of the inputs. If you are using the process builder, it is "
"as simple as:"
msgstr ""

#: ../docs/source/working/calculations.rst:354
msgid ""
"When you now launch the process builder, the engine will perform the entire "
"process of a normal calculation job run, except that it will not actually "
"upload and submit the job to the remote computer. However, the "
"``prepare_for_submission`` method will be called. The inputs that it writes "
"to the input folder will be stored in temporary folder called "
"``submit_test`` that will be created in the current working directory. Each "
"time you perform a dry-run, a new sub folder will be created in the "
"``submit_test`` folder, which you allows you to perform multiple dry-runs "
"without overwriting the previous results."
msgstr ""

#: ../docs/source/working/calculations.rst:359
msgid "Moreover, the following applies:"
msgstr ""

#: ../docs/source/working/calculations.rst:361
msgid ""
"when calling :py:func:`~aiida.engine.launch.run` for a calculation with the "
"``dry_run`` flag set, you will get back its results, being always an empty "
"dictionary ``{}``;"
msgstr ""

#: ../docs/source/working/calculations.rst:364
msgid ""
"if you call :py:func:`~aiida.engine.launch.run_get_node`, you will get back "
"as a node an unstored ``CalcJobNode``. In this case, the unstored "
"``CalcJobNode`` (let's call it ``node``) will have an additional property "
"``node.dry_run_info``. This is a dictionary that contains additional "
"information on the dry-run output. In particular, it will have the following"
" keys:"
msgstr ""

#: ../docs/source/working/calculations.rst:370
msgid ""
"``folder``: the absolute path to the folder within the ``submit_test`` "
"folder where the files have been created, e.g.: "
"``/home/user/submit_test/20190726-00019``"
msgstr ""

#: ../docs/source/working/calculations.rst:373
msgid ""
"``script_filename``: the filename of the submission script that AiiDA "
"generated in the folder, e.g.: ``_aiidasubmit.sh``"
msgstr ""

#: ../docs/source/working/calculations.rst:376
msgid ""
"if you send a dry-run to the :py:func:`~aiida.engine.launch.submit` "
"function, this will be just forwarded to run and you will get back the "
"unstored node (with the same properties as above)."
msgstr ""

#: ../docs/source/working/calculations.rst:383
msgid ""
"By default the storing of provenance is enabled and this goes also for a dry"
" run. If you do not want any nodes to be created during a dry run, simply "
"set the metadata input ``store_provenance`` to ``False``."
msgstr ""

#: ../docs/source/working/calculations.rst:390
msgid "Parsing"
msgstr ""

#: ../docs/source/working/calculations.rst:391
msgid ""
"The previous sections explained in detail how the execution of an external "
"executable is wrapped by the ``CalcJob`` class to make it runnable by "
"AiiDA's engine. From the first steps of preparing the input files on the "
"remote machine, to retrieving the relevant files and storing them in a "
":py:class:`~aiida.orm.nodes.data.folder.FolderData` node, that is attached "
"as the ``retrieved`` output. This is the last *required* step for a "
"``CalcJob`` to terminate, but often we would *like* to parse the raw output "
"and attach them as queryable output nodes to the calculation job node. To "
"automatically trigger the parsing of a calculation job after its output has "
"been retrieved, is to specify the :ref:`parser name "
"option<working_calcjobs_options>`. If the engine find this option specified,"
" it will load the corresponding parser class, which should be a sub class of"
" :py:class:`~aiida.parsers.parser.Parser` and calls its "
":py:meth:`~aiida.parsers.parser.Parser.parse` method."
msgstr ""

#: ../docs/source/working/calculations.rst:397
msgid ""
"To explain the interface of the ``Parser`` class and the ``parse`` method, "
"let's take the "
":py:class:`~aiida.parsers.plugins.arithmetic.add.ArithmeticAddParser` as an "
"example. This parser is designed to parse the output produced by the simple "
"bash script that is wrapped by the ``ArithmeticAddCalculation`` discussed in"
" the previous sections."
msgstr ""

#: ../docs/source/working/calculations.rst:404
msgid ""
"To create a new parser implementation, simply create a new class that sub "
"classes the :py:class:`~aiida.parsers.parser.Parser` class. As usual, any "
"valid python class name will work, but the convention is to always use the "
"``Parser`` suffix and to use the same name as the calculation job for which "
"the parser is designed. For example, here we are implementing a parser for "
"the ``ArithmeticAddCalculation``, so therefore we name it "
"``ArithmeticAddParser``, just replacing the ``Calculation`` suffix for "
"``Parser``. The only method that needs to be implemented is the "
":py:meth:`~aiida.parsers.parser.Parser.parse` method. Its signature should "
"include ``**kwargs``, the reason for which will become clear later. The goal"
" of the ``parse`` method is very simple:"
msgstr ""

#: ../docs/source/working/calculations.rst:411
msgid ""
"Open and load the content of the output files generated by the calculation "
"job and have been retrieved by the engine"
msgstr ""

#: ../docs/source/working/calculations.rst:412
msgid ""
"Create data nodes out of this raw data that are attached as output nodes"
msgstr ""

#: ../docs/source/working/calculations.rst:413
msgid "Log human-readable warning messages in the case of worrying output"
msgstr ""

#: ../docs/source/working/calculations.rst:414
msgid ""
"Optionally return an :ref:`exit code<concepts_process_exit_codes>` to "
"indicate that the results of the calculation was not successful"
msgstr ""

#: ../docs/source/working/calculations.rst:416
msgid ""
"The advantage of adding the raw output data in different form as output "
"nodes, is that in that form the content becomes queryable. This allows one "
"to query for calculations that produced specific outputs with a certain "
"value, which becomes a very powerful approach for post-processing and "
"analyses of big databases."
msgstr ""

#: ../docs/source/working/calculations.rst:419
msgid ""
"The ``retrieved`` attribute of the parser will return the ``FolderData`` "
"node that should have been attached by the engine containing all the "
"retrieved files, as specified using the :ref:`retrieve "
"list<working_calcjobs_file_lists_retrieve>` in the :ref:`preparation step of"
" the calculation job<working_calcjobs_prepare>`. If this node has not been "
"attached for whatever reason, this call will throw an "
":py:class:`~aiida.common.exceptions.NotExistent` exception. This is why we "
"wrap the ``self.retrieved`` call in a try-catch block:"
msgstr ""

#: ../docs/source/working/calculations.rst:429
msgid ""
"If the exception is thrown, it means the retrieved files are not available "
"and something must have has gone terribly awry with the calculation. In this"
" case, there is nothing to do for the parser and so we return an exit code. "
"Specific exit codes can be referenced by their label, such as "
"``ERROR_NO_RETRIEVED_FOLDER`` in this example, through the "
"``self.exit_codes`` property. This call will retrieve the corresponding exit"
" code defined on the ``CalcJob`` that we are currently parsing. Returning "
"this exit code from the parser will stop the parsing immediately and will "
"instruct the engine to set its exit status and exit message on the node of "
"this calculation job. This should scenario should however never occur, but "
"it is just here as a safety. If the exception would not be caught, the "
"engine will catch the exception instead and set the process state of the "
"corresponding calculation to ``Excepted``. Note that this will happen for "
"any exception that occurs during parsing."
msgstr ""

#: ../docs/source/working/calculations.rst:438
msgid ""
"Assuming that everything went according to plan during the retrieval, we now"
" have access to those retrieved files and can start to parse them. In this "
"example, there should be a single output file that was written by "
"redirecting the standard output of the bash script that added the two "
"integers. The parser opens this file, reads its content and tries to parse "
"the sum from it:"
msgstr ""

#: ../docs/source/working/calculations.rst:448
msgid ""
"Note that again we wrap this parsing action in a try-except block. If the "
"file cannot be found or cannot be read, we return the appropriate exit code."
" The ``parse_stdout`` method is just a small utility function to separate "
"the actual parsing of the data from the main parser code. In this case, the "
"parsing is so simple that we might have as well kept it in the main method, "
"but this is just to illustrate that you are completely free to organize the "
"code within the ``parse`` method for clarity. If we manage to parse the sum,"
" produced by the calculation, we wrap it in the appropriate "
":py:class:`~aiida.orm.nodes.data.int.Int` data node class, and register it "
"as an output through the ``out`` method:"
msgstr ""

#: ../docs/source/working/calculations.rst:460
msgid ""
"Note that if we encountered no problems, we do not have to return anything. "
"The engine will interpret this as the calculation having finished "
"successfully. You might now pose the question: \"what part of the raw data "
"should I parse and in what types of data nodes should I store it?\". This "
"not an easy question to answer in the general, because it will heavily "
"depend on the type of raw output that is produced by the calculation and "
"what parts you would like to be queryable. However, we can give you some "
"guidelines:"
msgstr ""

#: ../docs/source/working/calculations.rst:466
msgid ""
"Store data that you might want to query for, in the lightweight data nodes, "
"such as :py:class:`~aiida.orm.nodes.data.dict.Dict`, "
":py:class:`~aiida.orm.nodes.data.list.List` and "
":py:class:`~aiida.orm.nodes.data.structure.StructureData`. The contents of "
"these nodes are stored as attributes in the database, which makes sure that "
"they can be queried for."
msgstr ""

#: ../docs/source/working/calculations.rst:468
msgid ""
"Bigger data sets, such as large (multi-dimnensional) arrays, are better "
"stored in an :py:class:`~aiida.orm.nodes.data.array.array.ArrayData` or one "
"of its sub classes. If you were to store all this data in the database, it "
"would become unnecessarily bloated, because the chances you would have to "
"query for this data are unlikely. Instead these array type data nodes store "
"the bulk of their content in the repository. This way you still keep the "
"data and therewith the provenance of your calculations, while keeping your "
"database lean and fast!"
msgstr ""

#: ../docs/source/working/data.rst:4
msgid "Concept"
msgstr ""

#: ../docs/source/working/data.rst:6
msgid ""
"The nodes in the :ref:`provenance graph<concepts_provenance>` that are the "
"inputs and outputs of processes are referred to as `data` and are "
"represented by :class:`~aiida.orm.nodes.data.data.Data` nodes. Since data "
"can come in all shapes and forms, the "
":class:`~aiida.orm.nodes.data.data.Data` class can be sub classed. AiiDA "
"ships with some basic data types such as the "
":class:`~aiida.orm.nodes.data.int.Int` which represents a simple integer and"
" the :class:`~aiida.orm.nodes.data.dict.Dict`, representing a dictionary of "
"key-value pairs. There are also more complex data types such as the "
":class:`~aiida.orm.nodes.data.array.array.ArrayData` which can store "
"multidimensional arrays of numbers. These basic data types serve most needs "
"for the majority of applications, but more specific solutions may be useful "
"or even necessary. In the next sections, we will explain :ref:`how a new "
"data type can be created<working_data_creating_new_types>` and what "
":ref:`guidelines<working_data_design_guidelines>` should ideally be observed"
" during the design process."
msgstr ""

#: ../docs/source/working/data.rst:17
msgid "Creating new data types"
msgstr ""

#: ../docs/source/working/data.rst:19
msgid ""
"Creating a new data type is as simple as creating a new sub class of the "
"base :class:`~aiida.orm.nodes.data.data.Data` class."
msgstr ""

#: ../docs/source/working/data.rst:28
msgid ""
"At this point, our new data type does nothing special. Typically, one "
"creates a new data type to represent a specific type of data. For the "
"purposes of this example, let's assume that the goal of our ``NewData`` type"
" is to store a single numerical value. To allow one to construct a new "
"``NewData`` data node with the desired ``value``, for example:"
msgstr ""

#: ../docs/source/working/data.rst:37
msgid ""
"we need to allow passing that value to the constructor of the node class. "
"Therefore, we have to override the constructor "
":meth:`~aiida.orm.nodes.node.Node.__init__`:"
msgstr ""

#: ../docs/source/working/data.rst:54
msgid ""
"For the class to function properly, the signature of the constructor "
"**cannot be changed** and the constructor of the parent class **has to be "
"called**."
msgstr ""

#: ../docs/source/working/data.rst:56
msgid ""
"Before calling the construtor of the base class, we have to remove the "
"``value`` keyword from the keyword arguments ``kwargs``, because the base "
"class will not expect it and will raise an exception if left in the keyword "
"arguments. The final step is to actually *store* the value that is passed by"
" the caller of the constructor. A new node has two locations to permanently "
"store any of its properties:"
msgstr ""

#: ../docs/source/working/data.rst:60
msgid "the database"
msgstr ""

#: ../docs/source/working/data.rst:61
msgid "the file repository"
msgstr ""

#: ../docs/source/working/data.rst:63
msgid ""
"The section on :ref:`design guidelines<working_data_design_guidelines>` will"
" go into more detail what the advantages and disadvantages of each option "
"are and when to use which. For now, since we are storing only a single "
"value, the easiest and best option is to use the database. Each node has "
"*attributes* that can store any key-value pair, as long as the value is JSON"
" serializable. By adding the value to the node's attributes, they will be "
"queryable in the database once an instance of the ``NewData`` node is "
"stored."
msgstr ""

#: ../docs/source/working/data.rst:74
msgid ""
"After storing the node instance in the database, its attributes are frozen, "
"and ``node.set_attribute('value', 7)`` will fail. By storing the ``value`` "
"in the attributes of the node instance, we ensure that that ``value`` can be"
" retrieved even when the node is reloaded at a later point in time."
msgstr ""

#: ../docs/source/working/data.rst:77
msgid ""
"Besides making sure that the content of a data node is stored in the "
"database or file repository, the data type class can also provide useful "
"methods for users to retrieve that data. For example, with the current state"
" of the ``NewData`` class, in order to retrieve the ``value`` of a stored "
"``NewData`` node, one needs to do:"
msgstr ""

#: ../docs/source/working/data.rst:85
msgid ""
"In other words, the user of the ``NewData`` class needs to know that the "
"``value`` is stored as an attribute with the name 'value'. This is not easy "
"to remember and therefore not very user-friendly. Since the ``NewData`` type"
" is a class, we can give it useful methods. Let's introduce one that will "
"return the value that was stored for it:"
msgstr ""

#: ../docs/source/working/data.rst:102
msgid ""
"The addition of the instance property ``value`` makes retrieving the value "
"of a ``NewData`` node a lot easier:"
msgstr ""

#: ../docs/source/working/data.rst:109
msgid ""
"As said before, in addition to their attributes, data types can also store "
"their properties in the file repository. Imagine a data type that needs to "
"wrap a single text file."
msgstr ""

#: ../docs/source/working/data.rst:140
msgid "To create a new instance of this data type and get its content:"
msgstr ""

#: ../docs/source/working/data.rst:147
msgid ""
"This example is a simplified version of the "
":class:`~aiida.orm.nodes.data.singlefile.SinglefileData` data class that "
"ships with `aiida-core`. If this happens to be your use case (or very close "
"to it), it is of course better to use that class, or you can sub class it "
"and adapt it where needed."
msgstr ""

#: ../docs/source/working/data.rst:150
msgid ""
"The two new data types we have just implemented are of course trivial and "
"not very useful, but the concepts are flexible and can easily be applied to "
"more complex use-cases. The following section will provide useful guidelines"
" on how to optimally design new data types."
msgstr ""

#: ../docs/source/working/data.rst:157
msgid "Database or repository?"
msgstr ""

#: ../docs/source/working/data.rst:159
msgid ""
"When deciding where to store a property of a data type, one has to choose "
"between the database and the file repository. The database will make it "
"possible to search in the provenance graph based on criteria based on the "
"property, e.g. all ``NewData`` nodes where the property is greater than 0. "
"The downside is that storing too much information in the database can make "
"it sluggish. Therefore, big data (think large files), whose content does not"
" necessarily need to be queried for, is better stored in the file "
"repository. Of course a data type may need to store multiple properties of "
"varying character, but both storage locations can safely be used in "
"parellel. When choosing the database as the storage location, the properties"
" should be stored using the node *attributes*. To set and retrieve them, use"
" the attribute methods of the :class:`~aiida.orm.nodes.node.Node` class."
msgstr ""

#: ../docs/source/working/functions.rst:4
msgid "About"
msgstr ""

#: ../docs/source/working/functions.rst:6
msgid ""
"A process function is a process (see the :ref:`process "
"section<concepts_processes>` for details) that is implemented as a decorated"
" python function. Currently, there are two types of process functions:"
msgstr ""

#: ../docs/source/working/functions.rst:9
msgid ":ref:`calculation function<concepts_calcfunctions>`"
msgstr ""

#: ../docs/source/working/functions.rst:10
msgid ":ref:`work function<concepts_workfunctions>`"
msgstr ""

#: ../docs/source/working/functions.rst:12
msgid ""
"The former can *create* new data, whereas the latter can orchestrate other "
"processes and *return* their results. This section will provide detailed "
"information and best practices on how to implement these two process types. "
"Since the calculation function and work function are both process functions "
"and have the same implementation, all the rules explained below apply to "
"both process types."
msgstr ""

#: ../docs/source/working/functions.rst:17
msgid ""
"This chapter assumes that the basic concept and difference between "
"calculation functions and work functions is known and when one should use on"
" or the other. It is therefore crucial that, before you continue, you have "
"read and understood the basic concept of :ref:`calculation "
"functions<concepts_calcfunctions>` and :ref:`work "
"functions<concepts_workfunctions>`."
msgstr ""

#: ../docs/source/working/functions.rst:20
msgid ""
"The simple example in the :ref:`introductory section on calculation "
"functions<concepts_calcfunctions>` showed how a simple python function can "
"be turned into a calculation function simply by adorning it with the "
":py:func:`~aiida.engine.processes.functions.calcfunction` decorator. When "
"the function is run, AiiDA will dynamically generate a "
":py:class:`~aiida.engine.processes.functions.FunctionProcess` and build its "
":ref:`process specification<working_processes_spec>` based on the function "
"signature. Here we will explain how this is accomplished and what features "
"of the python function signature standard are supported."
msgstr ""

#: ../docs/source/working/functions.rst:25
msgid "Function signatures"
msgstr ""

#: ../docs/source/working/functions.rst:26
msgid ""
"To explain what features of python function definitions and calls are "
"supported we first need to be clear about some terminology. When dealing "
"with functions, there are two distinct parts:"
msgstr ""

#: ../docs/source/working/functions.rst:29
msgid ""
"`function definitions "
"<https://docs.python.org/3/reference/compound_stmts.html#function-"
"definitions>`_"
msgstr ""

#: ../docs/source/working/functions.rst:30
msgid ""
"`function calls "
"<https://docs.python.org/3/reference/expressions.html#calls>`_"
msgstr ""

#: ../docs/source/working/functions.rst:32
msgid ""
"Consider the following code snippet that defines a simple python function:"
msgstr ""

#: ../docs/source/working/functions.rst:37
msgid ""
"The function takes three 'parameters', named ``x``, ``y`` and ``z``. In "
"addition, the function ``plain_function`` is said to have default values, "
"because one or more parameters (``z`` in this case) have the form `parameter"
" = expression`. When *calling* a function, the terminology changes slightly "
"and values for parameters can be passed as either 'positional' or 'keyword'."
" In the example below, the function is called with 'positional' arguments:"
msgstr ""

#: ../docs/source/working/functions.rst:45
msgid ""
"They are called positional, because the arguments are not explicitly named "
"and so will be matched to the corresponding parameter solely based on their "
"position in the function call. In this example, ``x``, ``y`` and ``z`` will "
"have the values ``1``, ``2`` and ``3``, respectively. Since we specified "
"three values, the default for the third parameter ``z`` was not actually "
"used. However, we are allowed to only specify two arguments, in which case "
"the default *will* be used as can be seen below:"
msgstr ""

#: ../docs/source/working/functions.rst:53
msgid ""
"By not specifying the third argument, the default will be used, so in this "
"case ``z`` will equal ``1``. Additionally, one can employ 'named' arguments "
"to specifically target a parameter based on its name, instead of having to "
"rely on its position:"
msgstr ""

#: ../docs/source/working/functions.rst:59
msgid ""
"Notice how the order in which we pass the arguments is irrelevant because we"
" specify the name of each argument explicitly when assigning the value. Now "
"that we know the difference between positional and named arguments, it is "
"important to realize a python requirement that **positional arguments have "
"to come before named arguments**. What this means is that *both* the "
"function definition and function call below are illegal, because there are "
"named arguments before positional ones:"
msgstr ""

#: ../docs/source/working/functions.rst:66
msgid ""
"Finally, python knows the concept of ``*args`` and ``**kwargs``, also "
"referred to as variable arguments and keyword arguments, which allow one to "
"define a function which accepts an undetermined number of positional and "
"keyword arguments."
msgstr ""

#: ../docs/source/working/functions.rst:71
msgid ""
"The variable arguments ``*args`` will receive the positionally passed "
"arguments as a tuple and the keyword arguments ``**kwargs`` will receive the"
" named arguments as a dictionary. With the formal definitions out of the "
"way, let's now see which of these concepts are supported by process "
"functions."
msgstr ""

#: ../docs/source/working/functions.rst:75
msgid "Default arguments"
msgstr ""

#: ../docs/source/working/functions.rst:76
msgid ""
"Default arguments are supported by calculation functions just as normal "
"python functions as long as it is a :py:class:`~aiida.orm.nodes.node.Node` "
"instance, just like the inputs or ``None``. However, just as with python "
"functions, one should only use immutable objects as function defaults "
"because mutable objects can give unexpected results as they will be kept "
"between function calls. Therefore, in order to use a default value for "
"process functions, simply use ``None`` as the default value and check for "
"its presence in the function body settings the default value if it is "
"``None``. This pattern looks like the following:"
msgstr ""

#: ../docs/source/working/functions.rst:84
msgid ""
"Both function calls in the example above will have the exact same result."
msgstr ""

#: ../docs/source/working/functions.rst:87
msgid "Variable and keyword arguments"
msgstr ""

#: ../docs/source/working/functions.rst:88
msgid ""
"Variable arguments are *not* supported by process functions. The reasoning "
"behind this is that the process specification for the "
":py:class:`~aiida.engine.processes.functions.FunctionProcess` is built "
"dynamically based on the function signature and so the names of the inputs "
"are based on the parameter name from the function definition, or the named "
"argument when the function is called. Since for variable arguments, neither "
"at function definition nor at function call, explicit parameter names are "
"used, the engine can impossibly determine what names, and by extensions link"
" label, to use for the inputs."
msgstr ""

#: ../docs/source/working/functions.rst:92
msgid ""
"In contrast, keyword arguments for that reason *are* supported and it is the"
" keyword used when the function is called that determines the names of the "
"parameters and the labels of the input links. The following snippet is "
"therefore perfectly legal and will return the sum of all the nodes that are "
"passed:"
msgstr ""

#: ../docs/source/working/functions.rst:98
msgid "The provenance generated by this example looks like the following:"
msgstr ""

#: ../docs/source/working/functions.rst:103
msgid ""
"The link labels of the inputs are determined based on the naming of the "
"parameters when the function is called."
msgstr ""

#: ../docs/source/working/functions.rst:105
msgid ""
"Note that the inputs **have to be passed as keyword arguments** because they"
" are used for the link labels. If the inputs would simply have been passed "
"as positional arguments, the engine could have impossibly determined what "
"label to use for the links that connect the input nodes with the calculation"
" function node. For this reason, invoking a 'dynamic' function, i.e. one "
"that supports ``**kwargs`` in its signature, with more positional arguments "
"that explicitly named in the signature, will raise a ``TypeError``."
msgstr ""

#: ../docs/source/working/functions.rst:110
msgid "Return values"
msgstr ""

#: ../docs/source/working/functions.rst:111
msgid ""
"In :numref:`fig_calculation_functions_kwargs` you can see that the engine "
"used the label ``result`` for the link connecting the calculation function "
"node with its output node. This is the default link label if only a single "
"result is returned from the calculation function. If you want to specify a "
"label yourself, you can return the result in the form of a dictionary, where"
" the key will be used as the link label. By using a dictionary you can also "
"record multiple nodes as output. Consider the following snippet:"
msgstr ""

#: ../docs/source/working/functions.rst:120
msgid ""
"The provenance generated by running this calculation function will look "
"like:"
msgstr ""

#: ../docs/source/working/functions.rst:125
msgid ""
"If a dictionary is returned, the keys will be used as the labels for the "
"links that connect the output nodes with the calculation node."
msgstr ""

#: ../docs/source/working/functions.rst:127
msgid ""
"As always, all the values returned by a calculation function have to be "
"storable, which means they have to be instances of the "
":py:class:`~aiida.orm.nodes.node.Node` class."
msgstr ""

#: ../docs/source/working/functions.rst:130
msgid ""
"It is very important that you **do not call** "
":py:meth:`~aiida.orm.nodes.node.Node.store` **yourself** on the nodes before"
" returning them from a ``calcfunction``. Because of the calculation/workflow"
" duality in AiiDA, a ``calcfunction``, which is a calculation-like process, "
"can only *create* and not *return* data nodes. This means that if a node is "
"returned from a ``calcfunction`` that *is already stored*, the engine will "
"throw an exception."
msgstr ""

#: ../docs/source/working/functions.rst:136
#: ../docs/source/working/processes.rst:224
#: ../docs/source/working/workflows.rst:109
#: ../docs/source/working/workflows.rst:274
msgid "Exit codes"
msgstr ""

#: ../docs/source/working/functions.rst:137
msgid ""
"So far we have only seen examples of calculation functions where everything "
"works out just fine. However, the real world is different, and often we will"
" encounter situations where problems arise. A calculation function may "
"receive incorrect or incoherent inputs, or the code it executes may throw an"
" exception. Of course we could throw an input validation exception or not "
"even catch the exceptions that the code we call throws, but that will lead "
"the function process to be put in the ``Excepted`` terminal state. As "
"explained in the :ref:`process state<concepts_process_state>` section, this "
"state is indeed reserved for processes that incurred an exception during "
"execution. Consider the following calculation function definition and call:"
msgstr ""

#: ../docs/source/working/functions.rst:147
msgid ""
"Because the value for ``y`` that is being passed is zero, the engine will "
"encounter a ``ZeroDivisionError`` exception when the calculation function is"
" run. The output of ``verdi process list`` will confirm that the process has"
" excepted:"
msgstr ""

#: ../docs/source/working/functions.rst:158
msgid ""
"Exceptions that occur during the execution of a process are recorded as a "
"log message on the corresponding process node. To show these log messages, "
"one can use ``verdi process report``. In the case of the example above, it "
"would look something like the following:"
msgstr ""

#: ../docs/source/working/functions.rst:177
msgid ""
"However, in this particular example the exception is not so much an "
"unexpected error, but one we could have considered and have seen coming, so "
"it might be more applicable to simply mark the process as failed. To "
"accomplish this, there is the concept of an :ref:`exit "
"status<concepts_process_exit_codes>` that can be set on the process, which "
"is an integer that, when non-zero, marks a process in the ``Finished`` state"
" as 'failed'. Since the exit status is set as an attribute on the process "
"node, it also makes it very easy to query for failed processes. To set a "
"non-zero exit status on a calculation function to indicate it as failed, "
"simply return an instance of the "
":py:class:`~aiida.engine.processes.exit_code.ExitCode` named tuple. Time for"
" a demonstration:"
msgstr ""

#: ../docs/source/working/functions.rst:186
msgid ""
"When we run the calculation function now, with the same inputs, instead of "
"excepting, the process will successfully terminate and its exit status will "
"be set to the value stored in the ``ExitCode``. The exit status is also "
"displayed by ``verdi process list``:"
msgstr ""

#: ../docs/source/working/functions.rst:198
msgid ""
"Both approaches are valid and which one to use depends on your use case. The"
" question you should ask yourself is whether a potential problem merits "
"throwing the process on the pile of 'excepted' processes. Or maybe, as in "
"the example above, the problem is easily foreseeable and classifiable with a"
" well defined exit status, in which case it might make more sense to return "
"the exit code. At the end one should think which solution makes it easier "
"for a workflow calling the function to respond based on the result and what "
"makes it easier to query for these specific failure modes."
msgstr ""

#: ../docs/source/working/functions.rst:205
msgid "Provenance"
msgstr "可验证性（Provenance）"

#: ../docs/source/working/functions.rst:206
msgid ""
"In addition to the basic attributes that are stored for all processes such "
"as the process state and label, the process functions automatically store "
"additional information that relates to the source code of the function they "
"represent:"
msgstr ""

#: ../docs/source/working/functions.rst:208
msgid "Function name"
msgstr "函数名"

#: ../docs/source/working/functions.rst:209
msgid "Function namespace"
msgstr "函数命名空间"

#: ../docs/source/working/functions.rst:210
msgid "Function starting line number"
msgstr "函数起始行号"

#: ../docs/source/working/functions.rst:211
msgid "Function source file"
msgstr "函数源文件"

#: ../docs/source/working/functions.rst:213
msgid ""
"The first three are retrieved by inspecting the python source code as soon "
"as the process function is executed and are stored as attributes on the "
"process node. They can be accessed through the corresponding properties on "
"the process node as follows:"
msgstr ""

#: ../docs/source/working/functions.rst:219
msgid ""
"The source code of the file in which the function is defined is also stored,"
" but since it can be quite big, it is stored as a raw file in the repository"
" of the process node. It can be retrieved through the "
":py:meth:`~aiida.orm.utils.mixins.FunctionCalculationMixin.get_function_source_code`"
" method."
msgstr ""

#: ../docs/source/working/functions.rst:222
msgid ""
"The attributes give some querability to the process functions stored in the "
"provenance graph and by storing the source code of the function that was "
"executed, there will be some reference in the future to track how the "
"function created its output nodes. Note, however, that just storing the "
"source file of the function does not guarantee that one can reproduce the "
"exact result. For example, one can 'leak' data into the function by reading "
"a file or loading an existing node from the database that was not explicitly"
" passed as an input. Alternatively, external code can be imported and "
"called, the source code of which will not be recorded."
msgstr ""

#: ../docs/source/working/functions.rst:228
msgid "Reproducibility guidelines"
msgstr "如何保证重现性指南"

#: ../docs/source/working/functions.rst:229
msgid ""
"Due to the nature of the way process functions are implemented, it is "
"impossible to guarantee 100% reproducibility, but by following the following"
" guidelines, one can come as close as possible."
msgstr ""

#: ../docs/source/working/functions.rst:231
msgid "Do not leak data into functions"
msgstr "不要将数据泄漏到函数中"

#: ../docs/source/working/functions.rst:232
msgid "Limit importing of external code"
msgstr "限制导入外部计算代码"

#: ../docs/source/working/functions.rst:233
msgid "Keep functions self-consistent and in separate files"
msgstr "保持函数自洽并在单独的文件中"

#: ../docs/source/working/functions.rst:235
msgid ""
"Leaking data into functions is accomplished for example by reading a file on"
" the local file system in the function body and using its contents for the "
"creation of the outputs. Even if you store the source code, if you don't "
"possess the file that was read, it is impossible to reproduce the results. "
"Likewise, you should not load any existing data from the database through "
"the API, but rather they should be direct inputs of the process function."
msgstr ""

#: ../docs/source/working/functions.rst:239
msgid ""
"A similar problem occurs when importing other python code. Practically, it "
"is almost impossible to never import code into process functions, as this "
"would force massive code duplication. However, there is still a difference "
"between importing code from the ``aiida-core`` library or the repository in "
"which the process function is hosted, and the importing of a local python "
"file. Even though for both cases there can no be guarantee of "
"reproducibility, the former stands a better chance by far, as the version "
"number of the plugin should be recorded. The rule of thumb then is to keep "
"the importing of code to a minimum, but if you have to, make sure to make it"
" part of a plugin package with a well-defined version number."
msgstr ""

#: ../docs/source/working/functions.rst:245
msgid ""
"Finally, as mentioned in the introduction, the source file of a process "
"function is stored as a file in the repository for *each execution*. "
"Currently there is no automatic deduplication for identical files by the "
"engine, so these files may occupy quite a bit of space. For this reason it "
"is advisable to keep each process function in its own separate file. This "
"not only improves readability, but it also minimizes the impact on the size "
"of the file repository."
msgstr ""

#: ../docs/source/working/processes.rst:7
msgid ""
"Before you start working with processes, make sure you have read and "
"understood the :ref:`basic concept<concepts_processes>`. This section will "
"explain the aspects of working with processes that apply to all the various "
"types of processes. Details that only pertain to a specific sub type of "
"process, will be documented in their respective sections:"
msgstr ""

#: ../docs/source/working/processes.rst:11
msgid ":ref:`calculation functions<working_calcfunctions>`"
msgstr ":ref:`算例函数<working_calcfunctions>`"

#: ../docs/source/working/processes.rst:12
msgid ":ref:`calculation jobs<working_calcjobs>`"
msgstr ":ref:`算例任务<working_calcjobs>`"

#: ../docs/source/working/processes.rst:13
msgid ":ref:`work functions<working_workfunctions>`"
msgstr ":ref:`工作流<working_workfunctions>`"

#: ../docs/source/working/processes.rst:14
msgid ":ref:`work chains<working_workchains>`"
msgstr ":ref:`工作链<working_workchains>`"

#: ../docs/source/working/processes.rst:16
msgid ""
"Since all of these are types of processes, everything that will be explained"
" in this section, will apply to each and everyone of them. That makes it "
"very useful to read and understand this section well, as the concepts apply "
"so broadly. However, for the same reason, at times this section may feel a "
"bit abstract. It may therefore be advisable to start reading a section on "
"one of the more specific processes listed above first, to get a more "
"concrete example, and then simply refer back here for a more extensive "
"explanation of the details."
msgstr ""

#: ../docs/source/working/processes.rst:25
msgid "Defining processes"
msgstr "定义例程"

#: ../docs/source/working/processes.rst:30
msgid "Process specification"
msgstr "例程规格"

#: ../docs/source/working/processes.rst:31
msgid ""
"How a process defines the inputs that it requires or can optionally take, "
"depends on the process type. The inputs of "
":py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` and "
":py:class:`~aiida.engine.processes.workchains.workchain.WorkChain` are given"
" by the :py:class:`~aiida.engine.processes.process_spec.ProcessSpec` class, "
"which is defined though  the "
":py:meth:`~aiida.engine.processes.process.Process.define` method. For "
"process functions, the "
":py:class:`~aiida.engine.processes.process_spec.ProcessSpec` is dynamically "
"generated by the engine from the signature of the decorated function. "
"Therefore, to determine what inputs a process takes, one simply has to look "
"at the process specification in the ``define`` method or the function "
"signature. For the "
":py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` and "
":py:class:`~aiida.engine.processes.workchains.workchain.WorkChain` there is "
"also the concept of the :ref:`process builder<working_processes_builder>`, "
"which will allow one to inspect the inputs with tab-completion and help "
"strings in the shell."
msgstr ""

#: ../docs/source/working/processes.rst:37
msgid ""
"The three most important attributes of the "
":py:class:`~aiida.engine.processes.process_spec.ProcessSpec` are:"
msgstr ""

#: ../docs/source/working/processes.rst:39
msgid "``inputs``"
msgstr "``inputs``"

#: ../docs/source/working/processes.rst:40
msgid "``outputs``"
msgstr "``outputs``"

#: ../docs/source/working/processes.rst:41
msgid "``exit_codes``"
msgstr "``exit_codes``"

#: ../docs/source/working/processes.rst:43
msgid ""
"Through these attributes, one can define what inputs a process takes, what "
"outputs it will produce and what potential exit codes it can return in case "
"of errors. Just by looking at a process specification then, one will know "
"exactly *what* will happen, just not *how* it will happen. The ``inputs`` "
"and ``outputs`` attributes are *namespaces* that contain so called *ports*, "
"each one of which represents a specific input or output. The namespaces can "
"be arbitrarily nested with ports and so are called *port namespaces*. The "
"port and port namespace are implemented by the :py:class:`~plumpy.Port` and "
":py:class:`~aiida.engine.processes.ports.PortNamespace` class, respectively."
msgstr ""

#: ../docs/source/working/processes.rst:53
msgid "Ports and Port namespaces"
msgstr "端口和端口命名空间"

#: ../docs/source/working/processes.rst:54
msgid ""
"To define an input for a process specification, we only need to add a port "
"to the ``inputs`` port namespace, as follows:"
msgstr ""

#: ../docs/source/working/processes.rst:61
msgid ""
"The ``input`` method, will create an instance of "
":py:class:`~aiida.engine.processes.ports.InputPort`, a sub class of the base"
" :py:class:`~plumpy.Port`, and will add it to the ``inputs`` port namespace "
"of the spec. Creating an output is just as easy, but one should use the "
":py:meth:`~plumpy.ProcessSpec.output` method instead:"
msgstr ""

#: ../docs/source/working/processes.rst:69
msgid ""
"This will cause an instance of "
":py:class:`~aiida.engine.processes.ports.OutputPort`, also a sub class of "
"the base :py:class:`~plumpy.Port`, to be created and to be added to the "
"``outputs`` specifcation attribute. Recall, that the ``inputs`` and "
"``output`` are instances of a "
":py:class:`~aiida.engine.processes.ports.PortNamespace`, which means that "
"they can contain any port. But the "
":py:class:`~aiida.engine.processes.ports.PortNamespace` itself is also a "
"port itself, so it can be added to another port namespace, allowing one to "
"create nested port namespaces. Creating a new namespace in for example the "
"inputs namespace is as simple as:"
msgstr ""

#: ../docs/source/working/processes.rst:79
msgid ""
"This will create a new ``PortNamespace`` named ``namespace`` in the "
"``inputs`` namespace of the spec. You can create arbitrarily nested "
"namespaces in one statement, by separating them with a ``.`` as shown here:"
msgstr ""

#: ../docs/source/working/processes.rst:87
msgid ""
"This command will result in the ``PortNamespace`` name ``namespace`` to be "
"nested inside another ``PortNamespace`` called ``nested``."
msgstr ""

#: ../docs/source/working/processes.rst:91
msgid ""
"Because the period is reserved to denote different nested namespaces, it "
"cannot be used in the name of terminal input and output ports as that could "
"be misinterpreted later as a port nested in a namespace."
msgstr ""

#: ../docs/source/working/processes.rst:93
msgid ""
"Graphically, this can be visualized as a nested dictionary and will look "
"like the following:"
msgstr ""

#: ../docs/source/working/processes.rst:103
msgid ""
"The ``outputs`` attribute of the ``ProcessSpec`` is also a ``PortNamespace``"
" just as the ``inputs``, with the only different that it will create "
"``OutputPort`` instead of ``InputPort`` instances. Therefore the same "
"concept of nesting through ``PortNamespaces`` applies to the outputs of a "
"``ProcessSpec``."
msgstr ""

#: ../docs/source/working/processes.rst:110
msgid "Validation and defaults"
msgstr "自动校验和默认值"

#: ../docs/source/working/processes.rst:111
msgid ""
"In the previous section, we saw that the ``ProcessSpec`` uses the "
"``PortNamespace``, ``InputPort`` and ``OutputPort`` to define the inputs and"
" outputs structure of the ``Process``. The underlying concept that allows "
"this nesting of ports is that the ``PortNamespace``, ``InputPort`` and "
"``OutputPort``, are all a subclass of :py:class:`~plumpy.ports.Port`. And as"
" different subclasses of the same class, they have more properties and "
"attributes in common, for example related to the concept of validation and "
"default values. All three have the following attributes (with the exception "
"of the ``OutputPort`` not having a ``default`` attribute):"
msgstr ""

#: ../docs/source/working/processes.rst:116
msgid "``default``"
msgstr "``default``"

#: ../docs/source/working/processes.rst:117
msgid "``required``"
msgstr "``required``"

#: ../docs/source/working/processes.rst:118
msgid "``valid_type``"
msgstr "``valid_type``"

#: ../docs/source/working/processes.rst:119
msgid "``validator``"
msgstr "``validator``"

#: ../docs/source/working/processes.rst:121
msgid ""
"These attributes can all be set upon construction of the port or after the "
"fact, as long as the spec has not been sealed, which means that they can be "
"altered without limit as long as it is within the ``define`` method of the "
"corresponding ``Process``. An example input port that explicitly sets all "
"these attributes is the following:"
msgstr ""

#: ../docs/source/working/processes.rst:128
msgid ""
"Here we define an input named ``positive_number`` that should be of type "
"``Int`` or ``Float`` and should pass the test of the ``is_number_positive`` "
"validator. If no value is passed, the default will be used."
msgstr ""

#: ../docs/source/working/processes.rst:133
msgid ""
"In python, it is good practice to avoid mutable defaults for function "
"arguments, `since they are instantiated at function definition and reused "
"for each invocation <https://docs.python.org/3/reference/compound_stmts.html"
"#function-definitions>`_. This can lead to unexpected results when the "
"default value is changed between function calls. In the context of AiiDA, "
"nodes (both stored and unstored) are considered *mutable* and should "
"therefore *not* be used as default values for process ports. However, it is "
"possible to use a lambda that returns a node instance as done in the example"
" above. This will return a new instance of the node with the given value, "
"each time the process is instantiated."
msgstr ""

#: ../docs/source/working/processes.rst:139
msgid ""
"Note that the validator is nothing more than a free function which takes a "
"single argument, being the value that is to be validated. If nothing is "
"returned, the value is considered to be valid. To signal that the value is "
"invalid and to have a validation error raised, simply return a string with "
"the validation error message, for example:"
msgstr ""

#: ../docs/source/working/processes.rst:149
msgid ""
"The ``valid_type`` can define a single type, or a tuple of valid types."
msgstr ""

#: ../docs/source/working/processes.rst:153
msgid ""
"Note that by default all ports are required, but specifying a default value "
"implies that the input is not required and as such specifying "
"``required=False`` is not necessary in that case. It was added to the "
"example above simply for clarity."
msgstr ""

#: ../docs/source/working/processes.rst:156
msgid ""
"The validation of input or output values with respect to the specification "
"of the corresponding port, happens at the instantiation of the process and "
"when it is finalized, respectively. If the inputs are invalid, a "
"corresponding exception will be thrown and the process instantiation will "
"fail. When the outputs fail to be validated, likewise an exception will be "
"thrown and the process state will be set to ``Excepted``."
msgstr ""

#: ../docs/source/working/processes.rst:164
msgid "Dynamic namespaces"
msgstr "动态命名空间"

#: ../docs/source/working/processes.rst:165
msgid ""
"In the previous section we described the various attributes related to "
"validation and claimed that all the port variants share those attributes, "
"yet we only discussed the ``InputPort`` and ``OutputPort`` explicitly. The "
"statement, however, is still correct and the ``PortNamespace`` has the same "
"attributes. You might then wonder what the meaning is of a ``valid_type`` or"
" ``default`` for a ``PortNamespace`` if all it does is contain "
"``InputPorts``, ``OutputPorts`` or other ``PortNamespaces``. The answer to "
"this question lies in the ``PortNamespace`` attribute ``dynamic``."
msgstr ""

#: ../docs/source/working/processes.rst:170
msgid ""
"Often when designing the specification of a ``Process``, we cannot know "
"exactly which inputs we want to be able to pass to the process. However, "
"with the concept of the ``InputPort`` and ``OutputPort`` one *does* need to "
"know exactly, how many value one expects at least, as they do have to be "
"defined. This is where the ``dynamic`` attribute of the ``PortNamespace`` "
"comes in. By default this is set to ``False``, but by setting it to "
"``True``, one indicates that that namespace can take a number of values that"
" is unknown at the time of definition of the specification. This now "
"explains the meaning of the ``valid_type``, ``validator`` and ``default`` "
"attributes in the context of the ``PortNamespace``. If you do mark a "
"namespace as dynamic, you may still want to limit the set of values that are"
" acceptable, which you can do by specifying the valid type and or validator."
" The values that will eventually be passed to the port namespace will then "
"be validated according to these rules exactly as a value for a regular input"
" port would be."
msgstr ""

#: ../docs/source/working/processes.rst:182
msgid "Non storable inputs"
msgstr "不存取的输入"

#: ../docs/source/working/processes.rst:183
msgid ""
"In principle, the only valid types for inputs and outputs should be "
"instances of a :py:class:`~aiida.orm.nodes.data.data.Data` node, or one of "
"its sub classes, as that is the only data type that can be recorded in the "
"provenance graph as an input or output of a process. However, there are "
"cases where you might want to pass an input to a process, whose provenance "
"you do not care about and therefore would want to pass a non-database "
"storable type anyway."
msgstr ""

#: ../docs/source/working/processes.rst:188
msgid ""
"AiiDA allows you to break the provenance as to be not too restrictive, but "
"always tries to urge you and guide you in a direction to keep the "
"provenance. There are legitimate reasons to break it regardless, but make "
"sure you think about the implications and whether you are really willing to "
"lose the information."
msgstr ""

#: ../docs/source/working/processes.rst:191
msgid ""
"For this situation, the ``InputPort`` has the attribute ``non_db``. By "
"default this is set to ``False``, but by setting it to ``True`` the port is "
"marked that the values that are passed to it should not be stored as a node "
"in the provenance graph and linked to the process node. This allows one to "
"pass any normal value that one would also be able to pass to a normal "
"function."
msgstr ""

#: ../docs/source/working/processes.rst:199
msgid "Automatic input serialization"
msgstr ""

#: ../docs/source/working/processes.rst:201
msgid ""
"Quite often, inputs which are given as python data types need to be cast to "
"the corresponding AiiDA type before passing them to a process. Doing this "
"manually can be cumbersome, so you can define a function when defining the "
"process specification, which does the conversion automatically. This "
"function, passed as ``serializer`` parameter to ``spec.input``, is invoked "
"if the given input is *not* already an AiiDA type."
msgstr ""

#: ../docs/source/working/processes.rst:205
msgid ""
"For inputs which are stored in the database (``non_db=False``), the "
"serialization function should return an AiiDA data type. For ``non_db`` "
"inputs, the function must be idempotent because it might be applied more "
"than once."
msgstr ""

#: ../docs/source/working/processes.rst:208
msgid ""
"The following example work chain takes three inputs ``a``, ``b``, ``c``, and"
" simply returns the given inputs. The "
":func:`aiida.orm.nodes.data.base.to_aiida_type` function is used as "
"serialization function."
msgstr ""

#: ../docs/source/working/processes.rst:213
msgid ""
"This work chain can now be called with native Python types, which will "
"automatically converted to AiiDA types by the "
":func:`aiida.orm.nodes.data.base.to_aiida_type` function. Note that the "
"module which defines the corresponding AiiDA type must be loaded for it to "
"be recognized by :func:`aiida.orm.nodes.data.base.to_aiida_type`."
msgstr ""

#: ../docs/source/working/processes.rst:218
msgid ""
"Of course, you can also use the serialization feature to perform a more "
"complex serialization of the inputs."
msgstr ""

#: ../docs/source/working/processes.rst:225
msgid ""
"Any ``Process`` most likely will have one or multiple expected failure "
"modes. To clearly communicate to the caller what went wrong, the ``Process``"
" supports setting its ``exit_status``. This ``exit_status``, a positive "
"integer, is an attribute of the process node and by convention, when it is "
"zero means the process was successful, whereas any other value indicates "
"failure. This concept of an exit code, with a positive integer as the exit "
"status, `is a common concept in programming <https://shapeshed.com/unix-"
"exit-codes/>`_ and a standard way for programs to communicate the result of "
"their execution."
msgstr ""

#: ../docs/source/working/processes.rst:230
msgid ""
"Potential exit codes for the ``Process`` can be defined through the "
"``ProcessSpec``, just like inputs and ouputs. Any exit code consists of a "
"positive non-zero integer, a string label to reference it and a more "
"detailed description of the problem that triggers the exit code. Consider "
"the following example:"
msgstr ""

#: ../docs/source/working/processes.rst:239
msgid ""
"This defines an exit code for the ``Process`` with exit status ``418`` and "
"exit message ``the work chain had an identity crisis``. The string "
"``ERROR_I_AM_A_TEAPOT`` is a label that the developer can use to reference "
"this particular exit code somewhere in the ``Process`` code itself."
msgstr ""

#: ../docs/source/working/processes.rst:242
msgid ""
"Whenever a ``Process`` exits through a particular error code, the caller "
"will be able to introspect it through the ``exit_status`` and "
"``exit_message`` attributes of the node. Assume for example that we ran a "
"``Process`` that threw the exit code described above, the caller would be "
"able to do the following:"
msgstr ""

#: ../docs/source/working/processes.rst:253
msgid ""
"This is useful, because the caller can now programmatically, based on the "
"``exit_status``, decide how to proceed. This is an infinitely more robust "
"way of communcating specific errors to a non-human then parsing text based "
"logs or reports. Additionally, The exit codes make it also very easy to "
"query for failed processes with specific error codes."
msgstr ""

#: ../docs/source/working/processes.rst:261
msgid "Exit code conventions"
msgstr ""

#: ../docs/source/working/processes.rst:262
msgid ""
"In principle, the only restriction on the exit status of an exit code is "
"that it should be a positive integer or zero. However, to make effective use"
" of exit codes, there are some guidelines and conventions as to decide what "
"integers to use. Note that since the following rules are *guidelines* you "
"can choose to ignore them and currently the engine will not complain, but "
"this might change in the future. Regardless, we advise you to follow the "
"guidelines since it will improve the interoperability of your code with "
"other existing plugins. The following integer ranges are reserved or "
"suggested:"
msgstr ""

#: ../docs/source/working/processes.rst:268
msgid "0 -  99: Reserved for internal use by `aiida-core`"
msgstr ""

#: ../docs/source/working/processes.rst:269
msgid ""
"100 - 199: Reserved for errors parsed from scheduler output of calculation "
"jobs (note: this is not yet implemented)"
msgstr ""

#: ../docs/source/working/processes.rst:270
msgid "200 - 299: Suggested to be used for process input validation errors"
msgstr ""

#: ../docs/source/working/processes.rst:271
msgid "300 - 399: Suggested for critical process errors"
msgstr ""

#: ../docs/source/working/processes.rst:273
msgid "For any other exit codes, one can use the integers from 400 and up."
msgstr ""

#: ../docs/source/working/processes.rst:279
msgid "Process metadata"
msgstr "例程元数据"

#: ../docs/source/working/processes.rst:281
msgid ""
"Each process, in addition to the normal inputs defined through its process "
"specifcation, can take optional 'metadata'. These metadata differ from "
"inputs in the sense that they are not nodes that will show up as inputs in "
"the provenance graph of the executed process. Rather, these are inputs that "
"slightly modify the behavior of the process or allow to set attributes on "
"the process node that represents its execution. The following metadata "
"inputs are available for *all* process classes:"
msgstr ""

#: ../docs/source/working/processes.rst:286
msgid "``label``: will set the label on the ``ProcessNode``"
msgstr ""

#: ../docs/source/working/processes.rst:287
msgid "``description``: will set the description on the ``ProcessNode``"
msgstr ""

#: ../docs/source/working/processes.rst:288
msgid ""
"``store_provenance``: boolean flag, by default ``True``, that when set to "
"``False``, will ensure that the execution of the process **is not** stored "
"in the provenance graph"
msgstr ""

#: ../docs/source/working/processes.rst:290
msgid ""
"Sub classes of the :py:class:`~aiida.engine.processes.process.Process` class"
" can specify further metadata inputs, refer to their specific documentation "
"for details. To pass any of these metadata options to a process, simply pass"
" them in a dictionary under the key ``metadata`` in the inputs when "
"launching the process. How a process can be launched is explained the "
"following section."
msgstr ""

#: ../docs/source/working/processes.rst:298
msgid "Launching processes"
msgstr "启动例程"

#: ../docs/source/working/processes.rst:299
msgid ""
"Any process can be launched by 'running' or 'submitting' it. Running means "
"to run the process in the current python interpreter in a blocking way, "
"whereas submitting means to send it to a daemon worker over RabbitMQ. For "
"long running processes, such as calculation jobs or complex workflows, it is"
" best advised to submit to the daemon. This has the added benefit that it "
"will directly return control to your interpreter and allow the daemon to "
"save intermediate progress during checkpoints and reload the process from "
"those if it has to restart. Running processes can be useful for trivial "
"computational tasks, such as simple calcfunctions or workfunctions, or for "
"debugging and testing purposes."
msgstr ""

#: ../docs/source/working/processes.rst:309
msgid "Process launch"
msgstr "例程启动"

#: ../docs/source/working/processes.rst:311
msgid ""
"To launch a process, one can use the free functions that can be imported "
"from the :py:mod:`aiida.engine` module. There are four different functions:"
msgstr ""

#: ../docs/source/working/processes.rst:314
msgid ":py:func:`~aiida.engine.launch.run`"
msgstr ":py:func:`~aiida.engine.launch.run`"

#: ../docs/source/working/processes.rst:315
msgid ":py:func:`~aiida.engine.launch.run_get_node`"
msgstr ":py:func:`~aiida.engine.launch.run_get_node`"

#: ../docs/source/working/processes.rst:316
msgid ":py:func:`~aiida.engine.launch.run_get_pk`"
msgstr ":py:func:`~aiida.engine.launch.run_get_pk`"

#: ../docs/source/working/processes.rst:317
msgid ":py:func:`~aiida.engine.launch.submit`"
msgstr ":py:func:`~aiida.engine.launch.submit`"

#: ../docs/source/working/processes.rst:319
msgid ""
"As the name suggest, the first three will 'run' the process and the latter "
"will 'submit' it to the daemon. Running means that the process will be "
"executed in the same interpreter in which it is launched, blocking the "
"interpreter, until the process is terminated. Submitting to the daemon, in "
"contrast, means that the process will be sent to the daemon for execution, "
"and the interpreter is released straight away."
msgstr ""

#: ../docs/source/working/processes.rst:323
msgid ""
"All functions have the exact same interface ``launch(process, **inputs)`` "
"where:"
msgstr ""

#: ../docs/source/working/processes.rst:325
msgid "``process`` is the process class or process function to launch"
msgstr ""

#: ../docs/source/working/processes.rst:326
msgid "``inputs`` are the inputs as keyword arguments to pass to the process."
msgstr ""

#: ../docs/source/working/processes.rst:328
msgid ""
"What inputs can be passed depends on the exact process class that is to be "
"launched. For example, when we want to run an instance of the "
":py:class:`~aiida.calculations.plugins.arithmetic.add.ArithmeticAddCalculation`"
" process, which takes two :py:class:`~aiida.orm.nodes.data.int.Int` nodes as"
" inputs under the name ``x`` and ``y`` [#f1]_, we would do the following:"
msgstr ""

#: ../docs/source/working/processes.rst:334
msgid ""
"The function will submit the calculation to the daemon and immediately "
"return control to the interpreter, returning the node that is used to "
"represent the process in the provenance graph."
msgstr ""

#: ../docs/source/working/processes.rst:337
msgid ""
"Process functions, i.e. python functions decorated with the ``calcfunction``"
" or ``workfunction`` decorators, **cannot be submitted** but can only be "
"run."
msgstr ""

#: ../docs/source/working/processes.rst:339
msgid "The ``run`` function is called identically:"
msgstr ""

#: ../docs/source/working/processes.rst:344
msgid ""
"except that it does not submit the process to the daemon, but executes it in"
" the current interpreter, blocking it until the process is terminated. The "
"return value of the ``run`` function is also **not** the node that "
"represents the executed process, but the results returned by the process, "
"which is a dictionary of the nodes that were produced as outputs. If you "
"would still like to have the process node or the pk of the process node you "
"can use one of the following variants:"
msgstr ""

#: ../docs/source/working/processes.rst:351
msgid ""
"Finally, the :py:func:`~aiida.engine.launch.run` launcher has two attributes"
" ``get_node`` and ``get_pk`` that are simple proxies to the "
":py:func:`~aiida.engine.launch.run_get_node` and "
":py:func:`~aiida.engine.launch.run_get_pk` methods. This is a handy "
"shortcut, as now you can choose to use any of the three variants with just a"
" single import:"
msgstr ""

#: ../docs/source/working/processes.rst:357
msgid ""
"If you want to launch a process class that takes a lot more inputs, often it"
" is useful to define them in a dictionary and use the python syntax ``**`` "
"that automatically expands it into keyword argument and value pairs. The "
"examples used above would look like the following:"
msgstr ""

#: ../docs/source/working/processes.rst:363
msgid ""
"Process functions, i.e. :ref:`calculation functions<concepts_calcfunctions>`"
" and :ref:`work functions<concepts_workfunctions>`, can be launched like any"
" other process as explained above, with the only exception that they "
"**cannot be submitted**. In addition to this limitation, process functions "
"have two additional methods of being launched:"
msgstr ""

#: ../docs/source/working/processes.rst:366
msgid "Simply *calling* the function"
msgstr "只需*调用*函数"

#: ../docs/source/working/processes.rst:367
msgid "Using the internal run method attributes"
msgstr "使用内部运行方法的属性"

#: ../docs/source/working/processes.rst:369
msgid ""
"Using a calculation function to add two numbers as an example, these two "
"methods look like the following:"
msgstr ""

#: ../docs/source/working/processes.rst:378
msgid "Process builder"
msgstr "例程构建器"

#: ../docs/source/working/processes.rst:379
msgid ""
"As explained in a :ref:`previous section<working_processes_spec>`, the "
"inputs for a :py:class:`~aiida.engine.processes.calcjobs.calcjob.CalcJob` "
"and :py:class:`~aiida.engine.processes.workchains.workchain.WorkChain` are "
"defined in the :py:meth:`~aiida.engine.processes.process.Process.define` "
"method. To know then what inputs they take, one would have to read the "
"implementation, which can be annoying if you are not a developer. To "
"simplify this process, these two process classes provide a utility called "
"the 'process builder'. The process builder is essentially a tool that helps "
"you build the inputs for the specific process class that you want to run. To"
" get a *builder* for a particular ``CalcJob`` or a ``WorkChain`` "
"implementation, all you need is the class itself, which can be loaded "
"through the :py:class:`~aiida.plugins.factories.CalculationFactory` and "
":py:class:`~aiida.plugins.factories.WorkflowFactory`, respectively. Let's "
"take the "
":py:class:`~aiida.calculations.plugins.arithmetic.add.ArithmeticAddCalculation`"
" as an example::"
msgstr ""

#: ../docs/source/working/processes.rst:389
msgid ""
"The string ``arithmetic.add`` is the entry point of the "
"``ArithmeticAddCalculation`` and passing it to the ``CalculationFactory`` "
"will return the corresponding class. Calling the ``get_builder`` method on "
"that class will return an instance of the "
":py:class:`~aiida.engine.processes.builder.ProcessBuilder` class that is "
"tailored for the ``ArithmeticAddCalculation``. The builder will help you in "
"defining the inputs that the ``ArithmeticAddCalculation`` requires and has a"
" few handy tools to simplify this process."
msgstr ""

#: ../docs/source/working/processes.rst:393
msgid ""
"To find out which inputs the builder exposes, you can simply use tab "
"completion. In an interactive python shell, by simply typing ``builder.`` "
"and hitting the tab key, a complete list of all the available inputs will be"
" shown. Each input of the builder can also show additional information about"
" what sort of input it expects. In an interactive shell, you can get this "
"information to display as follows::"
msgstr ""

#: ../docs/source/working/processes.rst:408
msgid ""
"In the ``Docstring`` you will see a ``help`` string that contains more "
"detailed information about the input port. Additionally, it will display a "
"``valid_type``, which when defined shows which data types are expected. If a"
" default value has been defined, that will also be displayed. The ``non_db``"
" attribute defines whether that particular input will be stored as a proper "
"input node in the database, if the process is submitted."
msgstr ""

#: ../docs/source/working/processes.rst:413
msgid ""
"Defining an input through the builder is as simple as assigning a value to "
"the attribute. The following example shows how to set the ``parameters`` "
"input, as well as the ``description`` and ``label`` metadata inputs::"
msgstr ""

#: ../docs/source/working/processes.rst:421
msgid ""
"If you evaluate the ``builder`` instance, simply by typing the variable name"
" and hitting enter, the current values of the builder's inputs will be "
"displayed::"
msgstr ""

#: ../docs/source/working/processes.rst:434
msgid ""
"In this example, you can see the value that we just set for the "
"``description`` and the ``label``. In addition, it will also show any "
"namespaces, as the inputs of processes support nested namespaces, such as "
"the ``metadata.options`` namespace in this example. Note that nested "
"namespaces are also all autocompleted, and you can traverse them recursively"
" with tab-completion."
msgstr ""

#: ../docs/source/working/processes.rst:438
msgid ""
"All that remains is to fill in all the required inputs and we are ready to "
"launch the process builder. When all the inputs have been defined for the "
"builder, it can be used to actually launch the ``Process``. The process can "
"be launched by passing the builder to any of the free functions "
":py:mod:`~aiida.engine.launch` module, just as you would do a normal process"
" as :ref:`described above<working_processes_launching>`, i.e.:"
msgstr ""

#: ../docs/source/working/processes.rst:445
msgid ""
"Note that the process builder is in principle designed to be used in an "
"interactive shell, as there is where the tab-completion and automatic input "
"documentation really shines. However, it is perfectly possible to use the "
"same builder in scripts where you simply use it as an input container, "
"instead of a plain python dictionary."
msgstr ""

#: ../docs/source/working/processes.rst:452
msgid "Monitoring processes"
msgstr "监控例程"

#: ../docs/source/working/processes.rst:453
msgid ""
"When you have launched a process, you may want to investigate its status, "
"progression and the results. The :ref:`verdi<verdi_overview>` command line "
"tool provides various commands to do just this."
msgstr ""

#: ../docs/source/working/processes.rst:460
msgid "verdi process list"
msgstr "verdi process list"

#: ../docs/source/working/processes.rst:461
msgid ""
"Your first point of entry will be the ``verdi`` command ``verdi process "
"list``. This command will print a list of all active processes through the "
"``ProcessNode`` stored in the database that it uses to represent its "
"execution. A typical example may look something like the following:"
msgstr ""

#: ../docs/source/working/processes.rst:475
msgid ""
"The 'State' column is a concatenation of the ``process_state`` and the "
"``exit_status`` of the ``ProcessNode``. By default, the command will only "
"show active items, i.e. ``ProcessNodes`` that have not yet reached a "
"terminal state. If you want to also show the nodes in a terminal states, you"
" can use the ``-a`` flag and call ``verdi process list -a``:"
msgstr ""

#: ../docs/source/working/processes.rst:491
msgid ""
"For more information on the meaning of the 'state' column, please refer to "
"the documentation of the :ref:`process state <concepts_process_state>`. The "
"``-S`` flag let's you query for specific process states, i.e. issuing "
"``verdi process list -S created`` will return:"
msgstr ""

#: ../docs/source/working/processes.rst:503
msgid ""
"To query for a specific exit status, one can use ``verdi process list -E "
"0``:"
msgstr ""

#: ../docs/source/working/processes.rst:515
msgid ""
"This simple tool should give you a good idea of the current status of "
"running processes and the status of terminated ones. For a complete list of "
"all the available options, please refer to the documentation of :ref:`verdi "
"process<verdi_process>`."
msgstr ""

#: ../docs/source/working/processes.rst:518
msgid ""
"If you are looking for information about a specific process node, the "
"following three commands are at your disposal:"
msgstr ""

#: ../docs/source/working/processes.rst:520
msgid ""
"``verdi process report`` gives a list of the log messages attached to the "
"process"
msgstr ""

#: ../docs/source/working/processes.rst:521
msgid ""
"``verdi process status`` print the call hierarchy of the process and status "
"of all its nodes"
msgstr ""

#: ../docs/source/working/processes.rst:522
msgid ""
"``verdi process show`` print details about the status, inputs, outputs, "
"callers and callees of the process"
msgstr ""

#: ../docs/source/working/processes.rst:524
msgid ""
"In the following sections, we will explain briefly how the commands work. "
"For the purpose of example, we will show the output of the commands for a "
"completed ``PwBaseWorkChain`` from the ``aiida-quantumespresso`` plugin, "
"which simply calls a ``PwCalculation``."
msgstr ""

#: ../docs/source/working/processes.rst:531
msgid "verdi process report"
msgstr "verdi process report"

#: ../docs/source/working/processes.rst:532
msgid ""
"The developer of a process can attach log messages to the node of a process "
"through the :py:meth:`~aiida.engine.processes.process.Process.report` "
"method. The ``verdi process report`` command will display all the log "
"messages in chronological order:"
msgstr ""

#: ../docs/source/working/processes.rst:542
msgid ""
"The log message will include a timestamp followed by the level of the log, "
"which is always ``REPORT``. The second block has the format ``pk|class "
"name|function name`` detailing information about, in this case, the work "
"chain itself and the step in which the message was fired. Finally, the "
"message itself is displayed. Of course how many messages are logged and how "
"useful they are is up to the process developer. In general they can be very "
"useful for a user to understand what has happened during the execution of "
"the process, however, one has to realize that each entry is stored in the "
"database, so overuse can unnecessarily bloat the database."
msgstr ""

#: ../docs/source/working/processes.rst:552
msgid "verdi process status"
msgstr "verdi process status"

#: ../docs/source/working/processes.rst:553
msgid ""
"This command is most useful for ``WorkChain`` instances, but also works for "
"``CalcJobs``. One of the more powerful aspect of work chains, is that they "
"can call ``CalcJobs`` and other ``WorkChains`` to create a nested call "
"hierarchy. If you want to inspect the status of a work chain and all the "
"children that it called, ``verdi process status`` is the go-to tool. An "
"example output is the following:"
msgstr ""

#: ../docs/source/working/processes.rst:563
msgid ""
"The command prints a tree representation of the hierarchical call structure,"
" that recurses all the way down. In this example, there is just a single "
"``PwBaseWorkChain`` which called a ``PwCalculation``, which is indicated by "
"it being indented one level. In addition to the call tree, each node also "
"shows its current process state and for work chains at which step in the "
"outline it is. This tool can be very useful to inspect while a work chain is"
" running at which step in the outline it currently is, as well as the status"
" of all the children calculations it called."
msgstr ""

#: ../docs/source/working/processes.rst:572
msgid "verdi process show"
msgstr "verdi process show"

#: ../docs/source/working/processes.rst:573
msgid ""
"Finally, there is a command that displays detailed information about the "
"``ProcessNode``, such as its inputs, outputs and the optional other "
"processes it called and or was called by. An example output for a "
"``PwBaseWorkChain`` would look like the following:"
msgstr ""

#: ../docs/source/working/processes.rst:617
msgid ""
"This overview should give you all the information if you want to inspect a "
"process' inputs and outputs in closer detail as it provides you their pk's."
msgstr ""

#: ../docs/source/working/processes.rst:623
msgid "Manipulating processes"
msgstr "操控例程"

#: ../docs/source/working/processes.rst:624
msgid ""
"To understand how one can manipulate running processes, one has to "
"understand the principles of the :ref:`process/node "
"distinction<concepts_process_node_distinction>` and a :ref:`process' "
"lifetime<concepts_process_lifetime>` first, so be sure to have read those "
"sections first."
msgstr ""

#: ../docs/source/working/processes.rst:630
msgid "verdi process pause/play/kill"
msgstr "verdi process pause/play/kill"

#: ../docs/source/working/processes.rst:631
msgid ""
"The ``verdi`` command line interface provides three commands to interact "
"with 'live' processes."
msgstr ""

#: ../docs/source/working/processes.rst:633
msgid "``verdi process pause``"
msgstr "``verdi process pause``"

#: ../docs/source/working/processes.rst:634
msgid "``verdi process play``"
msgstr "``verdi process play``"

#: ../docs/source/working/processes.rst:635
msgid "``verdi process kill``"
msgstr "``verdi process kill``"

#: ../docs/source/working/processes.rst:637
msgid ""
"The first pauses a process temporarily, the second resumes any paused "
"processes and the third one permanently kills them. The sub command names "
"might seem to tell you this already and it might look like that is all there"
" is to know, but the functionality underneath is quite complicated and "
"deserves additional explanation nonetheless."
msgstr ""

#: ../docs/source/working/processes.rst:640
msgid ""
"As the section on :ref:`the distinction between the process and the "
"node<concepts_process_node_distinction>` explained, manipulating a process "
"means interacting with the live process instance that lives in the memory of"
" the runner that is running it. By definition, these runners will always run"
" in a different system process then the one from which you want to interact,"
" because otherwise, you would *be* the runner, given that there can only be "
"a single runner in an interpreter and if it is running, the interpreter "
"would be blocked from performing any other operations. This means that in "
"order to interact with the live process, one has to interact with another "
"interpreter running in a different system process. This is once again "
"facilitated by the RabbitMQ message broker. When a runner starts to run a "
"process, it will also add listeners for incoming messages that are being "
"sent for that specific process over RabbitMQ."
msgstr ""

#: ../docs/source/working/processes.rst:648
msgid ""
"This does not just apply to daemon runners, but also normal runners. That is"
" to say that if you were to launch a process in a local runner, that "
"interpreter will be blocked, but it will still setup the listeners for that "
"process on RabbitMQ. This means that you can manipulate the process from "
"another terminal, just as if you would do with a process that is being run "
"by a daemon runner."
msgstr ""

#: ../docs/source/working/processes.rst:652
msgid ""
"In the case of 'pause', 'play' and 'kill', one is sending what is called a "
"Remote Procedure Call (RPC) over RabbitMQ. The RPC will include the process "
"identifier for which the action is intended and RabbitMQ will send it to "
"whoever registered itself to be listening for that specific process, in this"
" case the runner that is running the process. This immediately reveals a "
"potential problem: the RPC will fall on deaf ears if there is no one "
"listening, which can have multiple causes. For example, as explained in the "
"section on a :ref:`process' lifetime<concepts_process_lifetime>`, this can "
"be the case for a submitted process, where the corresponding task is still "
"queued, as all available process slots are occupied. But even if the task "
"*were* to be with a runner, it might be too busy to respond to the RPC and "
"the process appears to be unreachable. Whenever a process is unreachable for"
" an RPC, the command will return an error:"
msgstr ""

#: ../docs/source/working/processes.rst:663
msgid ""
"Depending on the cause of the process being unreachable, the problem may "
"resolve itself automatically over time and one can try again at a later "
"time, as for example in the case of the runner being too busy to respond. "
"However, to prevent this from happening, the runner has been designed to "
"have the communication happen over a separate thread and to schedule "
"callbacks for any necessary actions on the main thread, which performs all "
"the heavy lifting. This should make occurrences of the runner being too busy"
" to respond very rare. If you think the The problem is, however, there is "
"unfortunately no way of telling what the actual problem is for the process "
"not being reachable. The problem will manifest itself identically if the "
"runner just could not respond in time or if the task has accidentally been "
"lost forever due to a bug, even though these are two completely separate "
"situations."
msgstr ""

#: ../docs/source/working/processes.rst:670
msgid ""
"This brings us to another potential unintuitive aspect of interacting with "
"processes. The previous paragraph already mentioned it in passing, but when "
"a remote procedure call is sent, it first needs to be answered by the "
"responsible runner, if applicable, but it will not *directly execute* the "
"call. This is because the call will be incoming on the communcation thread "
"who is not allowed to have direct access to the process instance, but "
"instead it will schedule a callback on the main thread who can perform the "
"action. The callback will however not necessarily be executed directly, as "
"there may be other actions waiting to be performed. So when you pause, play "
"or kill a process, you are not doing so directly, but rather you are "
"*scheduling* a request to do so. If the runner has successfully received the"
" request and scheduled the callback, the command will therefore show "
"something like the following:"
msgstr ""

#: ../docs/source/working/processes.rst:681
msgid ""
"The 'scheduled' indicates that the actual killing might not necessarily have"
" happened just yet. This means that even after having called ``verdi process"
" kill`` and getting the success message, the corresponding process may still"
" be listed as active in the output of ``verdi process list``."
msgstr ""

#: ../docs/source/working/processes.rst:684
msgid ""
"By default, the ``pause``, ``play`` and ``kill`` commands will only ask for "
"the confirmation of the runner that the request has been scheduled and not "
"actually wait for the command to have been executed. This is because, as "
"explained, the actual action being performed might not be instantaneous as "
"the runner may be busy working with other processes, which would mean that "
"the command would block for a long time. If you want to send multiple "
"requests to a lot of processes in one go, this would be ineffective, as each"
" one would have to wait for the previous one to be completed. To change the "
"default and actually wait for the action to be completed and await its "
"response, you can use the ``--wait`` flag. If you know that your daemon "
"runners may be experiencing a heavy load, you can also increase the time "
"that the command waits before timing out, with the ``-t/--timeout`` flag."
msgstr ""

#: ../docs/source/working/processes.rst:692
#: ../docs/source/working/workflows.rst:576
msgid "Footnotes"
msgstr "脚注"

#: ../docs/source/working/processes.rst:693
msgid ""
"Note that the "
":py:class:`~aiida.calculations.plugins.arithmetic.add.ArithmeticAddCalculation`"
" process class also takes a ``code`` as input, but that has been omitted for"
" the purposes of the example."
msgstr ""

#: ../docs/source/working/workflows.rst:7
msgid ""
"A workflow in AiiDA is a process (see the :ref:`process "
"section<concepts_processes>` for details) that calls other workflows and "
"calculations and optionally *returns* data and as such can encode the logic "
"of a typical scientific workflow. Currently, there are two ways of "
"implementing a workflow process:"
msgstr ""

#: ../docs/source/working/workflows.rst:10
msgid ":ref:`work function<working_workfunctions>`"
msgstr ":ref:`工作函数<working_workfunctions>`"

#: ../docs/source/working/workflows.rst:11
msgid ":ref:`work chain<working_workchains>`"
msgstr ":ref:`工作链<working_workchains>`"

#: ../docs/source/working/workflows.rst:13
msgid ""
"This section will provide detailed information and best practices on how to "
"implement these two workflow types."
msgstr ""

#: ../docs/source/working/workflows.rst:16
msgid ""
"This chapter assumes that the basic concept and difference between work "
"functions and work chains is known and when one should use on or the other. "
"It is therefore crucial that, before you continue, you have read and "
"understood the basic concept of :ref:`workflow "
"processes<concepts_workflows>`."
msgstr ""

#: ../docs/source/working/workflows.rst:22
msgid "Work functions"
msgstr "工作函数"

#: ../docs/source/working/workflows.rst:24
msgid ""
"The concept of work functions and the basic rules of implementation are "
"documented in detail elsewhere:"
msgstr ""

#: ../docs/source/working/workflows.rst:26
msgid ":ref:`concept of work functions<concepts_workfunctions>`"
msgstr ":ref:`工作流函数的概念<concepts_workfunctions>`"

#: ../docs/source/working/workflows.rst:27
msgid ":ref:`implementation of process functions<working_process_functions>`"
msgstr ":ref:`例程函数的实现<working_process_functions>`"

#: ../docs/source/working/workflows.rst:29
msgid ""
"Since work functions are a sub type of process functions, just like "
"calculation functions, their implementation rules are as good as identical. "
"However, their intended aim and heuristics are very different. Where "
":ref:`calculation functions<working_calcfunctions>` are 'calculation'-like "
"processes that *create* new data, work functions behave like 'workflow'-like"
" processes and can only *return* data. What this entails in terms of "
"intended usage and limitations for work functions is the scope of this "
"section."
msgstr ""

#: ../docs/source/working/workflows.rst:37
msgid "Returning data"
msgstr "返回数据"

#: ../docs/source/working/workflows.rst:38
msgid ""
"It has been said many times before: work functions, like all 'workflow'-like"
" processes, `return` data, but what does `return` mean exactly? In this "
"context, the term 'return' is not intended to refer to a piece of python "
"code returning a value. Instead it refers to a workflow process recording a "
"data node as one of its outputs, that *it itself did not create*, but which "
"rather was created by some other process, that was called by the workflow. "
"The calculation process was responsable for *creating* the data node and the"
" workflow is merely *returning* it as one of its outputs."
msgstr ""

#: ../docs/source/working/workflows.rst:43
msgid ""
"This is then exactly what the workfunction function does. It takes one or "
"more data nodes as inputs, calls other processes to which it passes those "
"inputs and optionally returns some or all of the outputs created by the "
"calculation processes it called. As explained in the :ref:`technical "
"section<working_process_functions>`, outputs are recorded as 'returned' "
"nodes simply by returning the nodes from the function. The engine will "
"inspect the return value from the function and attach the output nodes to "
"the node that represents the work function. To verify that the output nodes "
"are in fact not 'created', the engine will check that the nodes are stored. "
"Therefore, it is very important that you **do not store the nodes you create"
" yourself**, or the engine will raise an exception, as shown in the "
"following example:"
msgstr ""

#: ../docs/source/working/workflows.rst:53
msgid ""
"Because the returned node is a newly created node and not stored, the engine"
" will raise the following exception:"
msgstr ""

#: ../docs/source/working/workflows.rst:61
msgid ""
"Note that you could of course circumvent this check by calling ``store`` "
"yourself on the node, but that misses the point. The problem with using a "
"``workfunction`` to 'create' new data, is that the provenance is lost. To "
"illustrate this problem, let's go back to the simple problem of implementing"
" a workflow to add two integer and multiply the result with a third. The "
":ref:`correct implementation<concepts_workfunctions>` has a resulting "
"provenance graph that clearly captures the addition and the multiplication "
"as separate calculation nodes, as shown in "
":numref:`fig_work_functions_provenance_add_multiply_full`. To illustrate "
"what would happen if one does does not call calculation functions to perform"
" the computations, but instead directly perform them in the work function "
"itself and return the result, consider the following example:"
msgstr ""

#: ../docs/source/working/workflows.rst:70
#: ../docs/source/working/workflows.rst:89
msgid ""
"For the documentation skimmers: this is an explicit example on **how not to "
"use** work functions. The :ref:`correct "
"implementation<concepts_workfunctions>` calls calculation functions to "
"perform the computation"
msgstr ""

#: ../docs/source/working/workflows.rst:72
msgid ""
"Note that in this example implementation we explicitly had to call ``store``"
" on the result before returning it to avoid the exception thrown by the "
"engine. The resulting provenance would look like the following:"
msgstr ""

#: ../docs/source/working/workflows.rst:78
msgid ""
"The provenance generated by the incorrect work function implementation. Note"
" how the addition and multiplication are not explicitly represented, but are"
" implicitly hidden inside the workflow node. Moreover, the result node does "
"not have a 'create' link, because a work function cannot create new data."
msgstr ""

#: ../docs/source/working/workflows.rst:80
msgid ""
"However, looking at the generated provenance shows exactly why we shouldn't."
" This faulty implementation loses provenance as it has no explicit "
"representations of the addition and the multiplication and the `result` node"
" does not have a `create` link, which means that if only the data provenance"
" is followed, it is as if it appears out of thin air! Compare this to the "
"provenance graph of "
":numref:`fig_work_functions_provenance_add_multiply_full`, which was "
"generated by a solution that correctly uses calculation functions to perform"
" the computations. In this trivial example, one may think that this loss of "
"information is not so important, because it is implicitly captured by the "
"workflow node. But a halfway solution may make the problem more apparent, as"
" demonstrated by the following snippet where the addition is properly done "
"by calling a calculation function, but the final product is still performed "
"by the work function itself:"
msgstr ""

#: ../docs/source/working/workflows.rst:91
msgid ""
"This time around the addition is correctly performed by a calculation "
"function as it should, however, its result is multiplied by the work "
"function itself and returned. Note that once again ``store`` had to be "
"called explicitly on ``product`` to avoid the engine throwing a "
"``ValueError``, which is only for the purpose of this example **and should "
"not be done in practice**. The resulting provenance would look like the "
"following:"
msgstr ""

#: ../docs/source/working/workflows.rst:98
msgid ""
"The provenance generated by the incorrect work function implementation that "
"uses only a calculation function for the addition but performs the "
"multiplication itself. The red cross is there to indicate that there is no "
"actual connection between the intermediate sum `D4` and the final result "
"`D5`, even though the latter in reality derives from the former."
msgstr ""

#: ../docs/source/working/workflows.rst:101
msgid ""
"The generated provenance shows, that although the addition is explicitly "
"represented because the work function called the calculation function, there"
" is no connection between the sum and the final result. That is to say, "
"there is no direct link between the sum `D4` and the final result `D5`, as "
"indicated by the red cross, even though we know that the final answer was "
"based on the intermediate sum. This is a direct cause of the work function "
"'creating' new data and illustrates how, in doing so, the provenance of data"
" creation is lost."
msgstr ""

#: ../docs/source/working/workflows.rst:111
msgid ""
"To terminate the execution of a work function and mark it as failed, one "
"simply has to return an :ref:`exit code<working_processes_exit_codes>`. The "
":py:class:`~aiida.engine.processes.exit_code.ExitCode` named tuple is "
"constructed with an integer, to denote the desired exit status and an "
"optional message When such as exit code is returned, the engine will mark "
"the node of the work function as ``Finished`` and set the exit status and "
"message to the value of the tuple. Consider the following example:"
msgstr ""

#: ../docs/source/working/workflows.rst:123
msgid ""
"The execution of the work function will be immediately terminated as soon as"
" the tuple is returned, and the exit status and message will be set to "
"``418`` and ``I am a teapot``, respectively. Since no output nodes are "
"returned, the ``WorkFunctionNode`` node will have no outputs and the value "
"returned from the function call will be an empty dictionary."
msgstr ""

#: ../docs/source/working/workflows.rst:130
msgid "Work chains"
msgstr "工作链"

#: ../docs/source/working/workflows.rst:132
msgid ""
"The :ref:`basic concept of the work chain<concepts_workchains>` has been "
"explained elsewhere. This section will provide details on how a work chain "
"can and should be implemented. A work chain is implemented by the "
":py:class:`~aiida.engine.processes.workchains.workchain.WorkChain` class. "
"Since it is a sub class of the "
":py:class:`~aiida.engine.processes.process.Process` class, it shares all its"
" properties. It will be very valuable to have read the section on working "
"with :ref:`generic processes<working_processes>` before continuing, because "
"all the concepts explained there will apply also to work chains."
msgstr ""
":ref:`工作链的基本概念<concepts_workchains>` 已在别处解释过。本节将提供有关应该如何实现工作链的详细信息。工作链由 "
":py:class:`~aiiida.engine.processes.workchains.workchain.WorkChain` 类实现。因为它是"
" :py:class:`~aiida.engine.processes.process.Process` "
"类的子类，所以它共享它的所有属性。在继续前，阅读有关使用的部分 :ref:`generic processes <working_processes>`"
" 将是非常有价值的，因为那里解释的所有概念也将适用于工作链。"

#: ../docs/source/working/workflows.rst:138
msgid ""
"Let's continue with the example presented in the section on the "
":ref:`concept of workchains<concepts_workchains>`, where we sum two integers"
" and multiply the result with a third. We provided a very simple "
"implementation in a code snippet, whose generated provenance graph, when "
"executed, is shown in "
":numref:`fig_work_chains_provenance_add_multiply_workchain_full`. For "
"convenience we copy the snippet here once more:"
msgstr ""
"让我们继续讨论 :ref:`work of workchains <concepts_workchains>` "
"中的示例，其中我们将两个整数相加并将结果乘以第三个。我们在代码片段中提供了一个非常简单的实现，其生成的可验证性图在执行时显示在 "
":numref:`fig_work_chains_provenance_add_multiply_workchain_full` "
"中。为方便起见，我们再次将代码段复制到此处："

#: ../docs/source/working/workflows.rst:145
msgid ""
"We will now got through the implementation step-by-step and go into more "
"detail on the interface and best practices."
msgstr "我们现在将逐步完成实现，并详细介绍结构和最佳实践。"

#: ../docs/source/working/workflows.rst:152
msgid ""
"To implement a new work chain, simply create a new class that sub classes "
":py:class:`~aiida.engine.processes.workchains.workchain.WorkChain`. You can "
"give the new class any valid python class name, but the convention is to "
"have it end in ``WorkChain`` so that it is always immediately clear what it "
"references. After having created a new work chain class, the first and most "
"important method to implement is the "
":py:meth:`~aiida.engine.processes.process.Process.define` method. This is a "
"class method that allows the developer to define the characteristics of the "
"work chain, such as what inputs it takes, what outputs it can generate, what"
" potential exit codes it can return and the logical outline through which it"
" will accomplish all this."
msgstr ""
"要实现一个新的工作链，只需创建一个 "
":py:class:`~aiida.engine.processes.workchains.workchain.WorkChain` "
"的子类。您可以为新类提供任何有效的python类名，但约定是将它以 ``WorkChain`` "
"结尾，以便始终立即清楚它引用的内容。在创建了一个新的工作链类之后，第一个也是最重要的实现方法是 "
":py:meth:`~aiida.engine.processes.process.Process.define` "
"方法。这是一个类方法，允许开发人员定义工作链的特征，例如它需要什么输入，它可以生成什么输出，它可以返回什么样的退出码以及它将完成所有这些的逻辑大纲。"

#: ../docs/source/working/workflows.rst:157
msgid ""
"To implement the ``define`` method, you have to start with the following "
"three lines:"
msgstr "要实现 ``define`` 方法，您必须从以下三行开始："

#: ../docs/source/working/workflows.rst:165
msgid ""
"where you replace ``AddAndMultiplyWorkChain`` with the actual name of your "
"work chain. The ``@classmethod`` decorator indicates that this method is a "
"class method  [#f1]_ and not an instance method. The second line is the "
"method signature and specified that it will receive the class itself ``cls``"
" and ``spec`` which will be an instance of the "
":py:class:`~aiida.engine.processes.process_spec.ProcessSpec`. This is the "
"object that we will use to define our inputs, outputs and other relevant "
"properties of the work chain. The third and final line is extremely "
"important, as it will call the ``define`` method of the parent class, in "
"this case the "
":py:class:`~aiida.engine.processes.workchains.workchain.WorkChain` class."
msgstr ""
"这里，用工作链的实际名称替换 ``AddAndMultiplyWorkChain`` 。  ``classmethod`` 装饰器表示此方法是类方法 "
"[＃f1]_ 而不是实例方法。第二行是方法签名，并指定它将接收类本身 ``cls`` 和 ``spec`` ，它们将是 "
":py:class:`~aiida.engine.processes.process_spec.ProcessSpec` "
"的一个实例。这是我们将用于定义工作链的输入，输出和其他相关属性的对象。第三行和最后一行非常重要，因为它将调用父类的 ``define`` "
"方法，在本例中父类为 "
":py:class:`~aiiida.engine.processes.workchains.workchain.WorkChain` 类。"

#: ../docs/source/working/workflows.rst:173
msgid ""
"If you forget to call ``super`` in the ``define`` method, your work chain "
"will fail miserably!"
msgstr "如果你忘记在 ``define`` 方法中调用 ``super`` ，你的工作链就会失败！"

#: ../docs/source/working/workflows.rst:179
msgid "Inputs and outputs"
msgstr "输入和输出"

#: ../docs/source/working/workflows.rst:180
msgid ""
"With those formalities out of the way, you can start defining the "
"interesting properties of the work chain through the ``spec``. In the "
"example you can see how the method "
":py:meth:`~aiida.engine.processes.process_spec.ProcessSpec.input` is used to"
" define multiple input ports, which document exactly which inputs the work "
"chain expects. Similarly, "
":py:meth:`~aiida.engine.processes.process_spec.ProcessSpec.output` is called"
" to instruct that the work chain will produce an output with the label "
"``result``. These two port creation methods support a lot more "
"functionality, such as adding help string, validation and more, all of which"
" is documented in detail in the section on :ref:`ports and port "
"namespace<working_processes_ports_portnamespaces>`."
msgstr ""
"通过这些步骤，您可以通过 ``spec`` 开始定义工作链的有趣属性。在该示例中，您可以看到方法 "
":py:meth:`~aiida.engine.processes.process_spec.ProcessSpec.input` "
"如何用于定义多个输入端口，这些端口准确记录工作链所期望的输入。类似地，调用 "
":py:meth:`~aiida.engine.processes.process_spec.ProcessSpec.output` "
"来指示工作链将生成带有 ``result`` 标签的输出。这两个端口创建方法支持更多功能，例如添加帮助字符串，验证等等，所有这些都在以下部分详细介绍 "
":ref:`端口和端口命名空间 <working_processes_ports_portnamespaces>` 。"

#: ../docs/source/working/workflows.rst:189
msgid "Outline"
msgstr "工作链大纲"

#: ../docs/source/working/workflows.rst:190
msgid ""
"The outline is what sets the work chain apart from other processes. It is a "
"way of defining the higher-level logic that encodes the workflow that the "
"work chain takes. The outline is defined in the ``define`` method through "
"the :py:meth:`~aiida.engine.processes.process_spec.ProcessSpec.outline`. It "
"takes a sequence of instructions that the work chain will execute, each of "
"which is implemented as a method of the work chain class. In the simple "
"example above, the outline consists of three simple instructions: ``add``, "
"``multiply``, ``results``. Since these are implemented as instance methods, "
"they are prefixed with ``cls.`` to indicate that they are in fact methods of"
" the work chain class. For that same reason, their implementation should "
"take ``self`` as its one and only argument, as demonstrated in the example "
"snippet."
msgstr ""
"大纲是工作链与其他例程区别原因。它是一种定义编码工作链所采用的工作流的更高级逻辑的方法。大纲在 ``define`` 方法中通过 "
":py:meth:`~aiiida.engine.processes.process_spec.ProcessSpec.outline` "
"定义。它需要一系列工作链将执行的指令组成，每个指令都作为工作链类的方法实现。在上面的简单示例中，大纲由三个简单的指令组成: ``add`` ， "
"``multiply`` ， ``results`` 。由于它们是作为实例方法实现的，因此它们以 ``cls .` "
"为前缀，表明它们实际上是工作链的类方法。出于同样的原因，他们的实现应该将 ``self`` 作为唯一的参数，如示例代码段所示。"

#: ../docs/source/working/workflows.rst:198
msgid ""
"The outline in this simple example is not particular interesting as it "
"consists of three simple instructions that will be executed sequentially. "
"However, the outline also supports various logical constructs, such as "
"while-loops, conditionals and return statements. As usual, the best way to "
"illustrate these constructs is by example. The currently available logical "
"constructs for the work chain outline are:"
msgstr ""
"这个简单示例中的大纲并不特别有趣，因为它包含三个将按顺序执行的简单指令。但是，该大纲还支持各种逻辑结构，例如while循环，条件和返回语句。像往常一样，说明这些结构的最佳方法是举例。工作链大纲的当前可用逻辑结构是:"

#: ../docs/source/working/workflows.rst:203
msgid "``if``, ``elif``, ``else``"
msgstr "``if``, ``elif``, ``else``"

#: ../docs/source/working/workflows.rst:204
msgid "``while``"
msgstr "``while``"

#: ../docs/source/working/workflows.rst:205
msgid "``return``"
msgstr "``return``"

#: ../docs/source/working/workflows.rst:207
msgid ""
"To distinguish these constructs from the python builtins, they are suffixed "
"with an underscore, like so ``while_``. To use these in your work chain "
"design, you will have to import them:"
msgstr "为了将这些结构区分python内置函数，它们的后缀为下划线，就像 ``while_`` 。要在工作链设计中使用它们，您必须导入它们:"

#: ../docs/source/working/workflows.rst:214
msgid ""
"The following example shows how to use these logical constructs to define "
"the outline of a work chain:"
msgstr "以下示例显示如何使用这些逻辑结构来定义工作链的大纲:"

#: ../docs/source/working/workflows.rst:234
msgid ""
"This is an implementation (and an extremely contrived one at that) of the "
"well known FizzBuzz [#f2]_ problem. The idea is that the program is supposed"
" to print in sequence the numbers from zero to some limit, except when the "
"number is a multiple of three ``Fizz`` is printed, for a multiple of five "
"``Buzz`` and when it is a multiple of both, the program should print "
"``FizzBuzz``. Note how the syntax looks very much like that of normal python"
" syntax. The methods that are used in the conditionals (between the "
"parentheses of the ``while_`` and ``if_`` constructs) for example should "
"return a boolean; ``True`` when the condition holds and ``False`` otherwise."
" The actual implementation of the outline steps themselves is now trivial:"
msgstr ""
"这是众所周知的FizzBuzz[＃f2]_ 问题的实现（以及极其拙劣的实现）。这个想法是程序应该按顺序打印从零到某个限制的数字，除非数字是三个 "
"``Fizz`` 的倍数打印，五个 ``Buzz`` 的倍数和当它是两者的倍数时，程序应该打印 ``FizzBuzz`` "
"。注意语法看起来非常像普通的python语法。条件中使用的方法（例如 ``while_`` 和 ``if_`` 构造的括号之间）应该返回一个布尔值; "
"条件成立时为 ``True`` ，否则为 ``False`` 。大纲步骤本身的实际实施现在是无足轻重的:"

#: ../docs/source/working/workflows.rst:260
msgid ""
"The intention of this example is to show that with a well designed outline, "
"a user only has to look at the outline to have a good idea *what* the work "
"chain does and *how* it does it. One should not have to look at the "
"implementation of the outline steps as all the important information is "
"captured by the outline itself. Since the goal of a work chain should be to "
"execute a very well defined task, it is the goal of the outline to capture "
"the required logic to achieve that goal, in a clear and short yet not overly"
" succint manner. The outline supports various logical flow constructs, such "
"as conditionals and while loops, so where possible this logic should be "
"expressed in the outline and not in the body of the outline functions. "
"However, one can also go overboard and put too finely grained logical blocks"
" into the outline, causing it to become bulky and difficult to understand."
msgstr ""
"这个例子的目的是为了表明，通过精心设计大纲，用户只需要查看大纲就可以了解 *工作链的作用以及* "
"它是如何实现的。人们不应该看大纲步骤的具体实现，因为大纲本身捕获了所有重要信息。由于工作链的目标应该是执行一项定义明确的任务，因此大纲的目标是以一种清晰而短暂但不过度苛刻的方式捕获实现该目标所需的逻辑。大纲支持各种逻辑流构造，例如条件和while循环，因此在可能的情况下，此逻辑应在大纲中表示，而不是在大纲函数的主体中表示。然而，人们也可能过度使用，并将太细粒度的逻辑块放入大纲中，导致它变得笨重且难以理解。"

#: ../docs/source/working/workflows.rst:266
msgid ""
"A good rule of thumb in designing the outline is the following: before you "
"start designing a work chain, define very clearly the task that it should "
"carry out. Once the goal is clear, draw a schematic block diagram of the "
"necessary steps and logical decisions that connect them, in order to "
"accomplish that goal. Converting the resulting flow diagram in a one-to-one "
"fashion into an outline, often results in very reasonable outline designs."
msgstr ""
"设计大纲的一个好的经验法则如下: "
"在开始设计工作链之前，要非常清楚地定义它应该执行的任务。一旦目标明确，绘制连接它们的必要步骤和逻辑决策的示意性框图，以实现该目标。将得到的流程图以一对一的方式转换为轮廓，通常会产生非常合理的大纲设计。"

#: ../docs/source/working/workflows.rst:275
msgid ""
"There is one more property of a work chain that is specified through its "
"process specification, in addition to its inputs, outputs and outline. Any "
"work chain may have one to multiple failure modes, which are modeled by "
":ref:`exit codes<working_processes_exit_codes>`. A work chain can be stopped"
" at any time, simply by returning an exit code from an outline method. To "
"retrieve an exit code that is defined on the spec, one can use the "
":py:meth:`~aiida.engine.processes.process.Process.exit_codes` property. This"
" returns an attribute dictionary where the exit code labels map to their "
"corresponding exit code. For example, with the following process spec:"
msgstr ""

#: ../docs/source/working/workflows.rst:287
msgid ""
"To see how exit codes can be used to terminate the execution of work chains "
"gracefully, refer to the section "
":ref:`working_workchains_aborting_and_exit_codes`."
msgstr ""

#: ../docs/source/working/workflows.rst:293
msgid "Launching work chains"
msgstr "启动工作链"

#: ../docs/source/working/workflows.rst:295
msgid ""
"The rules for launching work chains are the same as those for any other "
"process, which are detailed in :ref:`this "
"section<working_processes_launching>`. On top of those basic rules, there is"
" one peculiarity in the case of work chains when submitting to the daemon. "
"When you submit a ``WorkChain`` over the daemon, or any other process for "
"that matter, you need to make sure that the daemon can find the class when "
"it needs to load it. Registering your class through the plugin system with a"
" designated entry point is one way to make sure that the daemon will be able"
" to find it. If, however, you simply have a test class and do not want to go"
" through the effort of creating an entry point for it, you should make sure "
"that the module where you define the class is in the python path. "
"Additionally, make sure that the definition of the work chain **is not in "
"the same file from which you submit it**, or the engine won't be able to "
"load it."
msgstr ""

#: ../docs/source/working/workflows.rst:306
msgid "Context"
msgstr "上下文（Context）"

#: ../docs/source/working/workflows.rst:307
msgid ""
"In the simplest work chain example presented in the introductory section, we"
" already saw how the context can be used to persist information during the "
"execution of a work chain and pass it between outline steps. The context is "
"essentially a data container, very similar to a dictionary that can hold all"
" sorts of data. The engine will ensure that its contents are saved and "
"persisted in between steps and when the daemon shuts down or restarts. A "
"trivial example of this would be the following:"
msgstr ""

#: ../docs/source/working/workflows.rst:320
msgid ""
"In the ``step_one`` outline step we store the string ``'store me in the "
"context'`` in the context, which can be addressed as ``self.ctx``, under the"
" key ``some_variable``. Note that for the key you can use anything that "
"would be a valid key for a normal python dictionary. In the second outline "
"step ``step_two``, we can verify that the string was successfully persisted,"
" by checking the value stored in the context ``self.ctx.some_variable``."
msgstr ""

#: ../docs/source/working/workflows.rst:326
msgid "Any data that is stored in the context **has** to be serializable."
msgstr ""

#: ../docs/source/working/workflows.rst:328
msgid ""
"This was just a simple example to introduce the concept of the context, "
"however, it really is one of the more important parts of the work chain. The"
" context really becomes crucial when you want to submit a calculation or "
"another work chain from within the work chain. How this is accomplished, we "
"will show in the next section."
msgstr ""

#: ../docs/source/working/workflows.rst:335
msgid "Submitting sub processes"
msgstr "提交子例程"

#: ../docs/source/working/workflows.rst:336
msgid ""
"One of the main tasks of a ``WorkChain`` will be to launch other processes, "
"such as a ``CalcJob`` or another ``WorkChain``. How to submit processes was "
"explained in :ref:`another section<working_processes_launch>` and is "
"accomplished by using the :py:func:`~aiida.engine.launch.submit` launch "
"function. However, when submitting a sub process from within a work chain, "
"**this should not be used**. Instead, the "
":py:class:`~aiida.engine.processes.process.Process` class provides its own "
":py:meth:`~aiida.engine.processes.process.Process.submit` method. If you do,"
" you will be greeted with the exception:"
msgstr ""

#: ../docs/source/working/workflows.rst:346
msgid ""
"The only change you have to make is to replace the top-level ``submit`` "
"method with the built-in method of the process class:"
msgstr ""

#: ../docs/source/working/workflows.rst:354
msgid ""
"The ``self.submit`` method has the exact same interface as the global "
"``aiida.engine.launch.submit`` launcher. When the ``submit`` method is "
"called, the process is created and submitted to the daemon, but at that "
"point it is not yet done. So the value that is returned by the ``submit`` "
"call is not the result of the submitted process, but rather it is the "
"process node that represents the execution of the process in the provenance "
"graph and acts as a *future*. We somehow need to tell the work chain that it"
" should wait for the sub process to be finished, and the future to resolve, "
"before it continues. To do so, however, control has to be returned to the "
"engine, which can then, when the process is completed, call the next step in"
" the outline, where we can analyse the results. The snippet above already "
"revealed that this is accomplished by returning an instance of the "
"``ToContext`` class."
msgstr ""

#: ../docs/source/working/workflows.rst:362
msgid "To context"
msgstr "To context （转换为上下文）"

#: ../docs/source/working/workflows.rst:363
msgid ""
"In order to store the future of the submitted process, we can store it in "
"the context with a special construct that will tell the engine that it "
"should wait for that process to finish before continuing the work chain. To "
"illustrate how this works, consider the following minimal example:"
msgstr ""
"为了存储提交过程的未来(Future)效果，我们可以将其存储在具有特殊构造的上下文(context)中，该构造将告诉引擎它应该在继续工作链之前等待该例程完成。为了说明其工作原理，请考虑以下小示例："

#: ../docs/source/working/workflows.rst:369
msgid ""
"As explained in the previous section, calling ``self.submit`` for a given "
"process that you want to submit, will return a future. To add this future to"
" the context, we can not access the context directly as explained in the "
":ref:`context section<working_workchains_context>`, but rather we need to "
"use the class "
":py:class:`~aiida.engine.processes.workchains.context.ToContext`. This class"
" has to be imported from the ``aiida.engine`` module. To add the future to "
"the context, simply construct an instance of ``ToContext``, passing the "
"future as a keyword argument, and returning it from the outline step. The "
"keyword used, ``workchain`` in this example, will be the key used under "
"which to store the node in the context once its execution has terminated. "
"Returning an instance of ``ToContext`` signals to the engine that it has to "
"wait for the futures contained within it to finish execution, store their "
"nodes in the context under the specified keys and then continue to the next "
"step in the outline. In this example, that is the ``inspect_workchain`` "
"method. At this point we are sure that the process, a work chain in this "
"case, has terminated its execution, although not necessarily successful, and"
" we can continue the logic of the work chain."
msgstr ""
"如上一节所述，为要提交的给定进程调用 ``self.submit`` "
"将返回未来结果(future)。要将此未来结果添加到上下文中，我们无法直接访问上下文，如 "
":ref:`context（上下文）章节<working_workchains_context>` 中所述，而我们需要使用类 "
":py:class:`~aiida.engine.processes.workchains.context.ToContext` 。这个类必须从 "
"``aiida.engine`` 模块导入。要将未来结果添加到上下文中，只需构造一个 ``ToContext`` 实例，将 future "
"作为关键字参数传递，并从outline步骤返回。在这个例子中使用的关键字 ``workchain`` 将是在执行终止后将节点存储在上下文中的键中。将 "
"``ToContext`` "
"信号的实例返回给引擎，它必须等待其中包含的预期完成执行，将它们的节点存储在指定键的上下文中，然后继续执行大纲中的下一步。在这个例子中，这是 "
"``inspect_workchain`` "
"方法。在这一点上，我们确信这个例程，在这种情况下是一个工作链，已经终止了它的执行，虽然不一定成功，但我们可以继续工作链的逻辑。"

#: ../docs/source/working/workflows.rst:380
msgid ""
"Using the ``ToContext`` construct alone is not enough to tell the engine "
"that it should wait for the sub process to finish. There **needs** to be at "
"least another step in the outline to follow the step that added the "
"awaitables. If there is no more step to follow, according to the outline, "
"the engine interprets this as the work chain being done and so it will not "
"wait for the sub process to finish. Think about it like this: if there is "
"not even a single step to follow, there is also nothing the work chain could"
" do with the results of the sub process, so there is no point in waiting."
msgstr ""
"仅使用 ``ToContext`` 构造并不足以告诉引擎它应该等待子进程完成。在大纲中，**需要** "
"至少有另一个步骤，以添加可等待的步骤。如果没有更多的步骤，根据大纲，引擎将其解释为正在完成的工作链，因此它不会等待子例程完成。这样想: "
"如果没有一个单独的步骤要遵循，那么工作链对子例程的结果也无能为力，所以等待是没有意义的。"

#: ../docs/source/working/workflows.rst:385
msgid ""
"Sometimes one wants to launch not just one, but multiple processes at the "
"same time that can run in parallel. With the mechanism described above, this"
" will not be possible since after submitting a single process and returning "
"the ``ToContext`` instance, the work chain has to wait for the process to be"
" finished before it can continue. To solve this problem, there is another "
"way to add futures to the context:"
msgstr ""
"有时候人们不仅想要启动一个，而是同时启动多个并行运行的进程。使用上述机制，这是不可能的，因为在提交单个进程并返回 ``ToContext`` "
"实例之后，工作链必须等待例程完成才能继续。要解决这个问题，还有另一种方法可以将未来结果添加到上下文中："

#: ../docs/source/working/workflows.rst:392
msgid ""
"Here we submit three work chains in a for loop in a single outline step, but"
" instead of returning an instance of ``ToContext``, we call the "
":meth:`~aiida.engine.processes.workchains.workchain.WorkChain.to_context` "
"method. This method has exactly the same syntax as the ``ToContext`` class, "
"except it is not necessary to return its value, so we can call it multiple "
"times in one outline step. Under the hood the functionality is also the same"
" as the ``ToContext`` class. At the end of the ``submit_workchains`` outline"
" step, the engine will find the futures that were added by calling "
"``to_context`` and will wait for all of them to be finished. The good thing "
"here is that these three sub work chains can be run in parallel and once all"
" of them are done, the parent work chain will go to the next step, which is "
"``inspect_workchains``. There we can find the nodes of the work chains in "
"the context under the key that was used as the keyword argument in the "
"``to_context`` call in the previous step."
msgstr ""
"在这里，我们在一个大纲步骤中在for循环中提交三个工作链，但是我们不是返回 ``ToContext`` 的实例，而是调用 "
":meth:`~aiiida.engine.processes.workchains.workchain.WorkChain.to_context ` "
"方法。这个方法与 ``ToContext`` "
"类的语法完全相同，只是没有必要返回它的值，所以我们可以在一个大纲步骤中多次调用它。在AiiDA引擎下，其功能也与 ``ToContext`` 类相同。在"
" ``submit_workchains`` 大纲步骤结束时，引擎将通过调用 ``to_context`` "
"找到所添加的未来期望结果，并等待所有这些未来结果完成。这里的好处是这三个子工作链可以并行运行，一旦完成所有这些工作链，父工作链将进入下一步，即 "
"``inspect_workchains`` 。在那里，我们可以在上下文的上下文中找到工作链的节点，该键在上一步的 ``to_context`` "
"调用中用作关键字参数。"

#: ../docs/source/working/workflows.rst:399
msgid ""
"Since we do not want the subsequent calls of ``to_context`` to override the "
"previous future, we had to create unique keys to store them under. In this "
"example, we chose to use the index of the for-loop. The name carries no "
"meaning and is just required to guarantee unique key names. This pattern "
"will occur often where you will want to launch multiple work chains or "
"calculations in parallel and will have to come up with unique names. In "
"essence, however, you are really just creating a list and it would be better"
" to be able to create a list in the context and simply append the future to "
"that list as you submit them. How this can be achieved is explained in the "
"next section."
msgstr ""
"由于我们不希望随后调用 ``to_context`` "
"来覆盖以前的未来，我们必须创建唯一的键来存储它们。在这个例子中，我们选择使用for循环的索引。该名称没有任何意义，只需要保证唯一的密钥名称。这种模式通常会出现在您希望并行启动多个工作链或算例的位置，并且必须提供唯一的名称。但实质上，您实际上只是创建一个列表，最好能够在上下文中创建列表，并在提交时将未来结果添加到该列表中。如何实现这一点将在下一节中解释。"

#: ../docs/source/working/workflows.rst:407
msgid "Appending"
msgstr "追加"

#: ../docs/source/working/workflows.rst:408
msgid ""
"When you want to add a future of a submitted sub process to the context, but"
" append it to a list rather than assign it to a key, you can use the "
":func:`~aiida.engine.processes.workchains.context.append_` function. "
"Consider the example from the previous section, but now we will use the "
"``append_`` function instead:"
msgstr ""
"如果要将已提交的子例程的未来结果添加到上下文中，但将其附加到列表而不是将其分配给键，则可以使用 "
":func:`~aiida.engine.processes.workchains.context.append_ ` "
"函数。继续考虑上一节中的示例，现在我们将使用 ``append_`` 函数："

#: ../docs/source/working/workflows.rst:414
msgid ""
"Notice that in the ``submit_workchains`` step we no longer have to generate "
"a unique key based on the index but we simply wrap the future in the "
"``append_`` function and assign it to the generic key ``workchains``. The "
"engine will see the ``append_`` function and instead of assigning the node "
"corresponding to the future to the key ``workchains``, it will append it to "
"the list stored under that key. If the list did not yet exist, it will "
"automatically be created. The ``self.ctx.workchains`` now contains a list "
"with the nodes of the completed work chains and so in the "
"``inspect_workchains`` step we can simply iterate over it to access all of "
"them."
msgstr ""
"请注意，在 ``submit_workchains`` 步骤中，我们不再需要根据索引生成唯一键，但我们需将未来结果包装在 ``append_`` "
"函数中，并将其分配给通用键 ``workchains`` 。引擎将看到 ``append_`` 函数，而不是将对应于未来结果的节点分配给键 "
"'`workchains`` ，它将把它附加到存储在该键下的列表中。如果列表尚不存在，则会自动创建。  ``self.ctx.workchains`` "
"现在包含一个列表，其中包含已完成工作链的节点，因此在 ``inspect_workchains`` 步骤中，我们可以简单地迭代它以访问所有这些链接。"

#: ../docs/source/working/workflows.rst:421
msgid ""
"The process nodes of the completed processes will **not necessarily** be "
"added to the list in the context in the same order as the ``to_context`` "
"calls. This is because the futures may not necessarily be resolved in the "
"same order as they were submitted. Therefore it is dangerous to depend on "
"the order when using the append method."
msgstr ""
"已完成的例程的i例程节点**不一定**会以与 ``to_context`` "
"调用相同的顺序添加到上下文中的列表中。这是因为未来结果可能不一定按照提交的顺序解决。因此，在使用append方法时依赖顺序是危险的。"

#: ../docs/source/working/workflows.rst:425
msgid ""
"Note that the use of ``append_`` is not just limited to the ``to_context`` "
"method. You can also use it in exactly the same way with ``ToContext`` to "
"append a process to a list in the context in multiple outline steps."
msgstr ""
"请注意， ``append_`` 的使用不仅限于 ``to_context`` 方法。您也可以使用与 ``ToContext`` "
"完全相同的方式将其添加到多个大纲步骤的上下文列表中。"

#: ../docs/source/working/workflows.rst:431
msgid "Reporting"
msgstr "报告"

#: ../docs/source/working/workflows.rst:432
msgid ""
"During the execution of a ``WorkChain``, we may want to keep the user "
"abreast of its progress and what is happening. For this purpose, the "
"``WorkChain`` implements the "
":py:meth:`~aiida.engine.processes.process.Process.report` method, which "
"functions as a logger of sorts. It takes a single argument, a string, that "
"is the message that needs to be reported:"
msgstr ""
"在执行 ``WorkChain`` 时，我们可能希望让用户及时了解其进度和发生的情况。为此，``WorkChain`` 实现了 "
":py:meth:`~aiiida.engine.processes.process.Process.report` "
"方法，该方法用作各种日志。它需要一个参数，一个字符串，即需要报告的消息:"

#: ../docs/source/working/workflows.rst:441
msgid ""
"This will send that message to the internal logger of python, which will "
"cause it to be picked up by the default AiiDA logger, but it will also "
"trigger the database log handler, which will store the message in the "
"database and link it to the node of the work chain. This allows the ``verdi "
"process report`` command to retrieve all those messages that were fired "
"using the ``report`` method for a specific process. Note that the report "
"method, in addition to the pk of the work chain, will also automatically "
"record the name of the work chain and the name of the outline step in which "
"the report message was fired. This information will show up in the output of"
" ``verdi process report``, so you never have to explicitly reference the "
"work chain name, outline step name or date and time in the message itself."
msgstr ""
"这会将该消息发送到python的内部日志，这将导致它被默认的AiiDA日志拾取，但它也将触发数据库日志处理程序，该处理程序将消息存储在数据库中并将其链接到节点工作链。这允许"
" ``verdi process report`` 命令检索所有那些使用 ``report`` "
"方法为特定例程触发的消息。请注意，除了工作链的pk之外，report 方法还将自动记录工作链的名称以及触发报告消息的大纲步骤的名称。此信息将显示在 "
"``verdi process report`` 的输出中，因此您无需在消息本身中明确引用工作链名称，大纲步骤名称或日期和时间。"

#: ../docs/source/working/workflows.rst:446
msgid ""
"It is important to note that the report system is a form of logging and as "
"such has been designed to be read by humans only. That is to say, the report"
" system is not designed to pass information programmatically by parsing the "
"log messages."
msgstr "值得注意的是，报告系统是一种日志，因此只能被设计为容易阅读的。也就是说，报告系统不是为了通过解析日志消息以编程方式传递信息而设计的。"

#: ../docs/source/working/workflows.rst:452
msgid "Aborting and exit codes"
msgstr "终止和退出码"

#: ../docs/source/working/workflows.rst:453
msgid ""
"At the end of every outline step, the return value will be inspected by the "
"engine. If a non-zero integer value is detected, the engine will interpret "
"this as an exit code and will stop the execution of the work chain, while "
"setting its process state to ``Finished``. In addition, the integer return "
"value will be set as the ``exit_status`` of the work chain, which combined "
"with the ``Finished`` process state will denote that the worchain is "
"considered to be ``Failed``, as explained in the section on the "
":ref:`process state <concepts_process_state>`. This is useful because it "
"allows a workflow designer to easily exit from a work chain and use the "
"return value to communicate programmatically the reason for the work chain "
"stopping."
msgstr ""
"在每个大纲步骤结束时，引擎将检查返回值。如果检测到非零整数值，引擎会将其解释为退出码并停止执行工作链，同时将其例程状态设置为 "
"``Finished``。另外，整数返回值将被设置为工作链的 ``exit_status`` ，它与 ``Finished`` 进程状态相结合则 "
"worchain 被认为是 ``Failed`` ，正如所解释的那样在以下部分中 :ref:`process state "
"<concepts_process_state>` 。这很有用，因为它允许工作流设计人员轻松退出工作链并使用返回值以编程方式知晓工作链停止的原因。"

#: ../docs/source/working/workflows.rst:458
msgid ""
"We assume that you have read the `section on how to define exit code "
"<exit_codes>`_ through the process specification of the work chain. Consider"
" the following example work chain that defines such an exit code:"
msgstr ""
"我们假设您已经阅读了关于如何通过工作链的流程规范 `定义退出码<exit_codes>`_ 的`部分。请考虑以下示例工作链，该工作链定义了这样的退出码："

#: ../docs/source/working/workflows.rst:465
msgid ""
"Now imagine that in the outline, we launch a calculation and in the next "
"step check whether it finished successfully. In the event that the "
"calculation did not finish successfully, the following snippet shows how you"
" can retrieve the corresponding exit code and abort the ``WorkChain`` by "
"returning it:"
msgstr ""
"现在想象一下，在大纲中，我们启动算例并在下一步检查它是否成功完成。如果计算没有成功完成，下面的代码片段显示了如何检索相应的退出码并通过返回它来中止 "
"``WorkChain`` :"

#: ../docs/source/working/workflows.rst:482
msgid ""
"In the ``inspect_calculation`` outline, we retrieve the calculation that was"
" submitted and added to the context in the previous step and check if it "
"finished successfully through the property ``is_finished_ok``. If this "
"returns ``False``, in this example we simply fire a report message and "
"return the exit code corresponding to the label "
"``ERROR_CALCULATION_FAILED``. Note that the specific exit code can be "
"retrieved through the ``WorkChain`` property ``exit_codes``. This will "
"return a collection of exit codes that have been defined for that "
"``WorkChain`` and any specific exit code can then be retrieved by accessing "
"it as an attribute. Returning this exit code, which will be an instance of "
"the :py:class:`~aiida.engine.processes.exit_code.ExitCode` named tuple, will"
" cause the work chain to be aborted and the ``exit_status`` and "
"``exit_message`` to be set on the node, which were defined in the spec."
msgstr ""
"在 ``inspect_calculation`` 大纲中，我们检索已提交的计算并将其添加到上一步中的上下文中，并通过属性 "
"``is_finished_ok`` 检查它是否成功完成。如果这返回 ``False`` ，在这个例子中，我们只需触发一条报告消息并返回对应于标签 "
"``ERROR_CALCULATION_FAILED`` 的退出码。请注意，可以通过 ``WorkChain`` 属性 ``exit_codes`` "
"检索特定的退出码。这将返回已为 ``WorkChain`` "
"定义的退出代码集合，然后可以通过将其作为属性访问来检索任何特定的退出代码。返回此退出码，它将是 "
":py:class:`~aiiida.engine.processes.exit_code.ExitCode` "
"命名为tuple的实例，将导致工作链中止并且在规范中定义的节点上设置 ``exit_status`` 和 `` exit_message`` ."

#: ../docs/source/working/workflows.rst:490
msgid ""
"The notation ``self.exit_codes.ERROR_CALCULATION_FAILED`` is just syntactic "
"sugar to retrieve the ``ExitCode`` tuple that was defined in the spec with "
"that error label. Constructing your own ``ExitCode`` directly and returning "
"that from the outline step will have exactly the same effect in terms of "
"aborting the work chain execution and setting the exit status and message. "
"However, it is strongly advised to define the exit code through the spec and"
" retrieve it through the ``self.exit_codes`` collection, as that makes it "
"easily retrievable through the spec by the caller of the work chain."
msgstr ""
"符号 ``self.exit_codes.ERROR_CALCULATION_FAILED`` 只是语法糖，用于检索带有该错误标签的规范中定义的 "
"``ExitCode`` 元组。直接构造自己的 ``ExitCode`` "
"并从大纲步骤返回它将在中止工作链执行和设置退出状态和消息方面具有完全相同的效果。但是，强烈建议通过规范定义退出码并通过 "
"``self.exit_codes`` 集合检索它，因为这使得工作链的调用者可以通过通过规范轻松检索。"

#: ../docs/source/working/workflows.rst:494
msgid ""
"The best part about this method of aborting a work chains execution, is that"
" the exit status can now be used programmatically, by for example a parent "
"work chain. Imagine that a parent work chain submitted this work chain. "
"After it has terminated its execution, the parent work chain will want to "
"know what happened to the child work chain. As already noted in the "
":ref:`report<working_workchains_reporting>` section, the report messages of "
"the work chain should not be used. The exit status, however, is a perfect "
"way. The parent work chain can easily request the exit status of the child "
"work chain through the ``exit_status`` property, and based on its value "
"determine how to proceed."
msgstr ""
"关于这种中止工作链执行的方法的最好的部分是，退出状态现在可以通过编程方式使用，例如被父工作链知晓并使用。想象一下，父工作链提交了这个工作链。在它终止执行后，父工作链将想知道子工作链发生了什么。正如在"
" :ref:`report <working_workchains_reporting>` "
"部分中已经指出的那样，不应该使用工作链的报告消息。退出状态是一种完美的方式。父工作链可以通过 ``exit_status`` "
"属性轻松请求子工作链的退出状态，并根据其值确定如何继续。"

#: ../docs/source/working/workflows.rst:503
msgid "Modular workflow design"
msgstr "模块化工作流设计"

#: ../docs/source/working/workflows.rst:504
msgid ""
"When creating complex workflows, it is a good idea to split them up into "
"smaller, modular parts. At the lowest level, each workflow should perform "
"exactly one task. These workflows can then be wrapped together by a "
"\"parent\" workflow to create a larger logical unit."
msgstr ""
"在创建复杂工作流时，最好将它们分割成更小的模块部分。在最低级别，每个工作流应该只执行一个任务。然后，这些工作流可以由“父”工作流包装在一起，以创建更大的逻辑单元。"

#: ../docs/source/working/workflows.rst:508
msgid ""
"In order to make this approach manageable, it needs to be as simple as "
"possible to glue together multiple workflows in a larger parent workflow. "
"One of the tools that AiiDA provides to simplify this is the ability to "
"*expose* the ports of another work chain."
msgstr ""
"为了使这种方法易于管理，需要尽可能简单地将更多父工作流中的多个工作流粘合在一起。 AiiDA为简化此操作而提供的工具之一是 *暴露（expose* "
"另一个工作链的端口的能力。"

#: ../docs/source/working/workflows.rst:514
msgid "Exposing inputs and outputs"
msgstr "暴露输入和输出"

#: ../docs/source/working/workflows.rst:515
msgid ""
"Consider the following example work chain, which simply takes a few inputs "
"and returns them again as outputs:"
msgstr "考虑以下示例工作链，它只需要几个输入并将它们作为输出再次返回:"

#: ../docs/source/working/workflows.rst:520
msgid ""
"As a first example, we will implement a thin wrapper workflow, which simply "
"forwards its inputs to ``ChildWorkChain``, and forwards the outputs of the "
"child to its outputs:"
msgstr ""
"作为第一个例子，我们将实现一个小型的封装的工作流，它只是将其输入转发到 ``ChildWorkChain`` ，并将后代的输出转发到它的输出："

#: ../docs/source/working/workflows.rst:525
msgid ""
"In the ``define`` method of this simple parent work chain, we use the "
":meth:`~plumpy.process_spec.ProcessSpec.expose_inputs` and "
":meth:`~plumpy.process_spec.ProcessSpec.expose_outputs`. This creates the "
"corresponding input and output ports in the parent work chain. Additionally,"
" AiiDA remembers which inputs and outputs were exposed from that particular "
"work chain class. This is used when calling the child in the ``run_child`` "
"method. The :meth:`~aiida.engine.processes.process.Process.exposed_inputs` "
"method returns a dictionary of inputs that the parent received which were "
"exposed from the child, and so it can be used to pass these on to the child."
" Finally, in the ``finalize`` method, we use "
":meth:`~aiida.engine.processes.process.Process.exposed_outputs` to retrieve "
"the outputs of the child which were exposed to the parent. Using "
":meth:`~aiida.engine.processes.process.Process.out_many`, these outputs are "
"added to the outputs of the parent work chain. This work chain can now be "
"run in exactly the same way as the child itself:"
msgstr ""
"在这个简单的父工作链的 ``define`` 方法中，我们使用 "
":meth:`~plumpy.process_spec.ProcessSpec.expose_inputs` 和 "
":meth:`~pumpmpy.process_spec.ProcessSpec.expose_outputs` "
"。这将在父工作链中创建相应的输入和输出端口。此外，AiiDA还记得从该特定工作链类中暴露了哪些输入和输出。在 ``run_child`` "
"方法中调用子进程时使用此方法。 "
":meth:`~aiiida.engine.processes.process.Process.exposed_inputs`方法返回父工作链接收到的从子例程中暴露的输入的字典，因此可以用它将这些输入传递给子例程。最后，在"
" ``finalize`` 方法中，我们使用 "
":meth:`~aiiida.engine.processes.process.Process.exposed_outputs`来检索暴露给父例程的子例程的输出。使用"
" :meth:`~aiiida.engine.processes.process.Process.out_many` "
"，这些输出被添加到父工作链的输出中。现在，此工作链可以与子项本身完全相同的方式运行:"

#: ../docs/source/working/workflows.rst:537
msgid ""
"Next, we will see how a more complex parent work chain can be created by "
"using the additional features of the expose functionality. The following "
"work chain launches two children. These children share the input ``a``, but "
"have different ``b`` and ``c``. The output ``e`` will be taken only from the"
" first child, whereas ``d`` and ``f`` are taken from both children. In order"
" to avoid name conflicts, we need to create a *namespace* for each of the "
"two children, where the inputs and outputs which are not shared are stored. "
"Our goal is that the workflow can be called as follows:"
msgstr ""
"接下来，我们将看到如何通过使用暴露功能的其他功能来创建更复杂的父工作链。以下工作链启动了两个子项。这些子项共享输入 ``a`` ，但有不同的 ``b``"
" 和 ``c`` 。输出 ``e`` 将仅从第一个子项中获取，而 ``d`` 和 ``f`` "
"同时从两个子项中获取。为了避免名称冲突，我们需要为两个子节点中的每一个创建一个 *命名空间* "
"，其中存储未共享的输入和输出。我们的目标是可以按如下方式调用工作流程:"

#: ../docs/source/working/workflows.rst:547
msgid ""
"This is achieved by the following workflow. In the next section, we will "
"explain each of the steps."
msgstr "这是通过以下工作流程实现的。在下一节中，我们将解释每个步骤。"

#: ../docs/source/working/workflows.rst:553
msgid ""
"First of all, we want to expose the ``a`` input and the ``e`` output at the "
"top-level. For this, we again use "
":meth:`~plumpy.process_spec.ProcessSpec.expose_inputs` and "
":meth:`~plumpy.process_spec.ProcessSpec.expose_outputs`, but with the "
"optional keyword ``include``. This specifies a list of keys, and only inputs"
" or outputs which are in that list will be exposed. So by passing "
"``include=['a']`` to :meth:`~plumpy.process_spec.ProcessSpec.expose_inputs`,"
" only the input ``a`` is exposed."
msgstr ""
"首先，我们希望在顶层公开 ``a`` 输入和 ``e`` 输出。为此，我们再次使用 "
":meth:`~plumpy.process_spec.ProcessSpec.expose_inputs` 和 "
":meth:`~plumpy.process_spec.ProcessSpec.expose_outputs` ，但使用可选关键字 "
"``include`` 。这指定了一个键列表，只显示该列表中的输入或输出。因此，通过将 ``include = ['a']`` 传递给 "
":meth:`~plumpy.process_spec.ProcessSpec.expose_inputs` ，只显示输入 ``a`` 。"

#: ../docs/source/working/workflows.rst:558
msgid ""
"Additionally, we want to expose the inputs ``b`` and ``c`` (outputs ``d`` "
"and ``f``), but in a namespace specific for each of the two children. For "
"this purpose, we pass the ``namespace`` parameter to the expose functions. "
"However, since we now shouldn't expose ``a`` (``e``) again, we use the "
"``exclude`` keyword, which specifies a list of keys that will not be "
"exposed."
msgstr ""
"另外，我们希望暴露输入 ``b`` 和 ``c`` （输出 ``d`` 和 ``f`` ），但是在特定于两个子项中的每一个的命名空间中。为此，我们将 "
"``namespace`` 参数传递给 expose 函数。但是，由于我们现在不应该再次暴露 ``a`` （ ``e`` ），我们使用 "
"``exclude`` 关键字，它指定了一个不会暴露的键列表。"

#: ../docs/source/working/workflows.rst:562
msgid ""
"When calling the children, we again use the "
":meth:`~aiida.engine.processes.process.Process.exposed_inputs` method to "
"forward the exposed inputs. Since the inputs ``b`` and ``c`` are now in a "
"specific namespace, we need to pass this namespace as an additional "
"parameter. By default, "
":meth:`~aiida.engine.processes.process.Process.exposed_inputs` will search "
"through all the parent namespaces of the given namespace to search for "
"input, as shown in the call for ``child_1``. If the same input key exists in"
" multiple namespaces, the input in the lowest namespace takes precedence. "
"It's also possible to disable this behavior, and instead search only in the "
"explicit namespace that was passed. This is done by setting "
"``agglomerate=False``, as shown in the call to ``child_2``. Of course, we "
"then need to explicitly pass the input ``a``."
msgstr ""
"在调用子项时，我们再次使用 :meth:`~aiida.engine.processes.process.Process.exposed_inputs`"
" 方法来转发暴露的输入。由于输入 ``b`` 和 ``c`` 现在位于特定的命名空间中，我们需要将此命名空间作为附加参数传递。默认情况下， "
":meth:`~aiida.engine.processes.process.Process.exposed_inputs` "
"将搜索给定命名空间的所有父命名空间以搜索输入，如调用 ``child_1`` "
"所示。如果多个名称空间中存在相同的输入键，则最低名称空间中的输入优先。也可以禁用此行为，而只搜索传递的显式命名空间。这是通过设置 "
"``agglomerate=False`` 来完成的，如调用 ``child_2`` 所示。当然，我们需要显式传递输入 ``a`` 。"

#: ../docs/source/working/workflows.rst:570
msgid ""
"Finally, we use "
":meth:`~aiida.engine.processes.process.Process.exposed_outputs` and "
":meth:`~aiida.engine.processes.process.Process.out_many` to forward the "
"outputs of the children to the outputs of the parent. Again, the "
"``namespace`` and ``agglomerate`` options can be used to select which "
"outputs are returned by the "
":meth:`~aiida.engine.processes.process.Process.exposed_outputs` method."
msgstr ""
"最后，我们使用 :meth:`~aiida.engine.processes.process.Process.exposed_outputs` 和 "
":meth:`~aiida .engine.processes.process.Process.out_many` 将子项们的输出转发给父项输出。同样，"
" ``namespace`` 和 ``agglomerate`` 选项可用于决定 "
":meth:`~aiida.engine.processes.process.Process.exposed_outputs` 方法返回哪些输出。"

#: ../docs/source/working/workflows.rst:577
msgid "https://docs.python.org/3.5/library/functions.html#classmethod"
msgstr "https://docs.python.org/3.5/library/functions.html#classmethod"

#: ../docs/source/working/workflows.rst:578
msgid "https://en.wikipedia.org/wiki/Fizz_buzz"
msgstr "https://en.wikipedia.org/wiki/Fizz_buzz"
